# 五种数据类型
## ①String 是 Redis 最基本的类型
常用命令：set,get,decr,incr,mget 
常规key-value缓存应用，常规的计数

## ②Hash是一个键值（key-value）的集合
常用命令： hget,hset,hgetall 
hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 
比如我们可以 hash 数据结构来存储用户信息，商品信息等等。

## ③List 列表是简单的字符串列表，按照插入顺序排序
常用命令: lpush,rpush,lpop,rpop,lrange
list 就是链表，Redis list 的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表等功能都可以用Redis的 list 结构来实现。
Redis list 的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。
另外可以通过 lrange 命令，就是从某个元素开始读取多少个元素，可以基于 list 实现分页查询，这个很棒的一个功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。


## ④Set 是 String 类型的无序集合。
常用命令： sadd,spop,smembers,sunion
当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择。
并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。

## ⑤Sorted Set
常用命令： zadd,zrange,zrem,zcard
和set相比，sorted set增加了一个权重参数score，使得集合中的元素能够按score进行有序排列。


# Redis过期时间
在Redis的expires字典中保存了数据库中所有键的过期时间，所以叫过期字典。
- 过期字典的key是一个指针，指向键空间的某个键对象（就是数据库键）
- 过期字典的value是一个long类型的整数，这个整数保存了键所指向的数据库键的过期时间，一个毫秒精度的UNIX时间戳
## 过期键判定
- 判断key是否存在于过期字典中
- 通过过期字典拿到key的过期时间，判断当前UNIX时间戳是否大于key时间
## 重点：过期键的删除策略
### 定时删除：
设置过期键的同时，设定设定定时器，通过定时器来主动删除过期键。
这种方式对内存友好，但是对cpu最不友好；定时器的设定需要使用redis服务器的时间事件（无序链表），查找的事件复杂度为O(n);故在过期键过多时，cpu的大部分占用是用来查找过期键和删除过期键的。
### 惰性删除：
每次对key进行操作时，判断当前key是否过期，再进行操作。
这种方式很明显对内存是不友好的，key过期的话仍然会一直存在数据库中，直到下次有对这个key的操作。
### 定期删除：
定期删除指的是Redis默认每隔100ms就随机抽取一些设置了过期时间的key，检测这些key是否过期，如果过期了就将其删掉。
因为key太多，如果全盘扫描所有的key会非常耗性能，所以是随机抽取一些key来删除。这样就有可能删除不完，需要惰性删除配合。

但有些过期的key既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以Redis提供了内存淘汰机制来解决这个问题。

# 内存淘汰机制
**MySQL里有2000w数据，Redis中只存20w的数据，内存淘汰机制可以保证Redis中的数据都是热点数据**
Redis在使用内存达到某个阈值（通过maxmemory配置)的时候，就会触发内存淘汰机制，选取一些key来删除。内存淘汰有许多策略，下面分别介绍这几种
- noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。默认策略
- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
- allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
- volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
- volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
- volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。
如何进行选择呢？
如何选取合适的策略？比较推荐的是两种lru策略。根据自己的业务需求。
如果你使用Redis只是作为缓存，不作为DB持久化，那推荐选择allkeys-lru；
如果你使用Redis同时用于缓存和数据持久化，那推荐选择volatile-lru。
应用场景（缓存预热）：
    1，缓存预热基本思路
    由于缓存冷启动问题，redis 启动后，一点数据都没有，直接就对外提供服务了，mysql 裸奔
    （1）提前给 redis 中灌入部分数据，再提供服务
    （2）数据量太大的话，无法将所有数据放入 redis 中
        耗费时间过长
        或 redis 根本无法容纳下所有的数据
    （3）需要根据当天的具体访问情况，实时统计出访问频率较高的热数据
        然后将访问频率较高的热数据写入 redis 中，肯定数据也比较多， 我们也得多个服务并行读取数据去写，并行的分布式缓存预热
    （4）都准备好后，在对外服务，就不至于冷启动，让数据库裸奔了
    2，缓存预热具体实现思路
    （1）nginx +lua 将访问流量上报到 kafka 中
        要统计出当前最新的实时的热数据是那些，我们就得将商品详情页访问的请求对应的流量 日志实时上报到 kafka 中
    （2）storm 从 kafka 中消费数据，实时统计访问次数
        访问次数基于 LRU 内存数据结构的存储方案；
        为什么要基于 LRU 内存方案？
            storm 中读写数据频繁
            数据量大
            所以不适合依赖 redis 或者 mysql：
            redis 可能出现故障，会导致 storm 的稳定性
            mysql：扛不住高并发读写
            hbase：hadoop 生态组合还是不错的，但是对于非专业大数据方向来说，维护太重了
        我之前做过的一些项目，一些广告计费类的系统也是用这种方案，有人就直接往 mysql 中去写， 流量上来之后 mysql 直接被打死了
        其实我们的需求就是：统计出最近一段时间访问最频繁的商品，进行访问计数， 同时维护出一个前 N 个访问最多的商品 list 即可
        也就是热数据：最近一段时间（如最近 1 小时、5 分钟），1 万个商品请求， 统计这段时间内每个商品的访问次数，排序后做出一个 top n 列表
        计算好每个 task 大致要存放的商品访问次数的数量，计算出大小， 然后构建一个 LRU MAP，它能够给你一个剩下访问次数最多的商品列表，访问高的才能存活
        LRU MAP 有开源的实现，apach commons collections 中有提供，设置好 map 的最大大小， 就会自动根据 LRU 算法去剔除多余的数据，保证内存使用限制， 即时有部分数据被干掉了，下次会从 0 开始统计，也没有关系，因为被 LRU 算法干掉了， 就表示它不是热数据，说明最近一段时间都很少访问了，热度下降了
    （3）每个 Storm task 启动时，基于 zk 分布式锁，将自己的 ID 写入 zk 同一个节点中
        这个 id 写到一个固定节点中，形成一个 task id 列表， 后续可以通过这个 id 列表去拿到对于 task 存储在 zk node 上的 topn 列表
    （4）每个 Storm task 负责完成自己这里的热数据统计
        比如每隔一段时间，就遍历下这个 map，维护并更新一个前 n 个商品的 list
    （5）定时同步到 zk 中去
        写一个后台线程，每隔一段时间，比如 1 分钟，将这个 task 所有的商品排名算一次 将排名前 n 的热数据 list 同步到 zk 中去
    （6）需要一个服务，根据 top n 列表在 mysql 中获取数据往 redis 中存
        这个服务有会部署多个实例，在启动时会拉取 storm task id 列表， 然后通过 zk 分布式锁，基于 id 去加锁，获取到这个 task id 节点中存储的 topn 列表， 然后读取 mysql 中的数据，存储在 redis 中
        这个服务可以是单独的服务，本课程为了方便会放在缓存服务中
# redis事务
redis的事务更像是一组命令的集合。
开启事务后我们可以同时执行一组命令，这些命令在事务执行前，不会进行入队的操作
## 1，如果事务执行时，命令集合存在书写错误，那么整个集合的命令都不会执行
- 如参数数量错误、参数名错误等等，或者其他更严重的错误，比如内存不足
- 对于这种情况，Redis早些时候会在事务执行前检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败
- 如果有命令在入队时失败，那么大部分客户端都会停止并取消这个事务
## 2，如果命令编译通过，存在运行时异常，那么其他命令仍会执行，存在异常的命令执行失败
- 比如使用 incy命令对一个非整形数据进行原子 +1操作
## 3，事务是可以取消的，事务取消，入队的命令不会执行
- 可以手动使用命令取消，也可以直接 ctrl + F4强制取消（在事务未被执行前打断施法即可
不存在原子性之外，Redis中的事务也没有隔离级别的概念


# Redis 雪崩了解吗？
热点数据的缓存都是定时任务去刷新，如果首页所有 Key 的失效时间都是某一个时间节点，这个时间大量用户涌入，这些请求全部落在了数据库上这就是缓存雪崩
每个 Key 的失效时间都加个随机值就好了，这样可以保证数据不会再同一时间大面积失效。


# Redis 穿透
缓存穿透吧，缓存穿透是指缓存和数据库中都没有的数据
而用户不断发起请求。攻击导致数据库压力很大，严重会击垮数据库。

缓存穿透我会在接口层增加校验

# Redis 击穿
某一个 Key 不停地扛着大量的请求，Key 在失效的瞬间，持续的大并发直接落到了数据库上
设置热点数据永不过期

Redis 内置了复制（Replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（Transactions） 和不同级别的磁盘持久化（Persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（High Availability）

# Redis如何进行持久化
##1，RDB
### 什么是RDB
在指定时间间隔内，将内存中的数据集快照写入磁盘，也就是Snapshot快照，它恢复时是将快照文件直接读到内存中，来达到恢复数据的。
### 会不会影响性能
Redis会单独创建(fork)一个子进程来进行持久化，会先将数据写进一个临时文件中，等到持久化过程结束了，再用这个临时文件替换上次持久化好的文件。在这个过程中，只有子进程来负责IO操作，主进程仍然处理客户端的请求，这就确保了极高的性能。
### 如何触发持久化
如何触发持久化呢？可以通过查看或者设置redis.conf配置文件来指定触发规则。
### 优点
1，如果要进行大规模数据的恢复，RDB方式要比AOF方式恢复速度要快。
2，RDB可以最大化Redis性能，父进程做的就是fork子进程，然后继续接受客户端请求，让子进程负责持久化操作，父进程无需进行IO操作。
3，RDB是一个非常紧凑(compact)的文件,它保存了某个时间点的数据集，非常适合用作备份，同时也非常适合用作灾难性恢复，它只有一个文件，内容紧凑，通过备份原文件到本机外的其他主机上，一旦本机发生宕机，就能将备份文件复制到redis安装目录下，通过启用服务就能完成数据的恢复。
### 缺点
1，RDB这种持久化方式不太适应对数据完整性要求严格的情况，因为，尽管我们可以用过修改快照实现持久化的频率，但是要持久化的数据是一段时间内的整个数据集的状态，如果在还没有触发快照时，本机就宕机了，那么对数据库所做的写操作就随之而消失了并没有持久化本地dump.rdb文件中。
2，每次进行RDB时，父进程都会fork一个子进程，由子进程来进行实际的持久化操作，如果数据集庞大，那么fork出子进程的这个过程将是非常耗时的，就会出现服务器暂停客户端请求，将内存中的数据复制一份给子进程，让子进程进行持久化操作。

## 2，AOF
### 什么是AOF
以日志的形式记录Redis每一个写操作,将Redis执行过的所有写指令记录下来（读操作不记录），只许追加文件不可以改写文件.
redis启动之后会读取appendonly.aof文件来实现重新恢复数据，完成恢复数据的工作。
默认不开启，需要将redis.conf中的appendonly  no改为yes启动Redis。
### 持久化策略
appendfsync always:每修改同步，每一次发生数据变更都会持久化到磁盘上，性能较差，但数据完整性较好。
appendfsync everysec: 每秒同步，每秒内记录操作，异步操作，如果一秒内宕机，有数据丢失。
appendfsync no:不同步。
### 数据恢复
重启Redis时，如果dump.rdb与appendfsync.aof同时都存在时，Redis会自动读取appendfsync.aof文件，通过该文件中对数据库的日志操作，来实现数据的恢复
### 重写
当然如果AOF 文件一直被追加，这就可能导致AOF文件过于庞大。因此，为了避免这种状况，Redis新增了重写机制，当AOF文件的大小超过所指定的阈值时，Redis会自动启用AOF文件的内容压缩，只保留可以恢复数据的最小指令集，可以使用命令bgrewiteaof。
### 优点
1，AOF有着多种持久化策略
2，AOF文件是一个只进行追加操作的日志文件，对文件写入不需要进行seek，即使在追加的过程中，写入了不完整的命令（例如：磁盘已满），可以使用redis-check-aof工具可以修复这种问题
3，Redis可以在AOF文件变得过大时，会自动地在后台对AOF进行重写：重写后的新的AOF文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为Redis在创建AOF文件的过程中，会继续将命令追加到现有的AOF文件中，即使在重写的过程中发生宕机，现有的AOF文件也不会丢失。一旦新AOF文件创建完毕，Redis就会从旧的AOF文件切换到新的AOF文件，并对新的AOF文件进行追加操作。
4，AOF文件有序地保存了对数据库执行的所有写入操作。这些写入操作一Redis协议的格式保存，易于对文件进行分析；例如，如果不小心执行了FLUSHALL命令，但只要AOF文件未被重写，通过停止服务器，移除AOF文件末尾的FLUSHALL命令，重启服务器就能达到FLUSHALL执行之前的状态。
### 缺点
1，对于相同的数据集来说，AOF文件要比RDB文件大。
2，根据所使用的持久化策略来说，AOF的速度要慢与RDB。一般情况下，每秒同步策略效果较好。不使用同步策略的情况下，AOF与RDB速度一样快。

## 3，AOF
1，一般来说，如果想达到足以媲美PostgreSQL的数据安全性，应该同时使用两种持久化方式。
2，有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快， 除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的 bug。
3，如果可以承受输分钟内的数据丢失，可以只使用RDB持久化。

# Redis为什么是单线程还那么快
1，Redis是基于内存实现的，数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
2，数据结构简单，对数据的操作也简单
3，采用单线程，避免了不必要的上下文切换，不用考虑锁的问题。
4，Redis的多路复用机制

# Redis的多路复用机制
多路指的是网络连接，复用指的是同一个线程。
一个线程监听多个IO事件，当有IO事件就绪时，就会通知相应的线程去执行相应的读写操作
没有就绪事件时就会交出cpu。

## select 机制
### 基本原理：
客户端操作服务器时就会产生这三种文件描述符(简称 fd)：writefds(写)、readfds(读)、和 exceptfds(异常)。select 会阻塞住监视 3 类文件描述符，等有数据、可读、可写、出异常 或超时、就会返回；
返回后通过遍历 fdset 整个数组来找到就绪的描述符 fd，然后进行对应的 IO 操作。
### 优点：
几乎在所有的平台上支持，跨平台支持性好。
### 缺点：
1.由于是采用轮询方式全盘扫描，会随着文件描述符 FD 数量增多而性能下降。
2.每次调用 select()，需要把 fd 集合从用户态拷贝到内核态，并进行遍历(消息传递都是从内核到用 户空间)
3.默认单个进程打开的 FD 有限制是 1024 个，可修改宏定义，但是效率仍然慢。
## poll 机制：
## 基本原理：
基本原理与 select 一致，也是轮询+遍历；唯一的区别就是 poll 没有最大文件描述符限制（使用链表的方式存储 fd）。

## epoll 机制：
### 基本原理
没有 fd 个数限制，用户态拷贝到内核态只需要一次，使用时间通知机制来触发。通过 epoll_ctl 注册 fd，一旦 fd 就绪就会通过 callback 回调机制来激活对应 fd，进行相关的 io 操作。
### 优点：
1.没 fd 这个限制，所支持的 FD 上限是操作系统的最大文件句柄数，1G 内存大概支持 10 万个句柄
2.效率提高，使用回调通知而不是轮询的方式，不会随着 FD 数目的增加效率下降
3.内核和用户空间 mmap 同一块内存实现(mmap 是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间).

# redis集群三种模式
    1，主从复制
        概述
            主从复制是指将redis主节点（master）的数据复制到从节点（slave）
            数据复制是单向的，只能从主节点复制到从节点
            默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。
        作用
            1，容灾恢复
                当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。
            2，负载均衡
                在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
            3，数据冗余
                实现数据热备份，是持久化之外的一种数据冗余方式
        原理
            全量同步
                1，从服务器连接主服务器，发送sync命令
                2，主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 
                3，主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 
                4，从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 
                5，主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
                6，从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；
            部分同步
                从redis 2.8版本以前，并不支持部分同步，当主从服务器之间的连接断掉之后，master服务器和slave服务器之间都是进行全量数据同步，
                但是从redis 2.8开始，即使主从连接中途断掉，也不需要进行全量同步，可以进行部分同步
                1，master服务器内存中给每个slave服务器维护了一份同步日志和同步标识
                2，每个slave服务器在跟master服务器进行同步时都会携带自己的同步标识和上次同步的最后位置
                3，当主从连接断掉之后，slave服务器隔断时间（默认1s）主动尝试和master服务器进行连接
                4，如果从服务器携带的偏移量标识还在master服务器上的同步备份日志中，那么就从slave发送的偏移量开始继续上次的同步操作
                5，如果slave发送的偏移量已经不再master的同步备份日志中（可能由于主从之间断掉的时间比较长或者在断掉的短暂时间内master服务器接收到大量的写操作），则必须进行一次全量更新
                6，在部分同步过程中，master会将本地记录的同步备份日志中记录的指令依次发送给slave服务器从而达到数据一致。
            增量同步
                主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。
        注意点：
            1，如果多个Slave断线了，需要重启的时候，因为只要Slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致Master IO剧增宕机。
            2，多个从服务器连接到一个主服务器之外，多个从服务器也可以连接到一个从服务器上，形成一个图状结构。
            3，Redis使用异步复制。但从Redis 2.8开始，从服务器会周期性的应答从复制流中处理的数据量。
            4，Redis主从复制不阻塞主服务器端。也就是说当若干个从服务器在进行初始同步时，主服务器仍然可以处理请求。
            5，主从复制也不阻塞从服务器端。当从服务器进行初始同步时，它使用旧版本的数据来应对查询请求，假设你在redis.conf配置文件是这么配置的。
            否则的话，你可以配置当复制流关闭时让从服务器给客户端返回一个错误。
            但是，当初始同步完成后，需要删除旧的数据集和加载新的数据集，在这个短暂的时间内，从服务器会阻塞连接进来的请求。
            6，使用主从复制可以为主服务器免除把数据写入磁盘的消耗：在主服务器的redis.conf文件中配置“避免保存”（注释掉所有“保存“命令），然后连接一个配置为“进行保存”的从服务器即可
        具体使用
            主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。
            从节点开启主从复制，有3种方式：
            (1) 配置文件
                在从服务器的配置文件中加入：slaveof <masterip> <masterport>
            (2) 启动命令
                redis-server启动命令后加入 --slaveof <masterip> <masterport>
            (3) 客户端命令
                Redis服务器启动后，直接通过客户端执行命令：slaveof <masterip> <masterport>，则该Redis实例成为从节点。
        缺点
            1，Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（也就是要人工介入）；
            2，主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性（需要手动将一台slave切换成master）；
            3，如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。
            4，Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；
    2，Sentinel（哨兵模式）
        概述
            哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令
            哨兵是一个独立的进程，作为进程，它会独立运行。
            其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个 Redis 实例。
        作用
            1，通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器；
            2，当哨兵监测到 master 宕机，会自动将 slave 切换成 master ，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机；
        一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。
        原理
            1，每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave 从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
            2，如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
            3，如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态
            4，当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为客观下线（ODOWN）
            5，在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有 Master 主服务器、Slave 从服务器发送 INFO 命令。
            6，当 Master 主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master 主服务器的所有 Slave 从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
            7，若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master 主服务器的客观下线状态就会被移除。若 Master 主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。
        优点
           哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
           主从可以自动切换，系统更健壮，可用性更高(可以看作自动版的主从复制)。
        缺点
            Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。
        配置过程
            1，配置Redis的主从服务器，修改redis.conf文件
                # 使得Redis服务器可以跨网络访问
                bind 0.0.0.0
                # 设置密码
                requirepass "123456"
                # 指定主服务器，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置
                slaveof 192.168.11.128 6379
                # 主服务器密码，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置
                masterauth 123456
                上述内容主要是配置Redis服务器，从服务器比主服务器多一个slaveof的配置和密码。
            2，配置3个哨兵，每个哨兵的配置都是一样的。在Redis安装目录下有一个sentinel.conf文件，copy一份进行修改
                # 禁止保护模式
                protected-mode no
                # 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。
                sentinel monitor mymaster 192.168.11.128 6379 2
                # sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码
                # sentinel auth-pass <master-name> <password>
                sentinel auth-pass mymaster 123456
                上述关闭了保护模式，便于测试。
            3，有了上述的修改，我们可以进入Redis的安装目录的src目录，通过下面的命令启动服务器和哨兵
                # 启动Redis服务器进程
                ./redis-server ../redis.conf
                # 启动哨兵进程
                ./redis-sentinel ../sentinel.conf
                注意启动的顺序。首先是主机（192.168.11.128）的Redis服务进程，然后启动从机的服务进程，最后启动3个哨兵的服务进程。
    3，Cluster
        redis最开始使用主从模式做集群，若master宕机需要手动配置slave转为master。
        后来为了高可用提出来哨兵模式，该模式下有一个哨兵监视master和slave，若master宕机可自动将slave转为master
        但是他也有一个问题，就是不能动态扩容，哨兵模式还是只有一个master；所以在3.x提出了cluster集群模式
        概述
            Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。
            多主多从，去中心化：从节点作为备用，复制主节点，不做读写操作，不提供服务
            不支持处理多个key：因为数据分散在多个节点，在数据量大高并发的情况下会影响性能；
            支持动态扩容节点：这是我认为算是Rerdis Cluster最大的优点之一；
            节点之间相互通信，相互选举，不再依赖sentinel：准确来说是主节点之间相互“监督”，保证及时故障转移
            所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。
            节点的fail是通过集群中超过半数的节点检测失效时才生效。
            客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。
        与其他集群区别
            1，相比较sentinel模式，多个master节点保证主要业务（比如master节点主要负责写）稳定性，不需要搭建多个sentinel实例监控一个master节点；
            2，相比较一主多从的模式，不需要手动切换，具有自我故障检测，故障转移的特点；
            3，相比较其他两个模式而言，对数据进行分片（sharding），不同节点存储的数据是不一样的；
            4，从某种程度上来说，Sentinel模式主要针对高可用（HA），而Cluster模式是不仅针对大数据量，高并发，同时也支持HA
        如何实现数据分片
            redis-cluster把所有的物理节点映射到[0-16383]slot上（不一定是平均分配）,cluster 负责维护node<->slot<->value。
            现在我们是三个主节点分别是：A, B, C 三个节点，它们可以是一台机器上的三个端口，也可以是三台不同的服务器。那么，采用哈希槽 (hash slot)的方式来分配16384个slot 的话，它们三个节点分别承担的slot 区间是：
                节点A覆盖0－5460;
                节点B覆盖5461－10922;
                节点C覆盖10923－16383.
            获取数据:
                如果存入一个值，按照redis cluster哈希槽的算法： CRC16('key')384 = 6782。 那么就会把这个key 的存储分配到 B 上了。同样，当我连接(A,B,C)任何一个节点想获取'key'这个key时，也会这样的算法，然后内部跳转到B节点上获取数据
            新增一个主节点:
                新增一个节点D，redis cluster的这种做法是从各个节点的前面各拿取一部分slot到D上，我会在接下来的实践中实验。大致就会变成这样：
                    节点A覆盖1365-5460
                    节点B覆盖6827-10922
                    节点C覆盖12288-16383
                    节点D覆盖0-1364,5461-6826,10923-12287
                同样删除一个节点也是类似，移动完成后就可以删除这个节点了。
                
        Redis Cluster主从模式
            redis cluster 为了保证数据的高可用性，加入了主从模式，一个主节点对应一个或多个从节点，主节点提供数据存取，从节点则是从主节点拉取数据备份，当这个主节点挂掉后，就会有这个从节点选取一个来充当主节点，从而保证集群不会挂掉
            上面那个例子里, 集群有ABC三个主节点, 如果这3个节点都没有加入从节点，如果B挂掉了，我们就无法访问整个集群了。A和C的slot也无法访问。
            所以我们在集群建立的时候，一定要为每个主节点都添加了从节点, 比如像这样, 集群包含主节点A、B、C, 以及从节点A1、B1、C1, 那么即使B挂掉系统也可以继续正确工作。
            B1节点替代了B节点，所以Redis集群将会选择B1节点作为新的主节点，集群将会继续正确地提供服务。 当B重新开启后，它就会变成B1的从节点。
            不过需要注意，如果节点B和B1同时挂了，Redis集群就无法继续正确地提供服务了。
# 懂Redis事务么？
    我们在生产上采用的是Redis Cluster集群架构，不同的key是有可能分配在不同的Redis节点上的，在这种情况下Redis的事务机制是不生效的。其次，Redis事务不支持回滚操作，简直是鸡肋！所以基本不用！
# Redis集群机制中，你觉得有什么不足的地方吗？
    假设我有一个key，对应的value是Hash类型的。如果Hash对象非常大，是不支持映射到不同节点的！只能映射到集群中的一个节点上！还有就是做批量操作比较麻烦！
# 懂Redis的批量操作么？
    我们在生产上采用的是Redis Cluster集群架构，不同的key会划分到不同的slot中，因此直接使用mset或者mget等操作是行不通的。
# 那在Redis集群模式下，如何进行批量操作？
    如果执行的key数量比较少，就不用mget了，就用串行get操作
    如果真的需要执行的key很多，就使用Hashtag保证这些key映射到同一台redis节点上。简单来说语法如下
        对于key为{foo}.student1、{foo}.student2，{foo}student3，这类key一定是在同一个redis节点上。
        因为key中“{}”之间的字符串就是当前key的hash tags， 只有key中{ }中的部分才被用来做hash，因此计算出来的redis节点一定是同一个
# 有对Redis做读写分离么？
    不做读写分离。我们用的是Redis Cluster的架构，是属于分片集群的架构。而redis本身在内存上操作，不会涉及IO吞吐，即使读写分离也不会提升太多性能。
    Redis在生产上的主要问题是考虑容量，单机最多10-20G，key太多降低redis性能.因此采用分片集群结构，已经能保证了我们的性能。
    其次，用上了读写分离后，还要考虑主从一致性，主从延迟等问题，徒增业务复杂度。

# redis热点数据问题
怎么发现热key
    1，凭借经验预估那些是热key，比如某商品在做秒杀，那就可以判断出热key
    2，在客户端收集
        在操作redis之前，加入一行代码进行数据统计。但是缺点就是对客户端代码造成入侵
    3，在proxy层收集
        有些集群架构使用proxy作为统一入口。例如Twemproxy作为统一入口，在proxy层收集上报，但是缺点明显，并非所有的redis集群都有proxy
    4，使用redis自带命令
        (1)monitor命令
            该命令可以实时抓取redis服务器收到的命令，然后写代码统计出热点key是什么。
            当然，也有现成的分析工具，比如redis-faina。但是该命令在高并发条件下，有内存暴增的隐患，还会降低redis性能
        (2)hotkeys参数
            redis4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上-hotkeys选项即可
            但是该参数执行的时候，如果key比较多，执行起来比较慢
    5，自己抓包评估
        redis客户端使用tcp协议和服务端进行交互，通信协议采用的是resp。自己写程序监听端口，按照resp协议规则解析数据，进行分析
如何解决热点key
    1，利用二级缓存
        比如利用ehcache，或者一个HashMap都可以。在发现热key以后，把热key加载到系统的jvm中
        针对这种热key数据，会直接从jvm中取，而不会走到redis
        （假设此时有十万个针对同一个key请求过来，如果没有本地缓存，这10万个请求就会直接怼到同一台redis上
        现在假设，应用层有50台机器，那么这10万个请求平均分散开来，每个机器有2000个请求，会从jvm中取到value返回数据）
    2，备份热key
        这个方案简单。不要让key走到同一台redis上就可以了。我们把这个key，在多个redis上都存一份
        接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值
行业中是怎么发现热key，然后自动处理的
    1，监控热key
        (1)比较认可的方式二：在客户端进行收集（TMC）
            TMC对原生jedis包的Jedis和JedisPool类做了改造，在JedisPool初始化过程中集成TMC（热点发现+本地缓存）
            也就是说改写了jedis原生jar包，加入了Hermes-SDK包。从监控角度看，该包对于Jedis-Client的每次key值请求访问
            Hermes-SDK都会通过其他通信模块将key访问事件异步上报给Hermes服务端集群以便根据上报数据进行"热点探测"
        (2)自己抓包评估
            利用flink或者storm搭建一套流式计算系统。然后自己写一个抓包程序抓redis监听端口的数据，抓到的数据往kafka里面丢
            接下来，流式计算系统消费kafka里的数据，进行数据统计即可，也能达到监控热key的目的
    2，通知系统处理
        (1)如果使用的是Hermes-SDK的话，利用的是二级缓存进行处理
            在监控到热点key后，Hermes服务端集群会通过各种手段通知各个业务系统里的Hermes-SDK，告诉他们做好本地缓存
            于是Hermes-SDK就会将该key缓存在本地，对于后面的请求。Hermes-SDK发现是一个热key，直接从本地拿，不回去访问集群
        (2)如果采用流式计算
            监控到热key后，往zookeeper里的某个节点写。然后业务系统监听该节点，发现节点数据变化了，就代表发现热key，最后往本地缓存里写
            
# redis实现实时热点统计和分布式缓存预热
问题
    由于缓存冷启动，redis一点数据都没有，直接就对外提供服务，mysql就裸奔了
    1，提前给redis中灌入部分数据，再提供服务
    2，数据量太大，无法将所有数据放入redis
        耗费时间过长
        redis无法容纳所有的数据
    3，根据当天具体访问情况，实时统计出访问频率较高的热数据
        然后将访问频率较高的热数据写入redis中，肯定数据也比较多，我们也得多个服务并行读数据去写，并行的分布式缓存预热
    4，都准备好后，对外提供服务
具体步骤：
    1，nginx +lua 将访问流量上报到 kafka 中
        要统计出当前最新的实时的热数据是那些，我们就得将商品详情页访问的请求对应的流量 日志实时上报到 kafka 中
        
    2，storm从kafka中消费数据，实时统计访问次数
        访问次数基于lru内存数据结构的存储方案
        计算好每个 task 大致要存放的商品访问次数的数量，计算出大小， 然后构建一个 LRU MAP，它能够给你一个剩下访问次数最多的商品列表，访问高的才能存活
        LRU MAP 有开源的实现，apach commons collections 中有提供，设置好 map 的最大大小
        就会自动根据 LRU 算法去剔除多余的数据，保证内存使用限制， 即时有部分数据被干掉了，下次会从 0 开始统计，也没有关系，因为被 LRU 算法干掉了， 
        就表示它不是热数据，说明最近一段时间都很少访问了，热度下降了
    3，每个 Storm task 启动时，基于 zk 分布式锁，将自己的 ID 写入 zk 同一个节点中
       这个 id 写到一个固定节点中，形成一个 task id 列表， 后续可以通过这个 id 列表去拿到对于 task 存储在 zk node 上的 topn 列表
    4，每个 Storm task 负责完成自己这里的热数据统计。比如每隔一段时间，就遍历下这个 map，维护并更新一个前 n 个商品的 list
    5，定时同步到 zk 中去
        写一个后台线程，每隔一段时间，比如 1 分钟，将这个 task 所有的商品排名算一次 将排名前 n 的热数据 list 同步到 zk 中去
    6，需要一个服务，根据 top n 列表在 mysql 中获取数据往 redis 中存
        这个服务有会部署多个实例，在启动时会拉取 storm task id 列表， 然后通过 zk 分布式锁，基于 id 去加锁，获取到这个 task id 节点中存储的 topn 列表， 然后读取 mysql 中的数据，存储在 redis 中
思路总结：
    1，使用 stom 实时计算出最近一段时间内的 n 个 topn 列表，并存储在 zk task id 节点上
    2，多服务通过 task id 进行分布式锁，获取 topn 列表，去 mysql 拉取数据放入 redis 中
    3，由于对 storm 不熟悉，这里的思路看来，只是利用了 storm 能创建大量并行的 task 和数据分组策略， 来让大量的访问日志分发到 n 个 task 中，让 storm 这种抗住大量并发访问量的计算能力， 注意这里是计算出 n 个 topn 列表，也就是大量的热数据。而不是唯一的一份 topn 列表， 而且是最近一段时间内的（之前一直想不通 storm 怎么能达到实时计算？原来是通过这种分而治之方式 + 分段时间来重复计算自己负责的部分结果数据实现的，就是不知道 storm 其他的使用场景也是这样的吗？）
      也想知道如果想维护一个全局的排行榜名单的话，用 storm 应该怎么做？这个数据量就很大了， 比如淘宝的双 11 的秒级统计成交金额

# redis哨兵模式
Redis Sentinel为redis提供了高可用解决方案。实际上这意味着使用Sentinel可以部署一套redis，在没有认为干预的情况下去应付各种失败事件
功能列表：
    监控（Monitoring）：sentinel不断检查主从实例是否按照预期在工作
    通知（notification）：sentinel可以通过一个api来通知系统管理员或者另外的应用程序，被监控的redis实例有问题
    自动转移故障（automatic failover）：如果一个主节点没有按照预期工作，Sentinel会开始故障转移，把一个从节点升为主节点，并重新配置其他的从节点使用新的主节点，使用redis服务的应用程序在连接的时候也被通知新的地址
    配置提供者（Configuration provider）：sentinel给客户端的服务发现提供来源：对于一个给定的服务，客户端连接到sentinels来寻找当前主节点的地址。当故障转移发生的时候，sentinel将报告新的地址
sentinel分布式特性
    redis sentinel是一个分布式系统，sentinel运行在许多sentinel进程互相合作的环境下，它本身就是这样被设计的。有许多sentinel进程相互合作的优点如下：
        1，当多个sentinel同意一个master不再可用的时候，就执行故障检测。这明显降低了错误概率
        2，即使并非全部的sentinel在工作，sentinel也可以正常工作，这种特性让系统很健康

# redis双写一致性









