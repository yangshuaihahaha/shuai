# 核心表单技术难点
1，保存表单
2，如果表单是verify，那么改为submit状态（attribute属性）
3，如果有签名签名，使得签名失效（attribute属性）
4，更新visit的信息（关联的表单数量）
5，patient信息更新（签名状态，是否填写表单状态）
6，Execute crf script after submit encounter（自定义脚本的执行）
7，发送信息进行auto verification（生成对应的query）
8，更新location下面表单数量
在更新表单数量的时候会有mysql的行锁，那么并发量就上不去。
那么我们就使用了一个队列，然后把更新location数量的请求放到这个队列里面，然后每200毫秒提交一次队列进行location表单数量的更新
这个队列也只有在并发量比较高的时候会创建。

如果表单保存失败后会发送消息给location端进行表单计数的增加或者删除。


# 采用Nginx + Redis集群 + JVM堆缓存 + 大数据热点侦测构建支撑亿级流量的多级缓存架构
探测热点数据
热数据是什么？
    系统中用户可以根据自己录入的表单数据，首先会通过kafka消息队列转成横表，然后利用superset生成对应各种图表分析数据
    我们会将这些图表数据的原始结构保存起来，每个用户都会对应很多的图表数据。
    而nginx中只会缓存热点数据，热点数据就是每个用户点击查看次数比较多的这些热点图表
    redis会缓存所有的图表数据。
热点数据探测
    1，nginx+lua将访问流量上报到kafka中
    2，flink从kafka中消费数据，实时统计访问次数
        其实我们的需求就是：统计出每个study中最近一段时间访问最频繁的图表是哪些，进行访问计数， 同时维护出一个前 N 个访问最多的图表Id list 即可
        也就是热数据：最近一段时间（如最近 1 小时），访问超过 1 千次图表， 统计这段时间内每个商品的访问次数，排序后做出一个 top n 列表
        计算好每个 task 大致要存放的商品访问次数的数量，计算出大小， 然后构建一个 LRU MAP，它能够给你一个剩下访问次数最多的商品列表，访问高的才能存活
        LRU MAP 有开源的实现，apach commons collections 中有提供，设置好 map 的最大大小， 就会自动根据 LRU 算法去剔除多余的数据，保证内存使用限制， 即时有部分数据被干掉了，下次会从 0 开始统计，也没有关系，因为被 LRU 算法干掉了， 就表示它不是热数据，说明最近一段时间都很少访问了，热度下降了
    3，然后会把这些数据top n 列表存放到redis中
nginx缓存热点数据
    将storm统计处认定为热点的数据上报到流量分发层nginx
    通过http将统计出的热点数据发送至流量分发层nginx上，通过lua脚本去处理这个请求，并将商品列表放至本地缓存中，
    同时storm会将热点数据对应的完整缓存发送至所有的应用层nginx服务器上去，并放至本地缓存中
nginx获取缓存数据
    1，应用 Nginx 的 Lua脚本接收到请求
    2，获取请求参数中的商品id，以及商品店铺id
    3，根据 商品id 和 商品店铺id，在 Nginx 本地缓存中尝试获取数据
    4，如果在 Nginx本地缓存中没有获取到数据，那么就到 Redis分布式缓存中获取数据，如果获取到数据，会判断是否是热点数据，如果是的话还会设置到 Nginx本地缓存中

# netty各个国家数据同步


mysql性能调优具体
jvm调优具体
接口安全机制

网关模块重构
数据导出优化
kafka发送消息将横表转成纵表，利于superset分析