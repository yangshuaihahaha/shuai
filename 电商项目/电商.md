# 1， 整体架构图
1，nginx集群访问项目
2，进入webflux网关（使用的是springcloud gateway），网关根据请求动态路由到指定的服务
如果一个结构在好几个请求里面都存在，那么也可以通过ribbon进行负载均衡
如果服务出现问题使用sentinel进行服务熔断降级，限流
网关还进行认证授权
3，当请求到达微服务集群，集群使用feign进行相互调用。
微服务登陆校验使用的是Spring Security Oauth2
配置中心和注册中心都是nacos

除了一般的登陆还集成了社交登陆
4，缓存用的是redis的分片集群和哨兵集群
5，持久化用的是mysql集群，有读写分离，和独库独表
6，使用rabbitmq消息队列
7，全文检索ES
8，图片存储用的是oss
9，日志存储用的是ELK（ES、kibana、LogStash）
10，服务追踪（sleuth、zipkin、metrics）交给promethrus进行聚合分析，再由grafana进行可视化展示，
同时promethrus还会有告警信息发送邮件
11，使用kuberneturs集成

# 2，前期服务搭建
可以使用vagrant来初始化一个centos镜像，结合virtual VM来使用
vagrant init centos//初始化
vagrant up//生成或者启动虚拟机
vagrant ssh//连接虚拟机
虚拟机网络配置：
    启动之后可以通过配置Vagrantfile这个文件来中的 config.vm.network "private_network", ip: "192.168.33.10"
    来解决端口转发的问题

然后使用docker安装mysql
docker之间的容器是相互隔离的，每个镜像都相当于一个小的linux环境

docker run -p 3306:3306 -name mysql \
-v /mydata/mysql/log:/var/log/mysql \
-v /mydata/mysql/data:/var/lib/mysql \
-v /mydata/mysql/conf:/etc/mysql \
-e MYSQL_ROOT_PASSWORD=root \
-d mysql:5.7

这是用来启动mysql的
-p 3306:3306 将容器的3306端口映射到主机的3306端口
/mydata/mysql/log:/var/log/mysql ： 将日志文件挂载到主机
/mydata/mysql/data:/var/lib/mysql ：将数据文件挂载到主机
/mydata/mysql/conf:/etc/mysql ：将配置文件挂在到主机

redis也一样需要将一些文件挂载到虚拟机服务器

# 快速开发人人开发搭建后端开发平台
主要有的微服务是
    gulimall-coupon
    gulimall-member
    gulimall-order
    gulimall-producr
    gulimall-ware
    gulimall-common //用来存放公用的类，公共依赖
然后使用
    renren-fast搭建管理系统的后端
    renren-fast-vue搭建管理系统的后端
    renren-generator生成各个微服务的基本代码
    
# 微服务的nacos注册中心
1，下载并启动nacos服务器 
2，引入nacos依赖，到公共模块gulimall-common
    <dependency>
        <groupId>com.alibaba.cloud</groupId>
        <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
    </dependency>
3，在application.properties配置nacos的端口号和地址
    spring.cloud.nacos.discovery.server-addr=127.0.0.1:8848
4，在入口使用@EnableDiscoveryClient注解启用nacos
    @SpringBootApplication
    @EnableDiscoveryClient
    public class NacosProviderDemoApplication {
       public static void main(String[] args) {
           SpringApplication.run(NacosProducerDemoApplication.class, args);
       }
       @RestController
       public class EchoController {
           @GetMapping(value = "/echo/{string}")
           public String echo(@PathVariable String string) {
               return "Hello Nacos Discovery " + string;
           }
       }
    }

# 测试会员服务调用优惠券服务
1，概述
获取某个会员所有的优惠券
会员服务（gulimall-member）去注册中心nacos找一下优惠券服务（gulimall-coupon）在那一些机器，得到机器后挑一台机器发送请求来获取数据
服务之间远程点用使用的是feign

2，什么是feign
feign是一个声明式的http客户端，它的目的就是让远程调用更简单。feign提供了http请求的模版，通过编写简单的接口和注解插入，
就可以定义好http请求参数、格式、地址等信息
feign整合了ribbon（负载均衡）和hystrix（服务熔断），可以让我们不需要显式的使用这两个组件
springcloudfeign在netflixfeign的基础上扩展了对springmvc注解的支持，在其实现下，我们只需要创建一个接口并用注解的方式来配置它，即可完成对服务提供方接口绑定
简化了springcloudribbon自行封装服务调用客户端的开发量

2，feign使用
(1) 引入依赖open-feign
    <dependency>
        <groupId>org.springframework.cloud</groupId>
        <artifactid>spring-cloud-starter-openfeign</artifactid>
    </dependency>
(2) 编写一个接口表示需要调用远程服务(在gulimall-member中编写)
    @FeignClient("gulimall-coupon")
    public interface CouponFeignService {
        @RequestMapping("/coupon/coupon/member.list")
        public R membercoupons();
    }
(3) 开启feign
    @EnableFeignClients(basePackages="com.atguigu.gulimall.member.feign")
    @SpringBootApplication
    @EnableDiscoveryClient
    public class GulimallMemberApplication {
       public static void main(String[] args) {
           SpringApplication.run(GulimallMemberApplication.class, args);
       }
    }
    
# nacos作为配置中心
bootsreap.properties会优先于application.properties加载
1，导入依赖
    <dependency>
        <groupId>org.alibaba.cloud</groupId>
        <artifactid>spring-cloud-starter-alibaba-nacos-config</artifactid>
    </dependency>
2，在应用/src/main/resources/bootsreap.properties配置文件中配置Nacos Config元数据
    spring.application.name=gulimall-coupon //名字
    spring.cloud.nacos.config.server-addr=127.0.0.1:8848 //nacos服务器地址
3，需要给配置中心默认添加一个叫 数据集 gulimall-coupon.properties（应用名.properties）
    然后就可以在nacos的服务端添加gulimall-coupon.properties添加配置信息
    对应的controller加上@RefreshScope 来动态获取并刷新配置
    @Value("${配置项}")来获取配置
    如果配置中心和当前应用的配置文件都配置了相同项，优先使用配置中心的配置
    细节
        (1) 命名空间
            做环境隔离（dev、test、prod）
                gulimall-coupon.properties默认是在public（保留的命名空间）里面，但是如果我们有开发、测试、生产环境那么怎么能用同一个呢？
                我们可以在nacos服务端配置中心配置多个命名空间test、dev、prod。在不同的命名空间下面创建gulimall-coupon.properties
                然后在对应微服务bootsreap.properties的配置文件配置，指定对应的命名空间
                    spring.cloud.nacos.config.namespace=6b31e642-4adb-449e-a038-314c5934b564
            微服务之间的相互配置隔离，每个微服务都有自己创建的命名空间  
        (2) 配置组  
             新增的配置文件都有一个组别，比如双十一的时候就用1111分组，618的时候用618分组
             在bootsreap.properties加上spring.cloud.nacos.config.group=1111来配置分组
        建议使用：为每个微服务创建自己的命名空间，使用配置分组来区分dev、test、prod
        (3) 加载多个配置文件
            我们把所有的文件放在一个配置文件中会显得凌乱，所以需要分开存放多个配置文件，比如datasource.ymc、mybaties.properties等等这样的话怎么来加载这些配置文件呢？
            spring.cloud.nacos.config.ext-config[0].data-id=datasource.yml
            spring.cloud.nacos.config.ext-config[0].group=dev
            spring.cloud.nacos.config.ext-config[0].refresh=true

# 关于gateway
网关作为流量的入口，常用的功能包括路由转发、权限校验、限流控制等。而Springcloud Gateway作为 springcloud官方推出的第二代网关框架，取代了zull网关

基本流程就是请求到达网关，网关根据断言判断路由是否符合规则， 如果符合了路由到指定的服务器，当然这中间会经过一系列的filter

网关使用的是netty做的而不是tomcat

需要单独创建一个单独的module，gulimall-gatway，然后依赖common工程
然后开启服务注册发现，配置注册中心地址，配置中心地址
    @EnableDiscoveryClient
    @SpringBootApplication
    public class GulimallGatewayApplication {
        public static void main(String[] args) {
            SpringApplication.run(GulimallGatewayApplication.class, args);
        }
    }

然后在这个工程下面创建application.yml文件，并进行配置
spring:
    cloud:
        gatwey:
            routes:
                - id: baidu_route
                  uri: https://www.baidu.com
                  predicates:
                    - Query=url,baidu
                - id: qq_route   
                  uri: https://www.qq.com
                  predicates:
                    - Query=url,qq 

# 前端vue
```html
<div id='app'>
    <!--事件处理-->
    <button v-on:click="num++">点赞</button>
    <button v-on:click="cancle">取消</button>
    <!--双向绑定-->
    <input type="text" v-model="num"/>
    <!-- 声明式渲染-->
    <h1>{{name}}, 非常帅, 有{{num}}为他点赞</h1>
    <!--html原生显示和解析显示-->
    <span v-html="msg"></span>
    <span v-text="msg"></span>
    <!--给html属性绑定-->
    <a v-bind:href="link">gogogo</a>
    <!--class,style-->
    <span v-bind:class="{active:isActive,'text-danger':hasError}">你好</span>
    <span v-bind:style="{color:color1,'font-size':fontSize1}">你好</span>
    
    <!--表单项-->
    精通的语言：
        <input type="checkbox" v-model="" value="java"/> java<br/>
        <input type="checkbox" value="php"/> php<br/>
        <input type="checkbox" value="python"/> php<br/>
    选中了{{language.join(',')}}


    <!--阻止事件冒泡和默认事件-->
    <!--大div只点击一次-->
    <div @click.once="hello">
        <!--阻止事件冒泡-->
        <div @click.stop="hello">
            <!--阻止默认事件发生-->
            <a href="http://www.baidu.com" @click.prevent>去百度</a>
            <!--阻止默认事件后执行hello-->
            <a href="http://www.baidu.com" @click.prevent="hello">去百度</a>
            <!--阻止默认事件发生，阻止冒泡后执行hello-->
            <a href="http://www.baidu.com" @click.prevent.stop="hello">去百度</a>
        </div>
    </div>
    


    <!--按键修饰符-->
    <input type="text" v-model="num" v-on:keyup.up="num+=2" @keyup.down="num-=2" @click.ctrl="num=10" />



    <!--遍历循环-->
    <ul>
        <li v-for="user in users">
            {{user.name}}
        </li>
    </ul>
    <!--获取下标-->
    <ul>
        <li v-for="(user,index) in users" :key="user.name">
            {{user.name}} - {{index}}
            <span v-for="(v, k, i) in user">
                {{k}} ------ {{v}} ------ {{i}}
            </span>
        </li>
    </ul>
    <!--建议在遍历的时候，都设置一个key，提高遍历渲染效率！！！
        key值是不可重复的，如果没有合适的值就设置为角标index-->
    <ul>
        <li v-for="(num, index) in nums" :key="index">
            {{num}}
        </li>
    </ul>
    
    <!--条件判断-->
    <button @click="show = !show"></button>
    <h1 v-if="show">if - 显示</h1>
    <h1 v-show="show">show - 显示</h1>
    
    <h1 v-if="random>1">random大于1</h1>
    <h1 v-else-if="random>2">random大于2</h1>
    <h1 v-else-if="random>3">random大于3</h1>
    <h1 v-else>大于4</h1>

    <!--计算属性-->
    <ur>
        <li>西游记，价格：{{xyjPrice}}, 数量：<input type="number" v-model="xyjNum"></li>
        <li>水浒传，价格：{{shzPrice}}, 数量：<input type="number" v-model="shzNum"></li>
        <li>总价：{{totalPrice}}</li>
    </ur>

    <!--过滤器-->
    <ul>
        <li v-for="user in users" :key="user.name">
            <!--管道过滤器-->
            {{user.name}} --  {{user.gender | genderFilter}}
            {{user.name}} --  {{user.gender | gFilter}}
        </li>
    </ul>
</div>
<script>
Vue.filter('gFilter', function(val) {
    if (val == 1) {
        return "男";
    } else {
        return "女";
    }
})
let vm = new Vue({
    el: '#app',
    data: {
        name:'张三',
        num: 1,
        msg: '<h1>Hello</h1>',
        link: 'http://www.baidu.com',
        isActive: true,
        hasError:true,
        color1: red,
        fontSize1: 80px,
        language: [],
        xyjNum: 1,
        shzNum: 1
    },
    methods: {
        cancle() {
            this.num--;
        },
        hello() {
            alert('hello')
        },
        // 计算属性
        computed: {
            totalPrice() {
                return this.xyjPrice*this.xyjNum + this.shzPrice*this.shzNums
            }       
        },
        // 监听器
        watch: {
            xyjNum: function(newval, oldval) {
                if (newval > 3) {
                   alert(newval + "-" + oldval);
                }                 
            }
        }  
        // 过滤器
        filters: {
            genderFilter(val) {
                if (val == 1) {
                    return "男";
                } else {
                    return "女";
                }
            }
        }   
    }
})
</script>



<!--vue组件化-->
<div id="app">
    <button v-on:click="count++">我被点击了 {{count}} 次</button>
    <counter></counter>
    <button-counter></button-counter>
</div>
<script>
    //1,全局声明注册一个组件
    Vue.component('counter', {
        template: `<button v-on:click="count++">我被点击了 {{count}} 次</button>`,
        data() {
            return {
                count: 1
            }
        }
    })
    //1,局部声明注册一个组件
    const buttonCounter = {
        template: `<button v-on:click="count++">我被点击了 {{count}} 次</button>`,
        data() {
            return {
                count: 1
            }
        }
    }
    Vue.component('counter', {
        template: `<button v-on:click="count++">我被点击了 {{count}} 次</button>`,
        data() {
            return {
                count: 1
            }
        }
    })
    new Vue({
        el: '#app',
        data: {
            count: 1
        },
        components: {
            'button-counter': buttonCounter
        }
    })
</script>


<!--vue声明周期-->
<div id="app">
    <span id="num">{{num}}</span>
    <button @click="num++">赞</button>
    <h2>{{name}}, 有{{num}}个人点赞</h2>
</div>
<script>
    new Vue({
        el: '#app',
        data: {
            name: '张三',
            num: 100
        },
        method: {
            show(){
                return this.name
            },
            add() {
                this.num++
            }
        },
        beforeCreate() {
            console.log("数据模型未加载");
            console.log("方法未加载");
            console.log("方法未加载");
        },
        created() {
            console.log("数据模型已加载");
            console.log("方法已加载");
            console.log("html模版已加载");
            console.log("html模版未渲染");
        },
        beforeMount() {
            console.log("html模版未渲染");
        },
        mounted() {
            console.log("html模版已渲染");
        },
        beforeUpdate() {
            console.log("数据模型已更新");
            console.log("html模版未更新");
        },
        updated() {
            console.log("数据模型已更新");
            console.log("html模版已更新");
        },
    })
</script>
```

# 后台管理系统（renren-fast）配置网关路由和路径重写
运行起来后台管理系统后，需要将前端请求的地址发送给网关，由网关来进行负载负载均衡
gateway网关配置：
    spring:
        cloud:
            gatwey:
                routes:
                    - id: admin_route
                      uri: lb://renren-fast
                      predicates:
                        - Path=/api/**
                      filters:
                        - RewritePath=/api/(?<sagment>.*),/renren-fast/$\{segment}
lb://renren-fast: 
    lb表示的是负载均衡
- Path=/api/**: 
    表示这些请求都会走这个网关配置
- RewritePath=/api/(?<sagment>.*),/renren-fast/$\{segment}:
    表示重写路径，在路径前面加上/renren-fast

# 网关统一配置跨域
gulimall-gateway项目下增加一个CorsConfiguration来解决跨域
@Configuration
public class CorsConfiguration {
    @Bean
    public CorsWebFilter corsWebFilter() {
        CorsConfiguration config = new CorsConfiguration();
        config.addAllowedMethod("*"); // 允许任何方法（post、get等）
        config.addAllowedOrigin("*"); // 允许任何域名使用
        config.addAllowedHeader("*"); // 允许任何头
        config.setAllowCredentials(true); //允许接受cookie
        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(new PathPatternParser());
        source.registerCorsConfiguration("/**", config);
        return new CorsWebFilter(source);
    }
}

# 配置商品服务（gulimall-product）网关
运行起来后台管理系统后，需要将前端请求的地址发送给网关，由网关来进行负载负载均衡
gateway网关配置：
    spring:
        cloud:
            gatwey:
                routes:
                    - id: admin_route
                      uri: lb://gulimall-product
                      predicates:
                        - Path=/api/product**
                      filters:
                        - RewritePath=/api/(?<sagment>.*),/$\{segment}
这个路由信息需要放在renren-fast前面，因为这是精确路由

# 结合renren-fast-vue书写三级分类菜单的查询


# 菜单删除，mybatis-plus逻辑删除
1，在application.yml配置全局的逻辑删除规则
    mybatis-plus:
        global-config:
            db-config:
                logic-delete-value:1
                lofic-not-delete-value:0
2，给bean的字段上加上逻辑删除注解
    @TableLogic(value="1", delval="0")
    private Integer showStatus;

# JSR303数据校验
1，给Bean添加校验注解：javax.validations.constraints
    @NotNull
    private String name;
    @NotNull("logo必须提交")//这里还可以自定义错误信息
    private String logo;
    @Pattern(regexp="/^[a-zA-Z]$", message="检索首字母必须是一个字母")//正则表达式
    private String description;
2，在controller上的save方法开启校验功能：@Valid
    @RequestMapping("/save")
    public R save(@Valid @RequestBody BrandEntity brand) {
        aService.save(brand)
    }
3，给校验的bean后紧跟一个BindingResult，就可以获取到校验的结果
    @RequestMapping("/save")
    public R save(@Valid @RequestBody BrandEntity brand, BindingResult result) {
        Map<String, String> map = new HashMap<>();
        if (result.hasErrores()) {
            result.getFieldErrors().foreach((item) -> {
                String message = item.getDefaultMessage();
                String field = item.getField();
                map.put(field, message);
            })
            return R.error(400, "提交的数据不合法").put("data", map)
            //提交的数据不合法
        } else {
            aService.save(brand)
        }
    }

# 统一异常处理
上面需要在每一个save请求都写一个BindingResult然后进行异常处理，这样是很冗余的
在每个微服务里面都建立一个统一的异常处理，集中处理异常
    @Sl4j
    @RestControllerAdvice(basePackages="com.atguigu.gulimall.product.controller")
    public class GulimallExceptionControllerAdvice {
        @ExceptionHandler(value=MethodArgumentNotValidException.class)
        public voided handleValidException(Exception e) {
            log.error("数据校验出现问题", e.getMessage(), e.getClass())
            BindingResult bindingResult = e.getBindResult();
            Map<String, String> errorMap = new HashMap<>();
            bindingResult.getFieldErrors().foreach((item) -> {
                            String message = item.getDefaultMessage();
                            String field = item.getField();
                            map.put(field, message);
                        })
            return R.error(400, "提交的数据不合法").put("data", errorMap)
        }
    }

# 封装统一的状态码
public enum BizCodeEnum {
    UNKONW_EXCEPTION(10000, "系统未知异常")
    VLILID_EXCEPTION(10001, "参数格式校验失败")
    private int code;
    private String msg;
    BizCodeEnum(int code, String msg) {
        this.code = code;
        this.msg = msg;
    }
    private int getCode() {
        return this.code;
    }
    private int getMsg() {
        return this.msg;
    }
}
就可以这样返回
return R.error(BizCodeEnum.UNKONW_EXCEPTION.getCode(), BizCodeEnum.UNKONW_EXCEPTION.getMsg()).put("data", errorMap)

# JSR303分组校验
业务场景：新增的时候id为空，而编辑的时候id不为空
1,创建分组接口
    public interface AddGroup {}
    public interface UpdateGroup {}
1,增加group，标注什么情况下需要校验
    @NotNull(message="修改时id不能为空", groups={Update.class})
    @Null(message="新增时id为空", groups={AddGroup.class})
    @TableId
    private Integer id;
    
    @NotBlank(message="品牌名必须提交", groups={Update.class,AddGroup.class})
    @TableId
    private String name;
2,在controller指定校验分组:@Valid(Update.class)
    @RequestMapping("/save")
    public R save(@Valid(Update.class) @RequestBody BrandEntity brand, BindingResult result) {
        aService.save(brand)
    }
    
# JSR303自定义校验注解
1，编写一个自定义校验器
@Documented
@Constraint(validateBy = {ListValueConstrainValidator.class})
@Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE})
@Retention(RUNTIME)
public @interface ListValue {
    String message() default "{java.validation.constraints.listvalue.message}";
    Class<?>[] groups() default {};
    CLass<?>[] groups() default {};
    CLass<? extends Payload>[] payload() default {};
    int[] values default {};
}
    
2，编写一个自定义校验器
public class ListValueConstrainValidator implements ContraintValidator<ListValue, Integer> {
    private Set<Integer> set = new HashSet<>()
    @Override
    public void initializa(ListValue contraintAnnotation) {
        //这里是传入的值
        int[] vals = contraintAnnotation.vals();
        for (int val : vals) {
            set.append(val);
        }
    }
    @Override
    public void isValid(Integer value, ConstraintValidatorContext context) {
        //value就是要校验的属性值
        return set.contains(value);
    }
}
3，关联自定义校验器和自定义校验注解

# SPU和SKU
SPU
SPU：Standard Product Unit，标准产品单位。

概念：SPU 是商品信息聚合的最小单位【即：商品共同的属性】，是一组可复用、易检索的标准化信息的集合，该集合描述了一个产品的特性。
通俗点讲，属性值、特性相同的货品就可以称为一个 SPU

SPU是用来定位的
例如：iphone8 就是一个 SPU，与商家、颜色、款式、套餐都无关

SKU
SKU：Stock Keeping Unit，库存量单位。

概念：SKU 即库存进出计量的单位， 可以是以件、盒、托盘等为单位，是物理上不可分割的最小存货单元。
在使用时要根据不同业务，不同管理模式来处理

SKU是用来定价和管理库存的
iphone8 有很多颜色，很多配置，每个颜色和配置的组合都会形成新的产品，这时就产生很多SKU
例如：银色 64G 的 iphone8 就是一个SKU；纺织品中一个 SKU 通常表示：规格、颜色、款式
    
单独创建一个gulimall-search，用于搜索
1，创建一个ES的客户端配置文件
@Configuration
public class GulimallElasticSearchConfig {
    public static final RequestOptions COMMON_OPTIONS;
    static {
        RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder();
        builder.addHeader("Authorization", "Bearer " + TOKEN); 
        builder.setHttpAsyncResponseConsumerFactory(           
            new HttpAsyncResponseConsumerFactory
                .HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024));
        COMMON_OPTIONS = builder.build();
    }
    @Bean
    public RestHighLevelClient esRestClient() {
        return new RestHighLevelClient(RestClient.builder(new HttpHost("127.0.0.1", 9200, "http")));
    }
}
2，测试保存
@Test
public void indexData() {
    IndexRequest indexRequest = new IndexRequest('users');
    indexRequest.id("1");
    User user = new User();
    user.setName("张三")
    user.setGender("男")
    String jsonString = JSON.toJSONString(user);
    indexRequest.source(jsonString, XContentType.JSON);//需要保存的内容
    //执行操作
    IndexResponse index = client.index(indexRequest, GulimallElasticSearchConfig.COMMON_OPTIONS);
}
3，测试检索复杂数据
@Test
public void searchData() {
    SearchRequest searchRequest = new SearchRequest(); 
    1，//指定索引
    searchRequest.indices("bank");
    2，//DLS，检索条件
    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder(); 
    searchSourceBuilder.query(QueryBuilders.matchAllQuery()); 
    searchRequest.source(searchSourceBuilder); 
    3，//执行检索
    SearchResponse searchResponse = client.search(searchRequest, GulimallElasticSearchConfig.DEFAULT);
    4，分析结果
}

# sku在es中的存储模型
点击上架就会上架商品，然后在es中生成商品的信息
sku和spu信息是一起存储的，可能会有冗余的字段，选择的是空间换取时间

如果想要解决这些冗余字段，就得选择时间换取空间，也就是先查询出sku信息在通过sku信息查询出spu信息
这样带来的问题就是二次查询sku信息过多时，请求超时严重。

比如我们查询苹果，得到的sku信息可能是手机、水果、食品有几十万条数据，再根据这几十万条数据去查询spu就会很慢
如果百万并发的话，还会造成服务器崩溃

# ngnix代理
    正向代理：
        类似一个跳板机，代理访问外部资源
        比如我们访问谷歌，访问不到，我们可以通过正向代理服务，把请求发送到代理服，代理服能够访问谷歌，这样由代理服访问谷歌，这样我们就能访问谷歌了
        应用场景：
            vpn访问谷歌，比如google
            可以做缓存访问资源
            客户端访问授权，上网进行认证
            代理可以记录用户访问记录，对外隐藏用户信息
    反向代理：
        实际上就是以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并从服务器上得到结果返回给internet上请求连接的客户端
        主要用途：
            保证内网安全，组织web攻击，大型网站通常将反向代理作为公网地址，web服务器是内网
            负载均衡，通过反向代理服务器来优化网站的负载
    nginx.config
        全局块：配置影响nginx全局的指令。如：用户组、nginx进程pid存放路径、日志存放路径、配置文件引入、允许生成worker process数等
        events块：配置影响nginx服务器或与用户的连接。如：每个进程的最大连接数、选取哪一种事件驱动模型处理连接请求、是否允许多个网络连接、开启多个网络连接序列化
        http块：可以嵌套多个server，配置代理、缓存、日志等绝大多数功能以及第三方模块的配置。如文件引入、mime-type定义、日志自定义、是否使用sendfile传输文件、连接超时时间、单请求连接数
            http全局模块：错误页面、连接超时
                location：配置请求的路由以及各种页面的处理情况
                location：
                .........
                
    在这个商城项目中具体的应用：
        1，在nginx的总配置文件中使用upstream配置上游服务器地址
        http {
            upstream gulimall {
                server 192.168.56.1:88;//这里配置的是网关的地址
            }
        }
        2，在gulimall.conf的nginx中配置
        http {
            location / {
                proxy_set_header Host $host//这里如果不加在转发的时候会丢掉请求头，访问就会出错
                proxy_pass http://gulimall;//引用上游服务器地址
            }
        }
        3，在网关中配置路由规则（这一段一定放在最后，要不然前面的配置就会被路由）
        - id: gulimall_host_route
          uri: lb://gulimall-product
          predicates:
            - Host=**.gulimall.com,gulimall.com

# thymeleaf渲染首页
在product里面配置
1）配置关闭缓存
spring
    thymeleaf:
        cache:false
2）静态资源都放在static文件夹下就可以按照路径访问
3）页面放在templates下，直接访问

# 压力测试
    HPS：每秒点击次数，单位是次/秒
    TPS：系统每秒处理的交易数
    QPS：系统每秒处理查询次数
    对于互联网业务中，如果某些业务仅有一个请求连接，那么TPS=QPS=HPS，
    一般用TPS来衡量业务流程，用QPS来衡量接口查询次数，用HPS表示对服务器的单次请求
    一般情况下：
        金融行业：1000TPS-50000TPS，不包括互联网的活动
        保险行业：100TPS-1000000TPS，不包括互联网互动
        制造业：10TPS-5000TPS
        互联网电子商务：10000TPS-10000000TPS
    影响性能的考虑包括：
        数据库、应用程序、中间件（nginx、tomcat）、网络、操作系统等
        
    压测内容      压测线程数     吞吐量     90%响应时间     99%响应时间
    Nginx          50         2335        11              944
    Getway         50         10367       8               31
    简单服务        50         11341       8               17
    首页一级菜单     50        270(db,thymeleaf)                      
    三级分类数据获取 50         2(db)
    首页全量数据获取 50         7(静态资源)
    Nginx+Getway   50
    Getway+简单服务 50         3126
    全链路          50         800

# nginx动静分离
主要目的是将静态资源放在nginx，增快访问速度
  1）在nginx创建对应存放静态   
  2）配置nginx的config
    location /static/ {
        root /user/share.nginx/html
    }  
# 本地缓存和分布式缓存
那些数据适合放入缓存
    即时性、数据一致性要求不高的
    访问量大但是更新频率不高的
    电商类应用，商品分类，商品列表等适合缓存并加一个失效时间（根据数据更新频率来定）后台发布一个商品，买家需要5分钟才能看到新商品一般是可以接受的

分布式情况下就不应该使用本地缓存，应该使用统一的缓存redis
如果缓存中有就取出缓存中的内容，如果没有就去数据库取

redis堆外内存溢出解决OutOfDriectMemoryError
    sprignboot2.0以后默认使用lettuce作为redis客户端。使用netty进行网络通信
    lettuce的bug导致netty堆外内存溢出；netty如果没有指定堆外内存，默认使用-Xmx300m
    我们不能通过-Dio.netty.maxDIrectMemory进行设置
    解决方案：
        1）更改lettuce源码
        2）切换使用jdis

# 分布式系统下缓存问题
1）缓存穿透
    去查询一个指定不存在的数据，由于缓存不明中，将去查询数据库，但是数据库也没有记录，我们没有将这次查询为null的写入缓存，就会导致这个不存在的数据每次请求都到存储层失去缓存意义
    解决：
        null结果缓存，加入短暂过期时间
2）缓存雪崩
    redis缓存设置key的过期时间相同，导致缓存某一时刻同时失效，DB压力过大
    解决：
        在原有失效的基础上增加一个随机值，比如1-5分钟随机，避免大面积失效
3）缓存击穿
      对于一个设置了过期时间的key可能在某个时间点高并发的访问，是一种热点数据
      如果这个key在大量请求同时进行访问时正好失效，那么这些查询就会落到db
      解决：
        加锁：大量并发只让一个人去查，其他人等待，查到以后释放锁，其他人获得锁，先查缓存，就会有数据，不用去db  

# redis加锁来解决缓存击穿的问题
1，只要是同一把锁就能锁住需要这个锁的所有线程
synchronized(this)：springboot的组件在容器中都是单例的
//先查询缓存然后没有的话调用方法查询数据库
//数据库查询方法（整个方法加锁）
synchronized(this){
    //得到锁以后，还是应该先去缓存中确定一次，如果没有才需要继续查询
    //查询数据库
    //把查询出来的结果放到缓存
    //注意这几个步骤必须放在锁里面
}

# 分布式锁使用
集群的情况下这样加锁，最终有几个实例就有几个锁，所以我们需要使用分布式锁
基本原理就是利用setnx命令
//1，占分布式锁，去redis占坑
String uuuid = UUID.randomUUID().toString();
Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 300, TimeUnit.SECONDS);
if (lock) {
    //加锁成功
    //getDataFromDB然后返回
    //删除锁（非原子操作）
    //String lockValue = redisTemplate.opsForValue().get("lock");
    //if (uuid.equals(lockValue)) {
        //redisTemplate.delete("key");
    //}
    //删除锁，判断删除原子操作
    String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1])"
    redisTemplate.excute(new DefaultRedisScript<Integer>(script, Inteher.class, Arrays.asList('lock'), uuid));
} else {
    //加锁失败。。。重试
    //休眠10s
    //递归自旋重试
}
问题：
    1,setnx占好了位，业务代码异常或者程序在页面过程中宕机。没有执行删除锁逻辑，就造成死锁
    解决：设置自动过期，即便没有删除，也会自动删除
    2,给锁加过期时间和加锁必须是一个原子操作，否则加锁不一定会成功
    3,删除了其他线程加的锁（比如加锁时间是10s，业务也执行了10s，正好业务执行完该删除锁的时候，由于过期时间已到锁已经被删，这时候正好有其他线程获取到了锁，那么我们删除的就是其他线程的锁）
    解决：占锁的时候放一个uuid，然后删除的时候判断是不是自己的uuid，是的话再删除
    4,如果判断是否是自己的锁和删除锁不是一个原子也会有问题（在得到uuid返回时，正好锁过期了，返回的uuid是自己设置的，但是真正的锁设置的uuid是其他线程的，这样还是删除的是别人的锁）
    解决：将判断是否是自己的锁和删除锁做成一个原子操作
    4,业务超时，超过了锁的过期时间
    解决：设置超时时间长一点
# redisson分布式锁
注意：
    1，如果该客户端面对的是一个redis cluster集群，他首先会根据hash节点选择一台机器。这里注意，仅仅只是选择一台机器！这点很关键！
加锁：
    加锁的时候需要使用lua脚本，为什么使用lua脚本呢？保证这段复杂业务逻辑执行的原子性
    1，KEYS[1]代表的是你加锁的那个key，比如说：RLock lock = redisson.getLock("myLock"); 这里你自己设置了加锁的那个锁key就是“myLock”。
    2，ARGV[1]代表的就是锁key的默认生存时间，默认30秒。ARGV[2]代表的是加锁的客户端的ID，类似于下面这样：8743c9c0-0795-4907-87fd-6c719a6b4586:1
    3，第一段if判断语句，就是用“exists myLock”命令判断一下，如果你要加锁的那个锁key不存在的话，你就进行加锁。如何加锁呢？很简单，用下面的命令：
        hset myLock 
            8743c9c0-0795-4907-87fd-6c719a6b4586:1 1
        上述就代表“8743c9c0-0795-4907-87fd-6c719a6b4586:1”这个客户端对“myLock”这个锁key完成了加锁。
    4，锁互斥机制
        如果客户端2来尝试加锁，执行了同样的一段lua脚本，会咋样呢？
        很简单，第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在了。
        接着第二个if判断，判断一下，myLock锁key的hash数据结构中，是否包含客户端2的ID，但是明显不是的，因为那里包含的是客户端1的ID。
        所以，客户端2会获取到pttl myLock返回的一个数字，这个数字代表了myLock这个锁key的剩余生存时间。比如还剩15000毫秒的生存时间。
        此时客户端2会进入一个while循环，不停的尝试加锁。
    5，watch dog自动延期机制
        客户端1加锁的锁key默认生存时间才30秒，如果超过了30秒，客户端1还想一直持有这把锁，怎么办呢？
        简单！只要客户端1一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一下，如果客户端1还持有锁key，那么就会不断的延长锁key的生存时间。
    6，可重入加锁机制
        那如果客户端1都已经持有了这把锁了，结果可重入的加锁会怎么样呢？
        RLock lock = redisson.getLock("myLock");
        lock.lock()
        //业务代码开始
            lock.lock()
            //业务代码开始
            //业务代码结束
            lock.unlock()
        //业务代码结束
        lock.unlock()
        分析：
            第一个if判断肯定不成立，“exists myLock”会显示锁key已经存在了。
            第二个if判断会成立，因为myLock的hash数据结构中包含的那个ID，就是客户端1的那个ID，也就是“8743c9c0-0795-4907-87fd-6c719a6b4586:1”
            此时就会执行可重入加锁的逻辑，他会用：incrby myLock 
                8743c9c0-0795-4907-87fd-6c71a6b4586:1 1
            通过这个命令，对客户端1的加锁次数，累加1。
            那个myLock的hash数据结构中的那个客户端ID，就对应着加锁的次数
    7，释放锁机制
        如果执行lock.unlock()，就可以释放分布式锁，此时的业务逻辑也是非常简单的。
        其实说白了，就是每次都对myLock数据结构中的那个加锁次数减1。
        如果发现加锁次数是0了，说明这个客户端已经不再持有锁了，此时就会用：
        “del myLock”命令，从redis里删除这个key。
        然后呢，另外的客户端2就可以尝试完成加锁了。
示例：
    RLock lock = redisson.getLock("myLock");
    lock.lock()
    //1，锁会自动续期，如果业务超长，运行期间自动加上30s，不用担心业务过长锁自动过期
    //2，加锁业务只要运行完成，就不会给当前锁续期
    try {
        //业务代码执行
        Thread.sleep();
    } catch (Exception e) {
        //异常处理
    } finally {
        lock.unlock()
    }
看门狗原理
    lock.lock(10, TimeUnit.SECONDS)//设置了自动过期时间，这样是不会自动续期的
    //这里如果我们传递了超时时间，就发送给redis执行脚本，进行占锁，默认超时时间就是我们指定的时间
    //如果我们未指定超时时间，就使用LockWatchTimeout看门狗的过期时间，只要占锁成功，就会启动一个定时任务（重新给锁设置过期时间，每隔十秒续期，过期时间就是看门狗的默认时间）
读写锁：
    //应用：保证一定能读取到最新数据
    //写锁是一个排它锁（互斥锁），读锁是一个共享锁
    //读 + 读：相当于无锁，并发读，只会在redis中记录好，所有当前的读锁都会加锁成功
    //写 + 读：等待写锁释放
    //写 + 写：阻塞
    //读 + 写：有读锁。写需要等待
    //总结：有写存在，都必须等待
    //写锁没释放，读锁就必须等待
    public String writeValue() {
        //改数据加写锁，读数据加读锁
        RReadWriteLock lock = redisson.getReadWriteLock("rw-lock");
        RLock wLock = lock.writeLock();
        wLock.lock();
        String s = UUID.randomUUID().toString();
        Thread.sleep(30000);
        redisTemplate.opsForValue().set("writeValue", s)
        wLock.unlock();
        return s;
    }
    public String readValue() {
        RReadWriteLock lock = redisson.getReadWriteLock("rw-lock");
        RLock rLock = lock.readLock();
        rLock.lock();
        String s = redisTemplate.opsForValue().get("writeValue");
        rLock.unlock();
        return s;
    }
闭锁：
    //比如所有的人走完才能锁门
    public String lockDoor() {
        RCountDOwnLatch door = redisson.getCountDownLatch("door");
        door.trySetCount(5);
        door.await();
        System.out.println("锁门成功");
    }
    public String go() {
        RCountDOwnLatch door = redisson.getCountDownLatch("door");
        door.countDown();//记述减1
    }
信号量：
    //比如停车位只有3个，只有有了空位才能继续停车
    //可以用作分布式限流，比如就能连接1000个用户
    public void park() {
        //park是提前在redis中设置好的
        RSemaphore park = redisson.getSemaphore("park");
        park.acquire();//相当于获取一个车位，获取不到就会阻塞
    }
    public void go() {
        RSemaphore park = redisson.getSemaphore("park");
        park.release();//释放一个车位
    }

# redis缓存一致性
    双写模式
        把数据库改完就去改缓存
        问题：
            脏数据，由于卡顿的原因，两台机器都更改数据库然后更新缓存，但是可能线程1更改了数据库，在更改缓存的时候遇到了卡顿。这是线程2写入了新的数据更新了缓存。然后线程1更新了缓存，这时缓存就是线程1设置的旧数据
        解决：
            1，双写的时候加锁
            2，如果允许暂时性的脏数据问题，那么就给缓存设置过期时间，到时候就又能得到正确的数据
    失效模式：
        每次更新完数据库，删除缓存，这样查询的时候就会更新缓存
        问题：
            线程1更新了数据库删除了缓存
            线程2更改了数据库卡住了，还没有删除缓存
            线程3在读取的时候发现缓存为空，然后就去读数据库，因为线程2卡住了，所以读取的是线程1更改的数据，在更新缓存时卡住了，这时候线程2完成了更改数据和更新缓存，那么线程3更新缓存时就是线程1更改的旧数据
    解决方案：
        1，如果是用户纬度数据，这种并发几率很小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可
        2，如果是菜单，商品介绍等基础数据，可以使用cannal订阅binlog的方式
        3，缓存数据加上过期时间足够解决大部分业务对缓存的要求
        4，通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓，所以适合使用读写锁。（业务不关心心脏数据，允许脏数据可忽略）
        总结：
            我们能放入缓存的数据本身不应该是实时性、一致性要求高的。所以缓存数据加上过期时间，保证每天拿到当前最新数据即可
            我们不应该过度设计，增加系统复杂性
            遇到实时性、一致性要求高的数据，就应该查询数据库，即使慢点
            对于少写、多读、数据一致性要求高的，我们可以使用失效模式加上分布式读写锁
            最好给所有的缓存加上过期时间
    cannal：
        1，实时更新缓存：
            业务代码更改数据库 -> 产生binlog -> cannal订阅binlog -> 更新redis
        2，大数据分析用户喜好：
            cannal订阅访问记录表和商品信息表的binlog，分析计算构建用户推荐表
# springcache         
spring从3.1开始定义了org.springframework.cache.Cache和org.springframework.cache.CacheManager接口来统一不同的缓存技术，并使用Jcache注解简化我们的开发
Cache接口下Spring提供了各种xxxCache的实现；如RedisCache、ChCache、ConcurrentMapCache
使用：
    1，引入依赖
    spring-bootpstarter-cache、spring-boot-starter-data-redis
    2，写配置
        (1) 自动配置了那些？
            CacheAUtoCOnfiguration会导入CacheConfiguration；
            自动配置好了缓存管理器RedisCacheManager
        (2）配置使用redis作为缓存
            spring.cache.type=redis
        (3) 缓存空值
            spring.cache.redis.cache-null-values=true
        (4) 缓存空值
             spring.cache.redis.cache-null-values=true
        (5) 前缀
             如果使用了前缀，就使用配置的前缀，如果没有配置前缀就使用缓存的名字作为前缀
             spring.cache.redis.key-prefix=CACHE_
             spring.cache.redis.use-key-prefix=true
        (6) 指定存活时间
            spring.cache.redis.time-to-live=36000000
    2，主要注解
            @Cacheable：触发将数据保存到缓存
            @CacheEvict：触发将数据从缓存中删除
            @CachePut：不影响方法执行更改
            @Caching：组合以上多种操作
            #CacheConfig：在类级别共享缓存的相同
    3，默认行为
            1）如果缓存中有，方法不能调用
            2）key是默认自动生成，缓存的名字::SimpleKey[](自主生成的key值)
            3）缓存的value的值。默认使用jdk序列化机制，将序列化后的数据存到redis
            4）默认ttl时间是-1，永不过期
    4，自定义
        将数据保存为json
            原理：CacheAutoConfiguration -> RedisCacheConfiguration -> 自动配置了RedisCacheManager
            -> 初始化所有的缓存 -> 每个缓存决定使用什么配置 -> 如果redisCacheConfiguration有就用已有的，没有就用默认配置
            -> 想更改缓存配置，只需要给容器中放一个RedisCacheConfiguration即可 -> 就会应用到当前RedisCacheManager管理的缓存分区中
            @EnableConfigurationProperties(CacheProperties.class)
            @Configuration
            @EnableCaching
            public class MyCacheConfig {
                @Bean
                RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) {
                    RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
                    //这里设置redis序列化
                    config = config.serializeKeyWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
                    config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));
                    //原本的配置
                    CacheProperties>redis redisProperties = cacheProperties.getRedis();
                    if (redisProperties.getTimeToLive() != null) {
                        config = config.entryTtl(redisProperties.getTimeToLive());
                    }
                    if (redisProperties.getKeyPrefix() != null) {
                        config = config.prefixKeysWith(redisProperties.getKeyPrefix());
                    }
                    if (!redisProperties.isCacheNullValues()) {
                        config = config.disableCachingNullValue();
                    }
                    if (!redisProperties.isUseKeyPrefix()) {
                        config = config.disableKeyPrefix();
                    }
                }
            }
    4，@Cacheenable()
        就代表当前方法的结果需要缓存，如果缓存中有，方法不用调用。如果缓存中没有，会调用方法最后将方法的结果放入缓存；
        @Cacheenable({"category", "product"})//缓存放入多个分区
        @Cacheeable(value = {"category"}, key = "'levellCategorys'")//指定分区以及key
        @Cacheeable(value = {"category"}, key = "#root.method.name")//指定分区，取方法名作为key
       建议： 每一个需要缓存的数据我们都来指定放到哪个名字的缓存。【缓存的分区（按照业务类型分类）】
    6，@CacheEvict()失效模式
       @CacheEvict(value = "category", key = "'getLevel1Categorys'")：
       @Caching(evict = {
            @CacheEvict(value = "category", key = "getLevellCategorys"),
            @CacheEvict(value = "category", key = "getCatalogJson"),
        })//同时失效多个key
       @CacheEvict(value = "category", allEntries = true)//删除整个分区category的数据
       建议：同一类型的数据都指定成同一个分区。分区名默认就是缓存的前缀
    7，@CachePut()双写模式
    8，Spring-Cache的不足
        1）读模式
            缓存穿透：查询一个null数据。
                解决：缓存空数据：cache-null-values=true
            缓存击穿：大量并发同时进来查询一个正好过期的数据。
                解决：(sync = true)加锁
                @Cacheeable(value = {"category"}, key = "#root.method.name", sync = true)
                这里的加锁不是分布式锁，而是本地锁，不过即使每个节点有一个请求到数据库，也是可以接受的
            缓存雪崩：大量的key同时过期。
                解决：加过期时间
                这里并不需要随机加过期时间，因为set的时候时间并不是一样的
        2）写模式（缓存和数据库一致）
            1，读写加锁
            2，引入cannal，感知到mysql就去更新数据库
            3，读多写多，直接去数据库查询
        
            
# CompletableFuture异步编排
应用场景：查询商品详情页的逻辑比较复杂，有些数据还需要远程调用，必然需要话费更多时间。
假如商品详情页的每个查询，需要如下标注时间才能完成，那么，用户需要6.5s后才能看到商品详情页内容，很显然是不能接受的
如果有多个线程同时完成这6步操作，也许只需要1.5s即可完成
1，基本方法
    1，static CompletableFuture<void> runAsync(Runnable runnable);
    2，public static CompletableFuture<void> runAsync(Runnable runnable, Executor executor);
    3，public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier);
    4，public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier, Executor executor);
    runXxx都是没有返回结果的，supplyXxx是可以获取返回结果的
    可以传入自定义线程池，否则就用默认的线程池
2，基本使用
    public static ExecutorService executor = Executors.newFixedThreadPoll(10);
    CompletableFuture<void> future = CompletableFuture.runAsync(() -> {
        int i = 10/2;
    }, executor);
    CompletableFuture<void> future = CompletableFuture.supplyAsync(() -> {
        int i = 10/2;
        return i;
    }, executor);
    Integer interger = future.get();
3，whenComplete（方法完成后的感知）
    CompletableFuture<void> future = CompletableFuture.supplyAsync(() -> {
        int i = 10/2;
        return i;
    }, executor).whenComplete((res, excption) -> {
        //虽然能得到异常信息，但是不能修改返回数据
        System.out.println("异步任务完成了。。。结果是" + res);
        System.out.println("异步任务完成了。。。异常是" + exception);
    }).execptionally((throwable) -> {
        //可以感知异常，同时返回默认值
        return 10;
    });
    whenComplete: 执行当前任务的线程继续执行whenComplete任务
    whenCompleteAsync: 执行把whenCompleteAsync这个任务继续提交给线程池
    方法不以async结尾，意味这action使用相同的线程执行，而Async可能会使用其他线程执行
4，handle（方法完成后的处理）
    CompletableFuture<void> future = CompletableFuture.supplyAsync(() -> {
        int i = 10/2;
        return i;
    }, executor).handle((res, excption) -> {
        //虽然能得到异常信息，还可以修改返回数据
        System.out.println("异步任务完成了。。。结果是" + res);
        System.out.println("异步任务完成了。。。异常是" + exception);
        if (res != null) {
            return res*2;
        }
        if (excption != null) {
            return 0;
        }
        return 0;
    });
5，线程串行化
    : 当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前任务的返回值
    带有Async默认是异步执行的。同之前，以上都要前置任务成功完成。
    //thenRun: 不能获取到上一步的执行结果
    CompletableFuture<void> future1 = CompletableFuture.supplyAsync(() -> {
        int i = 10/2;
        return i;
    }, executor).thenRunAsync(() -> {
        System.out.println("任务2启动了。。。");
    }, executor);
    //thenAccept: 能获取到上一步的执行结果，但是无返回值
    CompletableFuture<void> future1 = CompletableFuture.supplyAsync(() -> {
        int i = 10/2;
        return i;
    }, executor).thenAccept((res) -> {
        System.out.println("任务2启动了。。。" + res);
    }, executor);
    //thenAccept: 既能获取到上一步的执行结果，又能有返回值
    CompletableFuture<void> future1 = CompletableFuture.supplyAsync(() -> {
        int i = 10/2;
        return i;
    }, executor).thenApplyAsync((res) -> {
        System.out.println("任务2启动了。。。" + res);
        return res*2;
    }, executor);
5，并行化（两任务组合 - 都要完成再执行后面的结果）
    CompletableFuture<void> future1 = CompletableFuture.supplyAsync(() -> {
        return 10/2;
    }, executor);
    CompletableFuture<void> future2 = CompletableFuture.supplyAsync(() -> {
        return "Hello";
    }, executor);
    //这样感知不到前两个的执行结果
    future1.runAfterBothAsync(future2, () -> {
        System.out.println("任务1、2都完成后，任务3启动了。。。");
    }, executor);
    //可以感知到前面线程的执行结果
    future1.thenAcceptBothAsync(future2, (f1, f2) -> {
        System.out.println("任务1、2都完成后，任务3启动了。。。之前的执行结果：" + f1 + f2);
    }, executor);
    //可以感知到前面线程的执行结果，并处理后返回
    future1.thenCombineAsync(future2, (f1, f2) -> {
        System.out.println("任务1、2都完成后，任务3启动了。。。");
        return f1 + f2;
    }, executor);
5，两个任务有一个完成就执行后面的结果
    CompletableFuture<void> future1 = CompletableFuture.supplyAsync(() -> {
        return 10/2;
    }, executor);
    CompletableFuture<void> future2 = CompletableFuture.supplyAsync(() -> {
        return 10/1;
    }, executor);
    //这样感知不到前两个的执行结果，无返回值
    future1.runAfterEitherAsync(future2, () -> {
        System.out.println("任务1、2任何一个完成后，任务3启动了。。。");
    }, executor);
    //可以感知到前面线程的执行结果，任务1、任务2的执行结果类型必须一样
    future1.acceptEitherAsync(future2, (res) -> {
        System.out.println("任务1、2任意一个完成后，任务3启动了。。。之前的执行结果：" + res);
    }, executor);
    //可以感知到前面线程的执行结果，并处理后返回，任务1、任务2的执行结果类型必须一样
    future1.applyToEitherAsync(future2, (res) -> {
        System.out.println("任务1、2任意一个完成后，任务3启动了。。。");
        return res + "hahaha";
    }, executor);
6，多任务组合
    CompletableFuture<void> future1 = CompletableFuture.supplyAsync(() -> {
        System.out.println("任务1执行。。。");
        return "任务1"；
    }, executor);
    CompletableFuture<void> future2 = CompletableFuture.supplyAsync(() -> {
        System.out.println("任务2执行。。。");
        return "任务2"；
    }, executor);
    CompletableFuture<void> future3 = CompletableFuture.supplyAsync(() -> {
        System.out.println("任务3执行。。。");
        return "任务3"；
    }, executor);
    //所有都执行成功后
    CompletableFuture<void> allof = CompletableFuture.allOf((future1, future2, future3));
    allof.get();//这里阻塞等待所有结果完成
    System.out.println("每个任务的结果。。。" + future1.get() + future2.get() + future3.get());
    //任何一个执行成功
    CompletableFuture<void> anyof = CompletableFuture.anyOf((future1, future2, future3));
    anyof.get();//阻塞等待有一个完成就好
    System.out.println("最先成功的任务的结果。。。" + anyof.get());

# 认证服务的分布式session
问题:1.不能跨不同域名共享; 2.同一域名，多个服务session不能同步

同一域名，多个服务session不能同步，解决：
    1，session复制。多个服务之间同步session数据
        优点：
            tomcat原生支持，只需要修改配置文件
        缺点：
            session同步需要数据传输，占用大量网络带宽，降低了服务集群的业务处理能力
            任意一台web-sever保存的数据都是所有web-sever的session总和，受到内存限制无法扩展更多web-sever
            大型分布式集群情况下，由于所有web-sever都全量保存数据，此方案不可取
    2，客户端存储session
        优点：
            服务器不需要存储session，用户自己保存自己的session信息到cookie，节省服务端资源
        缺点：
            缺点太多，这只是一种思路
            每次http请求，用户携带cookie完整信息，浪费网络带宽
            session数据保存在cookie中，cookie的长度限制只有4k
            session信息保存在cookie中，存在泄漏、篡改、窃取等安全隐患
    3，hash一致性。用户请求时将同一个用户的请求都落到同一台服务器
        优点：
            只需更改nginx配置，不需要改代码
            负载均衡，只要hash属性值是分布均匀的，多台web-sever负载就是均衡的
            可以支持web-sever水平扩展
        缺点：
            session还是存储在web-sever中，所以web-sever重启可能导致部分session丢失，影响业务，部分用户可能需要重新登陆
            如果web-sever水平扩展，rehash后session重新分布，也会有一部分用户路由不到正确的session
        但是以上缺点问题不大，因为session本身是有有效期的。所以这两种方向代理方式可以使用
    4，session统一存储
        优点：
            没有安全隐患
            可以水平扩展，数据库/缓存水平切分即可
            web-sever重启扩容都不会有session丢失
        不足：
            增加了一次网络调用，并且需要修改应用代码；如将所有的getSession方法替换为从Redis查询数据。redis获取数据比内存慢得多
            上面的不足可以用springsession完美解决
不同域名session共享解决：
    放大作用域，子域名存储session的时候放大存储到父域名
    子域之间：gulimall.com 和 auth.gulimall.com、order.gulimall.com
    发卡的时候（指定域名为父域名），即使是子域系统发的卡，也能让父域直接使用

两者终极解决方案（springsession）：
    1，引入依赖：sprign-session-data-redis
    2，配置application.properties：spring.session.store-type=redis
    3，配置session过期时间：server.servlet.session.timeout=30m
    4，开启springsession：@EnableRedisHttpSession
    5，解决子域session共享问题（放大session）：
        在每一个微服务下面都配置上自定义的SessionConfig
        @Configuration
        public class GlimallSessionConfig {
            @Bean
            public CookieSerializer cookieSerializer() {
                DefaultCookieSerializer ciikieSerializer = new DefaultCookieSerializer();
                //放大到父域名
                ciikieSerializer.setDimainName("gilimall.com");
                //设置cookiename
                ciikieSerializer.setCookieName("GULISESSION");
                return ciikieSerializer;
            }
            //设置json序列化
            @Bean
            public RedisSerializer<Object> springSessionDefaultRedisSerializer() {
                return new GenericJackson2JsonRedisSerializer();
            }
        }
springsession原理
    @EnableRedisHttpSession导入RedisHttpSessionConfiguretion，给容器添加了一个组件SessionRepository，SessionRepository相当于dao层来操作增删改查
    springSessionRepositoryFilter用来过滤每一个请求
    在过滤器中原始的reques、response都被包装成SessionRepositoryRequestWrapper、SessionRepositoryResponseWrapper
    往后获取session都是wrapperRequest.getSession()，都是SessionRepository从redis中获取到的
    这里就用到了装饰者模式

# 购物车
    特点：
        在线购物车在登陆以后，会将临时购物车数据合并过来，并清空临时购物车
        临时购物车，即使关闭浏览器，购物车的东西还会存在
    怎么存储：
        不管是在线购物车还是离线购物车，都存放在redis里面
        商品在redis里面保存的应该是一个双层Map，第一个key是用户id，第二个key是商品的skuId，然后就是具体的商品信息（单价、图片、名称以及是否选中等等）
        如果用户已经登陆，那么用户id就是session里面的id，如果未登录，用户id就是cookie里面的user-key
    标识临时用户：
        第一次访问网址，浏览器cookie里面创建一个user-key，大概一个月后过期，以后每次访问都会带上这个user-key
    添加购物车之前拦截器获取用户信息：
        如果已经登陆就直接获取用户信息。未登录就从cookie里面获取user-key，没有就在cookie里面创建user-key
        @Component
        public class CartInterceptor implements HandlerInterceptor {
            public static YhreadLocal<UserInfo> threadLocal = new YhreadLocal<>();
            //业务执行之前
            @Override
            public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object ahdler) throes Exception {
                UserInfo userInfo = new UserInfo();
                HttpSession session = request.getSession;
                MemberRespVo member = session.getAttribute("login_user");
                if (member != null) {
                    //如果用户登陆，就设置用户id
                    userInfo.setUserId(member.getId());
                } else {
                    //用户没有登陆从cookie中获取临时用户
                    Cookie[] cookies = request.getCookies();
                    if (cookies != null && cookies.length > 0) {
                        for (Cookie cookie : cookies) {
                            String name = cookie.getName();
                            if (name.equals("user-key")) {
                                userInfo.setUserId(cookie.gteValue());
                            }
                        }
                    }
                }
                //如果临时用户不存子啊分配一个临时用户
                if (StringUtiles.idEmpty(userInfo.getUserKey())) {
                    String uuid = UUID.randomUUID().toString();
                    userInfo.setUserKey(uuid);
                }
                //threadLocal经典用法，可以快速的在controller中通过CartInterceptor.threadLocal.get()快速的获取到UserInfo对象
                threadLocal.set(threadLocal)
                return true;
            }
            //业务执行过后，储存user-key到cookie
            @Override
            public boolean postHandle(HttpServletRequest request, HttpServletResponse response, Object ahdler) throes Exception {
                UserInfo userInfo = threadLocal.get()
                Cookie cookie = new Cookie("user-key", userInfo.getUserKey());
                cookie.setDomain("gulimall");
                cookie.setMaxAge(3600000);
                response.addCokie(cokie);
                return true;
            }
        }
    具体添加购物车service
        public CartItem addToCart(Long skuId, Integer num) {
            //根据user信息获取操作购物车的options
            BoundHashoperations<String, Object, Object> options = getCartOps();
            CatrItem cartItem = new CartItem();
            //异步编排远程查询当前要添加的商品信息,并封装到CatrItem
            //异步编排远程查询当前sku组合信息,并封装到CatrItem
            String s = JSON.toJSONString(cartItem);
            options.put(skuId.toString(), s);
            return cartItem
        }
        
        //根据key获取操作购物车的options
        private void getCartOps() {
            UserInfo userInfo = CartIntegerceptor.threadLocal.get();
            String cartKey = "";
            if (userInfo.getUserId() != null) {
                cartKey = CART_PREFIX + userInfoTo.getUserId();
            } else {
                cartKey = CART_PREFIX + userInfoTo.getUserKey();
            }
            BoundHashoperations<String, Object, Object> options = redisTemplate.boundTemplate.boundHashOps(cartKey);
            return options;
        } 
# 幂等性
    就是用户对统一操作发起的一次请求或者多次请求结果是一致的
    哪些情况需要防止：
        1，用户多次点击按钮
        2，页面退回再次提交
        3，微服务互相调用，由于网络问题，导致请求失败。feign触发重试机制
    什么情况下有幂等行：
        查询是天然幂等的
        删除也是幂等的
        更新如果是改为固定值也是幂等的
        插入带唯一主键也是幂等的
        如果更新操作每次操作都会使执行结果发生变化，就不是幂等的
        插入的时候没有主键那么也不是幂等的
    幂等解决方案：# es整合springboot（使用lastic-Rest-Client）

        1，token机制（最常见的机制）
            解决：
                1）跳转到保存页面的时候分别在redis以及页面里面放入token
                2）然后调用业务接口保存时，把token携带过去，一般放在请求头
                3）服务器判断token是否和redis里面的token一样，然后删除token，继续执行业务
                4）如果判断token不存在redis中或者和redis里面的token不一致，就表示重复操作，直接返回重复标记给client，这样就保证了业务代码不会重复执行
            危险：
                1，先删除token还是后删除token
                    1）先删除可能导致业务确实没有执行，重试还是带上之前的token，由于防重设计导致，请求还是不能执行
                    2）后删除可能导致，业务处理成功，但是服务问题，出现超时，没有删除token，别人继续重试，导致业务被执行两遍
                    3）我们最好设计先删除token，如果业务调用失败，就重新获取token再次请求
                2，token获取、比较、删除必须是原子性操作
                    1）redis.get("token")、token.equals、redis,del(tiken)如果这两个操作不是原子，可能导致高并发下，都get到同样的数据，判断都成功，继续业务执行
                    2）可以在redis使用lua脚本完成这个操作
                        if redia.call('get', KEYS[1]) = ARGV[1] then return redis.call('del' KEYS[1]) else reutnr o end
            适用场景：
                插入操作
                更新操作
                删除操作
        3，各种锁机制（主要是乐观锁）
            1，数据库悲观锁
                就是在查询的时候不允许别的请求再动这条记录
                select * from table where id = 1 for update;
                悲观锁使用时一般伴随事物一起使用，数据可锁定时间可能会很长，需要根据实际情况选用。
                另外需要注意的是，id字段一定是主键或者唯一索引，不然可能造成表锁的结果，处理起来非常麻烦
            2，数据库乐观锁
                这种方法适合在更新场景中
                update t_goods set count=count-1, version=version+1 where good_id=2 and version = 1
                根据version版本，也就是操作库存前先获取当前商品的version版本号，然后操作的时候带上version好。
                梳理一下：
                    第一次操作库存的时候，得到version为1，调用库存服务version变成了2；但是返回给订单服务出现了问题，
                    订单服务又一次发起调用库存服务，当订单服务传入的verison还是1，再执行上面的sql语句，就不会执行；
                    因为version已经变成2了，where条件不成立。这样就保证了不管调用几次，只会真正处理一次。
                    乐观锁主要适用于处理读多写少的问题
                适用场景：
                    更新操作
            3，业务的分布式锁
                如果如果多个机器可能在同一时间同时处理相同的数据，比如多台机器定时任务都拿到了相同数据处理
                我们可以加分布式锁，锁定此数据，处理完成后释放锁。获取到锁必须先判断这个数据是否被处理过
        4，数据可得唯一约束（在分布式系统下注意限制）
            插入数据，应该按照唯一索引进行插入，比如订单号就不可能有两条记录插入。我们在数据库层面防止重复
            这个机制利用了数据库主键唯一的约束特性，解决了insert场景时等问题。
            如果是分库分表的情境下，路由规则要保证相同的请求下，落在同一个数据库同一张表中
            使用数据库唯一主键完成幂等性时需要注意的是，该主键一般来说并不是使用数据库中自增主键，而是使用分布式 ID 充当主键，这样才能能保证在分布式环境下 ID 的全局唯一性。
            适合场景：
                插入操作
                删除操作
        6，下游传递唯一序列号实现幂等性
            当调用接口时，参数中必须传入source字段和seq字段（这边举了一个我们项目中的列子，其实并不一定要传两个字段，传一个唯一的序列号uuid也能达到一样的效果）
            服务端接收到请求，先判断自己是否是一个幂等接口，如果不是幂等接口就正常处理请求。
            如果是一个幂等接口，就将source和seq组成联合主键去数据库表中或者是Redis中查询，如果没有查询到，说明没处理过这个请求，然后正常处理请求就行了。处理完之后将处理结果和source和seq信息一个存入数据库或Redis中。
            如果根据source和seq能查询到，说明已经处理过这个请求了，直接将处理的结果返回即可。
            适用操作：
                插入操作
                更新操作
                删除操作
            缺点：
                如果请求量很大的话，存放请求记录的表会很大，这个时候可以将一段时间之前的记录删除，以提升性能。
            调用接口时，生成一个唯一的id，redis将数据保存到集合中（去重），存在即处理过
            可以使用nginx设置每一个请求的唯一id
                proxy_set_header X-Request-Id $request_id;
# 分布式事物
    CAP理论：
        分区容错性：
            指的分布式系统中的某个节点或者网络分区出现了故障的时候，整个系统仍然能对外提供满足一致性和可用性的服务。也就是说部分故障不影响整体使用。
            事实上我们在设计分布式系统是都会考虑到bug,硬件，网络等各种原因造成的故障，所以即使部分节点或者网络出现故障，我们要求整个系统还是要继续使用的
            (不继续使用,相当于只有一个分区,那么也就没有后续的一致性和可用性了)
        可用性： 
            一直可以正常的做读写操作。简单而言就是客户端一直可以正常访问并得到系统的正常响应。用户角度来看就是不会出现系统操作失败或者访问超时等问题。
        一致性：
            在分布式系统完成某写操作后任何读操作，都应该获取到该写操作写入的那个最新的值。相当于要求分布式系统中的各节点时时刻刻保持数据的一致性。
        举例：
            1，Zookeeper保证CP
                当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接受服务直接down掉不可用。
                也就是说，服务注册功能对可用性的要求要高于一致性。但是zk会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。
                问题在于，选举leader的时间太长，30 ~ 120s, 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。
            2，Eureka保证AP
                Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册或时如果发现连接失败，则会自动切换至其它节点，只要有一台Eureka还在，就能保证注册服务可用(保证可用性)，只不过查到的信息可能不是最新的(不保证强一致性)。除此之外，Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况：
                1. Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务
                2. Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用)
                3. 当网络稳定时，当前实例新的注册信息会被同步到其它节点中
                因此， Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪。
        关于一致性算法raft：
            raft算法核心就是选举以及日志复制，主要保证的是CP，就是一致性和分区容错性。如果一个节点宕机就一直返回错误数据
        分布式集群一般会保证AP
            对于大多数互联网应用场景，主机众多、部署分散、而且集群规模越来越大，所以节点故障以及网络故障是常态，而且要保证可用性达到99.99999999%,即要保证AP舍弃CP
    BASE理论：
        是对cap理论的延伸，即无法做到强一致性（cap一致性就是强一致性），但可以采用弱一致性，即最终一致性
        base是指：
            基本可用（basically available）
                基本可用指的是分布式系统出现故障的时候，允许损失部分可用性（例如响应时间的可用性）。注意：基本可用不等于系统不可用
                    1，响应时间上的损失：比如正常一个查询需要0.5s，但是由于机房故障，查询时间增加了2s
                    2，功能上的损失：购物网站高峰时，部分消费者被引导到另一个页面
            软状态：
                允许系统中存在中间状态，该中间状态不影响系统整体可用性。
                分布式存储中一份数据会有多个副本，允许不同副本同步的延时。例如mysql replication的异步复制
            最终一致性：
                最终一致性指系统中所有数据副本经过一段时间后，最终达到一致的状态。最终一致性是弱一致性的一种特殊情况
    分布式事物解决方案：
        1，2PC（二阶提交）
            数据库支持，mysql从5.5版本开始
            该协议分为一下两个阶段：
                1，第一阶段：事物协调器要求每个涉及到事物的数据库预提交（precommit），并反应是否可以提交
                2，第二阶段：事务协调器要求每个数据库提交数据
                其中，如果有任何数据库否决此次提交，所有的数据库会被要求回滚它们在此事物中的那部分信息
            这种协议性能不理想，无法满足高并发的场景
        2，TCC事物补偿性方案
            是柔性事物，允许在一定时间内，不同节点的数据不一致，但是最终一直
            一阶段：prepare准备阶段。准备要提交的数据
            二阶段：comform提交阶段。提交数据
            三阶段：cancel取消阶段。如果发生异常，取消之前对数据库的操作。
            三个阶段都有自己编写代码，相当于把业务代码拆分成了三步。
            比如订单模块首先调用库存模块减库存，调用积分模块减积分然后下单成功。
            那么下单、减库存、减积分都有prepare、comform、cancel三个阶段。如果下单、减库存、减积分任何一个出错那么就会调用其cancel取消事物
        3，最大努力通知，消息事物
            定时进行通知，不保证数据一定通知成功，但会提供可查询操作接口进行核对。
            这种方案主要用于第三方系统通讯，比如：调用支付宝的支付接口。
            这种方案结合mq进行实现。例如：通过mq发送请求，设置最大通知次数。达到次数后不再通知
            比如，还是下单、减库存、减积分如果减库存出错，就会通过mq通知下单、减积分服务进行回滚
    分布式事务seata
        seata将为用户提供AT、TCC、SAGA和XA事物模式，为用户打造一站式分布式解决方案
        主要概念：
            TC-事务协调者：维护全局和分支事物状态，驱动全局事务提交或回滚。在下单业务里面就是减库存、减积分这些操作
            TM-事务管理器：定义全局事务范围，开始全局事务、提交或回滚全局事务。在订单业务里面就是下单这个大操作
            RM-资源管理器：管理分支事务处理资源，与TC交谈以注册分支事务和报告分支事务状态，并驱动分支事务提交或回滚。事务协调者，用来协调管理所有的事物
        使用（AT模式）：
            1）数据库建立UNDO_LOG表，用于反向补偿。
            2）安装seata服务器
            3）导入依赖spring-cloud-starter-alibaba-seata
            4）修改seata的registry.conf更改注册中心为nacos，启动seata服务
            5）想用seata的微服务配置seata代理数据源。然后seata就可以回滚事务了
                @Configuration
                public class MySeataCOnfig {
                    @Autowried
                    DataSouurceProperties dataSouurceProperties;
                    @Bean
                    public DataSource dataSource(DataSourceProperties dataSourceProperties) {
                        HikariDataSource dataSource = dataSourceProperties.initializeDataSOurceBuilder.type(HikariDataSource.class)；
                        if (StringUtils.hasText(dataSourceProperties.getName())) {
                            dataSource.setPollName(dataSourceProperties.getName());
                        }
                        return new DataSourceProxy(dataSource);
                    }
                }
            6）微服务导入registry.config以及file.config
                更改file.config里面的service名字：vgroup_mapping.{application.name}-fescar-service-group = "default"
            7）给分布式大事务加上@GlobalTransactional，每一个远程小事务用@Transactional就可以了
                即在下单service上面加上@GlobalTransactional就可以了   
        但是seata并不适用于高并发，所以并不适用，高并发最好还是使用最大通知。这里适用于后台管理服务的场景，比如上架新品
# 消息队列RabbitMq
两种类型：
    1，JMS(Java Message Service) Java消息服务
        - 基于jvm消息代理的规范。ActiveMq、HornetMq都是JMSshixian
    2，AMQP(Advanced Message Queuing Protocol)
        - 高级消息队列协议，也是一种消息代理规范，兼容jms
        - RabbitMQ是AMQP的实现
两种形式的目的地：
    1，队列（queue）：点对点的消息通信
        消息发送者发送消息，消息代理将其放入一个队列中，消息接受者从队列获取消息内容，消息读取后被移除队列
        消息只有唯一的发送者和接受者，但是并不是说只能有一个接收者。消息只能被一个监听消费
    2，主题（topic）：发布/订阅消息通信
        发送者发送消息到主题，多个接收者订阅这个主题，那么就会在消息到达时同时接收到消息
核心概念：
    message：
        消息，消息是不具名的，它由消息头和消息体组成，消息体不透明，而消息头则由一系列的可选属性组成。
        这些属性包括routing-key(路由键)、priority（相对其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）
    publisher：
        消息的生产者，也是一个向交换器发布消息的客户端应用程序
    exchange：
        交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。excahnge有4种类型：
            direct（默认）、fanout、topic、headers，不同类型的exchange转发消息的策略有所区别
    queue：
        消息队列，用来保存消息发送给消费者，它是消息的容器，也是消息的终点。
        一个消息可以投入一个或者多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走
    binding：
        绑定，用于消息队列和交换机之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则
        所以可以将交换器理解成一个由绑定构成的路由表，exchange和queue的绑定可以是多对多的关系
    connection：
        网络连接，比如一个tcp连接
    channel：
        信道，多路复用连接中的一条独立双向数据流通道。信道是建立在真是tcp连接内的虚拟连接
基本流程概述：
    1，不管是生产者还是消费者，只会会和rabbitmq建立一条长连接，建立的长连接中有很多channel
    2，生产者发送消息给rabbitmq其中一台虚拟机的交换机
        1）消息主要包含头和体，头中主要携带的信息是route-key路由键
        2）rabbitmq虚拟机作用是可以产生多个rabbitmq服务器相互隔离，来处理不同的业务，比如处理java消息的、处理php消息的
    3，交换机接收到消息后发送给其绑定的队列
    4，然后消费者监听队列，消费队列中的消息
exchange交换机：
    direct：
        消息中的路由键和binding中的binding key一致，交换机就将消息发到对应的队列中。
        路由键与队列名完全一致，如果一个队列绑定到交换机要求路由键为"dog"，则只会转发routing key标记为"dog"的消息
        不会转发"dog.puppy"，也不会转发"dog.guard"等等，它是完全匹配、单播的模式
    fanout：
        每个发到fanout类型交换机的消息都会分到所绑定的队列上。fanout交换机不处理路由键
        只是简单的将队列绑定到交换器上，每个发送到交换器上的消息都会转发到与该交换器绑定的所有队列上
        很像原子广播，fanout类型转发消息是最快的
    topic
        交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配
        此时队列需要绑定在一个模式上，它将路由键和绑定键字符串切分成单词
        这些单词之间用点隔开。她同样也会识别两个通配符，符号"#"和符号"*"，"#"匹配0个或多个单词，"*"匹配一个单词
spring-boot整合
    1，引入依赖spring-boot-starter-amqp, 引入后@RabbitAutoConfiguration就会自动生效
    2，配置连接信息：
        spring.rabbitmq.host=192.168.56.19
        spring.rabbitmq.port=192.168.56.19
        spring.rabbitmq.virtual-host=/
    2，容器中自动配置了：
        RabbitTemplate、AmqpAdmin、CachingConnectionFactory、RabbitMessageTemplate
    3，@EnableRabbit启用rabbitmq
    5，自定义配置，发送消息内容为对象时转为json
            @Configuration
            public class MyTabbitConfig {
                @Bean 
                public MessageConverter messageCPnverter() {
                    return new Jackson2JsonMessageConverter();
                }
            }
    5，测试代码：
        @RunWith(SpringRunner.class)
        @SpringBootTest
        public class GulimallOrderApplicationTests {
            @Autowired
            AmqpAdmin amqpAdmin;
            (1)创建交换机:
                @Test
                public void createExchange() {
                    DirectExchange directExchange = new DirectExchange("hello-java-exchange", true, false); 
                    amqpAdmin.declareExchange(directExchange);
                    log.info("交换机创建成功")
                }
            (2)创建队列
                @Test
                public void createQueue() {
                    Queue queue = new Queue("hello-java-exchange", true, false, false); 
                    amqpAdmin.declareExchange(queue);
                    log.info("队列创建成功")
                }
            (3)创建绑定
                @Test
                public void createBinding() {
                    //destination：目的地、destinationType：目的地类型、exchange：交换机、routinKey：路由键、arguments：自定义参数
                    Binding queue = new Binding("hello-java-queue", Binding.DestinationType.QUEUE, "hello-java-exchange", "hello-java", null); 
                    amqpAdmin.declareBinding(queue);
                    log.info("绑定创建成功")
                }
            (4)发送消息
                @Autowired
                RabbitTemplate rabbitTemplate;
                @Test
                //发送消息
                public void sendMessageTest() {
                    rabbitTemplate.covertANdSend("hello-java-exchange", "hello.java", "Hello Word")
                    log.info("消息发送完成")；
                }
            (5)接收消息 RabbitListener
                @Test
                //接收消息
                //Queue: 可以很多人来监听，只要收到消息，队列删除消息，而且只能有一个收到消息
                    场景：
                        1，订单服务启动多个；同一个消息，只能有一个客户端收到
                        2，只有一个消息完全处理完，方法运行结束，我们才可以接收下一个消息
                @RabbitListener(queues = {"hello-java-queue"})
                public void receiveMessageTest(Message message, //消息头+消息体
                                               OrderReturnReasonEnity orderReturnReasonEnity, //消息体对应的对象
                                               Channel channel//管道
                                               ) {
                    //消息体
                    byte[] body = message.getbody();
                    //消息头信息
                    MessageProperties properties = message.getMessageProperties();
                    log.info("接收到的消息是：" + message);
                }
            (6)接收消息 RabbitHandler
                @RabbitListener(queues = {"hello-java-queue"})
                public class OrderItemServiceImpl impl OrderItemService {
                    @RabbitHandler
                    public void reviceMessage(Message message, OrderReturnReasonEntiy content, Channel chaneel) {
                        Sysout.out.println("消息处理完成" + message);
                    }
                    @RabbitHandler
                    public void reviceMessage(OrdeEntiy content) {
                        Sysout.out.println("消息处理完成" + content);
                    }
                }
        }
消息确认机制（可靠抵达）
    消息保证不丢失，可靠抵达，可以使用消息事务，性能下降250倍，为此引入确认机制
        2，publisher confirmCallback确认模式
        3，publisher returnCallback未投递到queue退回模式
        4，consumer ack机制
        product -----(confirmCakkback)----> Broker Exchange -----(returnCallback)----> Queue -----(ack)----> Consumer
        confirmCallback实现：
            1，开启确认：
                spring-rabbitmq.publisher-confirms=true
            2，配置自定义MyRabbitConfig：
                @Configuration
                public class MyTabbitConfig {
                    @Bean 
                    public MessageConverter messageCPnverter() {
                        return new Jackson2JsonMessageConverter();
                    }
                    (1)定义confirmCallback
                    @PostConstruct //对象创建完成以后，就执行这个方法
                    public void initRabbitTemplate() {
                        rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {
                            /**
                             * 消息每次发送都会触发
                             *@param correlationData 当前消息的唯一关联数据（消息的唯一id）
                             *@param ack 消息是否成功接收
                             *@param cause 失败原因
                             */
                            @Override
                            public void confirm(CorrelationData correlationData, boolean ack, String cause) {
                                System.out.println("confirm......");
                            }
                        });
                    }
                }
        returnCallback实现：
             1，开启确认：
                 spring-rabbitmq.publisher-returns=true
                 spring-rabbitmq.template.mandatory=true
             2，配置自定义MyRabbitConfig：
                 @Configuration
                 public class MyTabbitConfig {
                     @Bean 
                     public MessageConverter messageCPnverter() {
                         return new Jackson2JsonMessageConverter();
                     }
                     (1)定义confirmCallback
                     @PostConstruct //对象创建完成以后，就执行这个方法
                     public void initRabbitTemplate() {
                         rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {
                             /**
                              * 消息没有投递给指定队列，就触发这个失败回调
                              *@param message 投递失败的消息信息
                              *@param replyCode 回复的状态码
                              *@param replyText 回复的文本内容
                              *@param exchange 消息发送给哪个交换机
                              *@param routingKey 所用的路由键
                              */
                             @Override
                             public void confirm(Message message, int replyCode, String replyText, String exchange, String routingKey) {
                                 System.out.println("confirm......");
                             }
                         });
                     }
                 }
        ack实现：
            默认是自动确认的，只要消息接收到，客户端自动确认，服务端就会移除这个消息
                问题：
                    当收到很多消息时，其中有一个消息消费成功发送了ack，这时宕机了，那么其余的消息就会丢失
                解决：
                    手动确认，只有确认后，服务器才会移除消息，即使consumer宕机，消息不会丢失：
                        1，设置：
                            spring-rabbitmq.listener.simple.acknowledge-mode=manual=manual
                        2，在listener里面接收完消息后，确认ack
                            @RabbitListener(queues = {"hello-java-queue"})
                            public void receiveMessageTest(Message message, OrderReturnReasonEnity orderReturnReasonEnity, Channel channel) {
                                //消息体
                                byte[] body = message.getbody();
                                //消息头信息
                                MessageProperties properties = message.getMessageProperties();
                                log.info("接收到的消息是：" + message);
                                //签收消息，非批量模式
                                long deliveryTag = message.getMessageProperties.getDeliveryTag();
                                try {
                                    //接收
                                    channel.basicAck(deliveryTag, false);
                                    //拒收（最后一个参数表示拒收后是否重新入队）
                                    channel.basicNack(deliveryTag, false, false);
                                } catch (Exception e) {
                                    //签收异常，网络中断
                                }
                            }
延时队列
    下单30min未支付，关闭订单
    40min后检查订单是否存在，不存在或取消时解锁库存
    如果定时任务轮询查数据库，增加了系统功耗，存在较大的时间误差（比如每隔30min扫描一次）
    延时队列主要是使用rabbitmq消息的ttl和死信exchange
    消息ttl就是消息的存活时间
        rabbitmq可以对队列和消息分别设置ttl
            - 对队列来说就是设置队列没有消费者连接的保留时间，也可以对单独的消息做单独的设置。超过了这个时间我们就认为这个消息死了，称之为死信
            - 如果队列设置了，消息也设置了，那么就会取小的。
            可以通过设置消息的expiration字段或者x-message-ttl属性来设置时间，两者是一样的效果
    Dead Letter Exchanges（DLX）
        一个消息满足如下条件，会进入死信路由，记住这里是路由而不是队列，一个路由可以对应很多队列
            1，一个消息被consumer拒收，并且reject方法的参数里requeue是false，也就是说不会被再次放在队列里，被其他消费者使用
            2，上面的消息的ttl到了，消费过期了
            3，队列的长度限制满了。排在前面的消息会被丢弃或者扔到死信路由
        DLX其实是一种普通的exchange，和创建其他的exchange一样。只是在某一个设置DLX的队列中有消息过期了，
        会自动触发消息转发，发送到DLX
        我们既可以控制消息在一段时间后变成死信，又可以控制变成死信的消息被路由到某一个指定交换机，结合二者，其实就可以实现一个延时队列
    大致原理：
        给队列设置过期时间、过期后丢给的交换机（死信交换机）、死信交换机路由到的队列
        我们向队列放入消息，过期后就会路由到死信交换机，然后死信交换机会把这些消息路由到新的队列，新的队列里面的消息就是达到延时时间的消息
    最好给队列设置过期时间而不是消息：
        因为rabbitmq采用的是惰性检查机制，比如队列中放入三个消息分别是5min、2min、2s过期，
        rabbotmq会先检查第一个消息发现5min后才过期，那么就会再过5min后再来检查。所以设置了2min、2s过期的消息必须等5min的过期后才来检查，然后发现早已过期就会把三个消息都扔了
    
# 可靠消息（消息丢失、积压、重复等解决方案）
柔性事务-可靠消息-最终一致性解决方案（异步确保型）
实现：
    业务处理服务在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只记录消息数据，而不是真正的发送。
    业务处理服务在业务事务提交后，向实时消息服务确认发送
    只有在得到确认发送指令后，实时消息服务才会真正发送
1，消息丢失：
       （1）消息发送出去后，由于网络问题没有抵达服务器
            1，做好容错方法（try-catch），发送消息可能会网络失败，失败后要有重试机制，可记录到数据库，采用定期扫描重发的方式
            2，做好日志记录，每个消息状态是否被服务器接收都应该记录
            3，做好定期重发，如果消息没有发送成功，定期去数据库扫描未成功的消息进行重发
       （2）消息抵达broker，broker要将消息写入磁盘才算成功。此时broker尚未持久化完成，宕机
            1，publisher也必须加入确认回掉机制，确认成功的消息，修改数据可消息状态
       （3）自动ack的状态下。消费者收到消息，但是还没有来得及消费，宕机
            1，一定开启手动ack，消费成功才移除，失败或者没有来得及处理就noAck重新加入队列
2，消息丢失
    消费成功，事务已经提交，ack时，机器宕机。导致没有ack成功，broker的消息重新由unack变为ready，并发送给其他消费者
        解决：
            1，消费者的业务消费接口应该设计为幂等性。比如扣库存有工作单的状态标志
            2，使用防重表，发送消息每一个都有业务的唯一标识，处理过就不用处理
            3，rabbitmq的每一个消息都有redelivered字段，可以获取是否是被重新投递过来的，而不是第一次投递过来的
3，消息积压
    1，消费者宕机
    2，消费者消费能力不足积压
    3，发送者发送流量太大
        上线更多的消费者，进行正常消费
        上线专门的队列消费服务，将消息先批量取出来，记录数据库，离线慢慢处理
# 秒杀业务
秒杀具有瞬间高并发的特点，针对这一点，必须做到限流+异步+缓存（页面静态化）+独立部署
限流方式：
    1，前段限流：一些高并发网站直接在前段限流，例如小米的验证码设计
    2，nginx限流，直接负载部分请求到错误页面：令牌算法、漏斗算法
    3，网关限流，限流的过滤器
    4，代码中使用分布式信号量
    5，rabbitmq限流（能者多劳：channel.basicQos(1)）,保证发挥所有服务性能
定时上架商品基本流程：
    1，定时任务查询需要上架的秒杀商品
    2，封装最新的秒杀商品信息到redis中
        seckill:skus hash结构 skuId作为key，方便详情页查询秒杀信息（商品基本信息、商品的随机码、结束时间）
        seckill:sessions key:start_endtime,val:[skuIds]
    3，设置秒杀商品分布式信号量作为库存扣减信息
1，代码实现
基本数据类型
    SeckillSessionWithSkus {
        private Long id;
        //场次名称
        private String name;
        //每日开始时间
        private Date startTime;
        //每日结束时间
        private Date endTime
        private Integer status;
        private Date createTime;
        private List<SeckillSkuVo> relationSkus;
    }
    SeckillSkuVo {
        private Long id;
        //活动id
        private Long promotionId;
        //活动场次id
        private Long promotionSessionId;
        //商品id
        private Long skuId;
        //秒杀价格
        private BigDecimal seckillPrice;
        //秒杀总量
        private Integer seckillCount;
        //每人限购数量
        private Integer seckillLimit;
        //排序
        private Integer seckillSort;
        //商品的详细信息
        private Integer seckillSort;
        //当前商品秒杀的开始时间
        private Long startTime;
        //当前商品秒杀的结束时间
        private Long endTime;
        //秒杀商品的随机码
        private String randomCode;
    }
上加最近三天的的秒杀商品信息
    public void uploadSeckillSkuLatest3Days() {
        1，//扫描最近三天需要参与的秒杀活动，feign远程调用
        R session = couponFeignService.getLates#DaySession();
        if (session.getCode() == 0) {
            List<SeckillSessionsWithSkus> sessionData = session.getData(new TypeReference<List<SeckillSessionWithSkus>>(){})
            //缓存到redis
            //1，缓存活动信息
            saveSessionInfos(sessionData);
            //2,缓存活动关联的商品信息
            saveSessionSkuInfos(sessionData);
        }
    }
    public void saveSessionInfos(List<SeckillSessionsWithSkus> sessions) {
        sessions.stream().forEach(session -> {
            Long startTime = session.getStartTime.getTime();
            Long endTime = session.getEndTime.getTime();
            String key = "seckill:sessions" + startTime + "_" + endTime;
            //判断保证幂等性
            if (!redisTemplate.hasKey(key)) {
                List<String> collect = session.getRelationSkus().stream().map(item -> item.getSkuId.toString+ "_" + item.getPromotionSessionId().toString).collect(Collectors.toList());
                //缓存活动信息
                //这里的key是SeckillSessionsWithSkus的开始时间+结束时间，value是关联的商品信息的id集合
                redisTemplate.opsForList().leftpushAll(key, collect);
            }
        });
    }
    public void saveSessionSkuInfos(List<SeckillSessionsWithSkus> sessionData) {
        sessions.stream().forEach(session -> {
            //准备hash操作
            BoundHashOperations<String, Object> ops = redisTemplate.boundHashOps("seckill:skus");
            //判断保证幂等性，上架过后不再进行上架
            if (!ops.hasKey(seckillSkuVo.getPromotionSessionId().toString() + "_" + seckillSkuVo.getSkuId().toString())) {
                sessions.getRelationSkus()stream().forEach(seckillSkuVo -> {
                    //缓存商品
                    SeckSkuRedisTo redisTo = new SeckSkuRedisTo();
                    //1，sku的基本数据
                    R skuInfo = productFeignService.getSkuInfo(skillSkuVo.getSkuId());
                    if (skuInfo.getCode == 0) {
                        SkuInfoVo info = skuInfo.getData("skuInfo", new TypeReference<SkuInfoVO>)
                        redisTo.setSkuInfo(info);
                    }
                    //2，sku的秒杀信息
                    NeanUtils.copyProperties(seckillSkuVo, redisTo);
                    //3，设置当前商品的秒杀时间
                    redisTo.setStartTime(session.getStartTime().getTime());
                    redisTo.setEndTime(session.getEndTime().getTime());
                    //4，设置商品的随机码（只有秒杀开始的时候才暴露出来，否则容易被程序攻击）
                    String token = UUID().randomUUID().toString().replace("-", "");
                    redisTo.setTandomCOde(token);
                    //5,引入分布式信号量
                    RSemaphore semaphore = redissonClient.getSemaphore("seckill.stock" + token);
                    //商品可以秒杀的数量作为信号量,限流
                    semaphore.trySetPermits(seckillSkuVo.getSeckillCount());
                    String jsonString = JSON.toJSONString(redisTo);
                    ops.put(seckillSkuVo.getPromotionSessionId().toString() + "_" + seckillSkuVo.getSkuId().toString(), jsonString);
                });
            }
        });
    }
幂等性处理
    1，定时任务加分布式锁
    public class SeckillSkuScheduled {
        @Autowired
        SeckillService seckillService;
        @Autowired
        RedissonClient redissonClient;
        @Scheduled(cron = "0 * * * * ?")
        public void uploadSeckillSkuLatest3Days() {
            log.info("上架秒杀商品的信息......");
            RLock lock = redissonClient.getLock(upload_lock);
            lock.lock(10, TimeUnit.SECONDS);
            try {
                seckillService.uploadSeckillSkuLatest3Days();
            } finally {
                lock.unlock();
            }
        }
    }
    2，上架商品到redis时，幂等性操作，如果商品已经在redis中存在就不再进行上架
查询秒杀商品：
    public List<SecKillSkuRedisTo> getCurrentSeckillSkus() {
        //1,确定当前时间属于哪一个秒杀场次
        long time = new Date().getTime();
        Set<String> keys = redisTemplate.keys("seckill:sessions:*");
        for (String key : keys) {
            String replace = key.replace("seckill:sessions:");
            String[] s = reolace.split("_");
            Long start = Long.parselong(s[0]);
            Long end = Long.parselong(s[1]);
            if (time >= start && time <= end) {
                //2，获取这个秒杀场次需要的所有商品信息
                redisTemplate.opsForList().range(key, -100, 100);
                BoundHashOperations<String, Object, Object> hashOps = redisTemplate.boundHashOps("seckill:skus");
                List<Object> list = hashOps.multiGet(Collections.singLeton(range));
                if (list != null) {
                    List<SecKillSkuRedisTo> collect = list.stream().map(item -> {
                        SeckillSkuRedisTo redisTo = JSON.parseObject((String)item, SeckillSkuRedisTo.class);
                        reutnr redis;
                    }).collect(Collectors.toList());
                    return collect;
                }
            }
        }
    }
秒杀商品：
    1，秒杀，高并发系统关注的问题
        1，服务单一职责+独立部署
            秒杀服务即使自己扛不住、挂掉。不要影响别人
        2，秒杀连接加密（设置商品随机码）
            防止恶意攻击、模拟秒杀请求、1000/s攻击
            防止连接暴露，给自己工作人员。提前秒杀商品
        3，库存预热+快速扣减（redis缓存库存，以及设置信号量）
            秒杀读多写少，无需每次校验库存。我们库存预热，放到redis中。信号量控制进来的秒杀请求
        4，动静分离（CDN）
            nginx做好动静分离。保证秒杀和商品详情页的动态请求才能打到后端的服务集群
        5，恶意请求拦截
            识别非法攻击进行拦截
        6，流量错峰
            使用各种手段，将流量分担到更大的时间宽度的时间点。比如验证码，加入购物车
        7，限流&熔断&降级
            前段限流+后端限流
            限制次数、限制总量，快速失败降级运行，熔断隔离防止雪崩
        8，队列削峰
            1w个商品，每个1000件秒杀。双11所有秒杀成功的请求，进入队列，慢慢创建订单，扣减库存即可
秒杀代码实现：
    public String kill (String killId, String key, Integer num) {
        MemberRespVo respVo = LoginUserInterceptor.LoginUser.get();
        BoundHashOperations<String, Object, Object> hashOps = redisTemplate.boundHashOps("seckill:skus");
        String json = hashOps.get(killId);
        if (StringUtils.isEmpty(json)) {
            return null;
        } else {
            SeckillSkuRedisTo redis = JSON.parseObject(json, SecKillSkuRedisTo.class);
            //校验合法性
            Long startTime = redis.getStartTime();
            Long endTime = redis.getEndTime();
            long time = new Date().getTime();
            long ttl = endTime - time;
            //1，校验时间的合法性
            if (time >= startTime && time <= endTime) {
                //2，校验随机码和商品id
                Long randomCode = redis.getRandomCode();
                Long skuId = redis.getPromotionSessionId() + "_" + redis.getSkuId();
                if (randomCode.equals(key) && killId.equals(skuId)) {
                    //3，验证购物数量是否合理
                    if (num <= redis.getSeckillLimit() {
                        //4，验证这个人是否已经购买过。幂等性；如果秒杀成功就去占位。userId_sessionId_skuId
                        //SETNX
                        Strign redisKey = respVo.getId() + "" + redis.getPromotionSessionId() + "_" + redis.getSkuId();
                        //自动过期，过期时间就是场次结束时间
                        Boolean aBoolean = redisTemplate.opsForValue().setIfAbsent(redisKey, num.toString, ttl, TimeUnit.MICROSECONDS);
                        if (aBoolean) {
                            //占位成功说明从来没有买过
                            Rsemaphore semaphore = redissonClient.getSemaphore("seckill.stock:" + randomCode);
                            try {
                                boolean b = semaphore.tryAcquire(num, 100, TimeUnit.MILLISECONDE);
                                if () {
                                    //秒杀成功，快速下单
                                    //生成订单号
                                    String timeId = IdWorker.getTimeId();
                                    SecKillOrderTo orderTo = new SeckillOrderTo();
                                    //订单号
                                    orderTo.setOrderSn(timeId);     
                                    //会员id                
                                    orderTo.setMemberId(respVo.getId());
                                    //购买数量
                                    orderTo.setNum(num);
                                    //活动场次id
                                    orderTo.setPromotionSessionId(redis.getPromotionSessionId());
                                    //商品id
                                    orderTo.setSkuId(redis.getSkuId());
                                    //秒杀价格
                                    orderTo.setseckillPrice(redis.getSeckillPrice());
                                    //生成这些信息发送给队列然后完成订单的创建
                                    rabbitTemplate.convertAndSend("order-event-excahnge", "order.seckill.order", orderTo);
                                    return timeId;
                                }
                            } catch (Exception e) {
                                return null;
                            }
                            semaphore.acquire(num);
                        } else {
                            return null;
                        }
                    }
                } else {
                    return null;
                }
            } else {
                return null;
            }
        }
    }
队列监听，创建真正的订单
    public class orderSeckillListener {
        @Autowired
        OrderService orderService;
        #RabbitHandler
        public void listeber(SeckillOrderto seckillOrder, Channel channel, Message message) {
            try {
                orderService.createSeckillOrder(seckillOrder);
                //手动调用支付宝收单
                channel.basicAck(message.getMessageProperties().getDeliveryTag(), false);
            }
        }
    }

# Sentinal（熔断、降级、限流）
1，什么是熔断
    a服务调用b服务的某个功能，由于网路不稳定，或者b服务卡机，导致功能时间超长。如果这样的次数过多。我们就可以直接将b断路了（a不再请求b接口）
    凡是调用b的直接返回数据，不必等待b超长执行。这样b的故障问题，就不会及联影响到a
2，什么是降级
    整个网站处理流浪高峰期，服务器压力剧增，根据当前业务场景及流量，对一些服务和页面进行有策略的降级（停止服务，所有的调用直接返回降级数据）。
    以此缓解服务器资源的压力，以保证核心业务的正常执行，同时保持了客户和大部分客户得到正确的响应
3，异同
    相同点：
        1，为了保证集群大部分核心业务的可用性，防止崩溃，牺牲小我
        2，用户最终体验到某个功能不可以
    不同点：
        1，熔断是被调用方故障，触发的系统主动规则
        2，降级是基于全局考虑，停止一些正常服务，释放资源
4，Hystrix和Sentinel比较
    功能                     sentinel                 hystrix
  隔离策略              信号量隔离（并发线程数限流）   线程池隔离/信号量隔离
  熔断降级策略          基于响应时间、异常比率、异常数    基于异常比例
  实时统计实现            滑动窗口（LeaoArray）        滑动窗口（基于RxJava）
  动态规则匹配            支持多种数据源               支持多种数据源
  扩展性                  多个扩展节点                插件形式
  基于注解支持              支持                       支持
  限流              基于QPS，支持基于调用关系的限流      有限的支持
  流量整形          支持预热模式、匀速模式、预热派对模式    不支持
  系统自适应保护            支持                         不支持
  控制台           可配置规则、查看秒级监控、机器发现    简单的监控查看
5，Sentinal
    Sentinal可以简单的分为Sentinal核心库和Dashboard，核心库不依赖Dashboard，但是结合Dashboard可以取得最好的效果
    我们说的资源可以是任何东西，服务、服务里面的方法，甚至是一段代码。使用Sentinel来进行资源保护，主要分为以下几个步骤：
        1，定义资源
        2，定义规则
        3，校验规则是否生效
    先把可能需要保护的资源定义好，之后再配置规则，也可以理解为，只要有了资源，我们就可以在任何时候灵活的定义各种流量控制规则
    在编码的时候，只需要考虑这个代码是否需要保护，如果需要保护，就将之定义为一个资源
    对于主流框架，我们提供适配，只需要按照适配中心说明配置，Sentinel就会默认定义提供好的服务，方法等为资源
6，定义资源
    方式一：
        主流框架默认适配
        为了减少开发的复杂程度，我们对大部分主流框架，例如Web Servlet、Double、Spring Cloud、gRPC、Spring WebFlux、Reactor等都做了适配
        只需要引入对应的依赖即可方便的整合Sentinel
    方式二：
        抛出异常的方式定义资源
        SphU包好了try-catch风格的api。用这种方式，当资源发生了限流之后会抛出BlockException。这个时候可以捕捉异常，进行限流之后的逻辑处理，示例代码如下：
            //资源名可以使用任意有业务语义的字符串，比如方法名，接口名或其他唯一标识的字符串
            try (Entry entry = SphU.entry("resourceName")) {
                //被保护的业务逻辑
            } catch (BlockException ex) {
                //资源访问阻止，被限流或者降级
                //在此处进行相应地处理操作
            }
        特别地，若entry的时候传入了热点参数，那么exit的时候也一定要带上对应的参数(exit(count, args))，否则可能会有统计错误
        这时候不能使用try-with-resources的方式。另外通过Tracer.trace(ex)来统计异常信息时，由于try-with-resources的catch块中调用Tracer.trace(ex)
    方法三：
        Sentinel支持通过@SentinelResource注解定义资源并配置blockHandler和fallback函数来进行限流之后的处理，示例：
            //原本的业务方法
            @SentinelResource(blockHandler = "blockHandlerForGetUser")
            public User getUserById(String id) {
                throw new RuntimeException("getUserById command failed")
            }
            //blockHandler函数，原方法调用被限流/降级/系统保护的时候被调用
            public User blockhandlerForGetUser(String id, BlockException ex) {
                return new User("admin");
            }
         注意blockHandler函数会在原方法被限流/降级/系统保护的时候调用，而fallback函数会针对所有类型的异常。请注意blockHandler和fallback函数的形式要求
7，整合Spring Boot（主流框架默认适配）
    1，引入依赖
        spring-cloud-starter-alibaba-sentinel
    2，下载sentinel服务端启动
    3，配置sentinel控制台地址信息
        spring.cloud.sentinel.transport.dashboard=localhost:8333
        spring.cloud.sentinel.transport.port=8719
    这样就可以用sentinel控制台调整参数，进行熔断、降级了。但是配置完成后都保存在内存中，重启失效
    4，开启sentinel控制台实时监控
        1，导入Spring的审计模块
            spring-boot-starter-actuator
        2，在配置文件中允许Endpoints访问
            management.endpoints.web.exposure.incloud=*
    5，自定义被限制后返回的错误信息
        @Configuration
        public class SeckillSentinelConfig {
            public ScekillSentingConfig() {
                WebCallbackManager.setUrlBlockHandler(new UrlBlockHandler(){
                    @Override
                    public void blocked(HttpServletRequest request, HttpServletResponse response, BlockException blockException) {
                        R error = R.error(BizCodeEnume.TOO_MANY_REQUESY.getCode(), BizCodeEnume.TOO_MANY_REQUESY.getMsg());
                        response.getWriter().write(JSON.toJSONString(error));
                    }
                });
            }
        }
8，客户端进行流量控制
    1，是否集群
    2，集群阀值模式（单机均摊、总体阀值）
    3，流控模式（直接、关联、链路）
        链路：比如有一个服务C，A->C还有F->C，如果是流控模式是直接的话只要调用了C就会收到流控
            但是如果设置了链路（这种模式需要设置入口路径），比如设置链路入口为A，那么只有A->C才会流控，而F->C则不会受到流控
        关联：
            当两个资源之间具有资源争抢或者依赖关系的时候，这两个资源便具有了关联。
            比如对数据库同一个字段的读操作和写操作存在争抢，读的速度过高会影响写的速度，写的速度过高会影响读的速度
            如果放任读写争抢资源，则争抢本身的开销会降低整体的吞吐量。
            可以使用关联限流来避免具有关联关系的资源之间过度争抢
            举例来说：
                read_db和write_db这两个资源分别代表数据库读写，我们可以给read_db设置限流来达到写优先的目的：
                设置FlowRule.strategy为RuleConstant.RELATE，同时设置FlowRule.ref_identity为write_db。
                这样写操作过于频繁时，读数据的请求会被限流
    4，流控效果
        1，直接拒绝
            达到阈值后直接返回失败信息
        2，warm up
            让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热时间，避免冷系统被压垮
        3，排队等待
            达到阈值后，后面的请求排队等待，分批处理
    5，熔断降级
        1，开启feign的sentinel功能
            feign.sentinel.enabled=true
        2，配置失败回调
            @FeignClient(value = "gulimall-seckill", fallback = SeckillFeignServiceFallBack.class)
            public interface SeckillFeignService {
                @GetMapping("/sku/seckill/{skuId}")
                R getSkuSeckillInfo(@PathVarible("skuId") Long skuId);
            }
        3，配置降级策略
            1，平均响应时间
                当1s内持续进入5个请求，对应的平均响应时间超过阈值RT，那么接下来窗口期内这个请求都会进行熔断降级
            2，异常比例
            3，异常数
        超大流量的时候，必须牺牲一些远程服务。在服务的提供方（远程服务）指定降级策略；提供方是在运行，但是不运行自己的业务逻辑，返回的是熔断数据
        在提供方进行熔断都是全局考虑了
    6，自定义受保护的资源
        1，代码片段流控
            try (Entry entry = SphU.entry("seckillSkus")) {
                //代码实现，这部分资源就加入到了sentinel，将被sentinel控制
            } catch (BlockException e) {
                log.info("资源被限流");
            }
        2，注解流控
            @SentinelResource(value = "getCurrentSeckillSkus", blockHandler = "blockHandler", fallback = "fallback")
            public List<SecKillSkuRedisTo> getCurrentSeckillSkus() {}
            (1) blockHandler对超过阈值后的返回值进行容错，是针对这个资源的回调，返回结果必须和getCurrentSeckillSkus方法返回结果一直
                public List<SecKillSkuRedisTo> blockHandler(BlockException e) {
                    log.error("getCurrentSeckillSkus被限流.........");
                    return null;
                }
            (2) fallback主要配置的是全局的异常处理
    7，网关流控
        sentinel支持对Spring cloud Gateway、zuul等主流框架等主流API Getway进行限流
        1，在网关微服务中加入spring-cloud-alibaba-sentinel-getway依赖
        2，然后就可以在sentinel中对网关服务进行流控了（对比其他服务有一个API管理模块）
        3，网关流控回调
            1，这是回调配置文件
                @Configuration
                public class SentinelGatewayConfig {
                    public SentinelGatewayConfig () {
                        GatewayCallbackManager.setBlockHandler(new BlockRequestHandler() {
                            @Override
                            public Mono<ServerResponse> handleRequest(ServerWebExchange exchange, Throwable t) {
                                R error = R.error(BizCodeEnum.TOO_MANY_REQUEST.getCode(), BizCodeEnum.TOO_MANY_REQUEST.getMsg());
                                String errJson = JSON.toJSONString(error);
                                Mono<ServerResponse> body = ServerResponse.ok().body(Mono.just(errJson), String.class);
                                return body;
                            }
                        });
                    }
                }
9，sleuth + zipkin服务链路追踪
    1，为什么用：
        微服务架构是一个分布式架构，它按业务划分服务单元，一个分布系统往往有很多服务单元。由于服务单元数量众多，业务的复杂性。如果出现了错误和异常，很难去定位。
        主要体现在，一个请求可能需要调用很多个服务，而内部服务的调用复杂性，决定了问题难以定位。
        所以微服务架构中，必须实现分布式链路追踪，去跟进一个请求到底有哪些服务参与，参与的顺序又是怎样
        链路追踪组件有Google的Dapper，Twitter的zipkin，以及阿里的Eagleeye等
    2，基本术语
        Span（跨度）：
            基本工作单元，发送一个远程任务调度，就会产生一个Span，Span是一个64位ID唯一标识
            trace是用另一个64位id标识的，Span还有其他数据信息，比如摘要、时间戳、Span的ID以及时间进度ID
        Trace（跟踪）：
            一系列Span组成的一个树状结构。请求一个微服务系统的api接口，这个api接口需要调用多个微服务
            调用每个微服务都会产生一个span，所有由这个请求产生的span组成了这个trace
        annotation（标注）：
            用来及时记录一个事件的，一些核心注解用来定义一个请求的开始和结束，主要注解包括以下：
                cs（client sent）：客户端发送一个请求-这个注解描述了这个span的开始
                sr（server received）: 服务端获得请求并准备处理它-如果将其sr减去cs时间戳便可得到网络传输事件
                ss（server sent）：服务端发送响应-该注解表明请求处理的完成（当请求返回客户端），如果ss的时间戳减去sr的时间戳就可以得到服务器请求时间
                cr（client received）：客户端接收响应-此时span的结束，如果cr时间戳减去cs时间戳便可以得到整个请求所消耗的时间
    3，链路追踪步骤：
        1，引入依赖：spring-cloud-starter-sleuth
        2，打开debug日志：
            logging.level.org.springframework.cloud.openfeign=debug
            logging.level.org.springframework.cloud.sleuth=debug
    4，zipkin可视化观察
        通过sleuth产生的调用链监控信息，可以得知微服务之间的调用链路，但是只输出到控制台不方便查看
        zipkin是图形化工具，是twitter开源分布式跟踪系统
        1，引入依赖：
            spring-cloud-starter-zipkin
        2，添加zipkin相关配置
            spring.zipkin.base-url=http://192.168.56.10:9411/
            //关闭自己的服务发现功能
            spring.zipkin.discovery-client-enabled=false
            spring.zipkin.sender.type=web
            spring.sleuth.sampler.probability=1
# K8s
Kubernetes，是用于自动部署，扩展和管理容器化应用的开源系统
基本架构：
    k8s集群由master节点、多个工作节点和ETCD组成，其中ETCD作为集群状态存储。
    master节点负责整个集群管理工作，为集群提供管理api，并负责编排和监控各工作节点
    各工作节点以Pod形式管理运行容器。
    master主要有apiserver、controller-manager、scheduler三个组件组成，同时负责与etcd交互存储集群状态数据，
    而每个工作节点主要包括kubelet、kube-proxy以及容器引擎（最常见的是docker）等组件
master节点：
    apiserver：对外提供restful api，k8s集群网关
    Controller：Pod控制器，k8s通过控制器来管理Pod资源，控制器包括ReplicationController、ReplicaSet、Deployment、StatefulSet、Job等，每种controller都有对应的功能（比如Deployment是最常见的无状态应用的控制器，它支持应用的扩缩容、滚动更新等操作，为容器化应用赋予了极具弹性的功能）；
    Scheduler：k8s调度器，k8s管理成千上万容器资源，apiserver接收到请求后由scheduler按照对应的调度策略进行不同node间的请求调度操作
    etcd：k8s集群状态都存储在etcd中（通过apiserver共享给集群的各个组件和客户端），通过etcd的watch机制来进行k8s各个组件的协同操作，一般etcd通过集群部署方式保证高可用
node节点：
    node节点接受master管理，负责管理各个pod资源
    kubelet：kubelete是node的守护进程，node接受master的管控，kubelet会向apiserver注册当前node，定期向master汇报node资源占用情况
    容器运行环境：node会提供一个容器运行环境，负责下载运行容器，k8s目前支持的容器运行环境包括docker、RKT、cri-o和Fraki
    kube-proxy：每个node都需要一个kube-proxy进程，比如对service按需生成iptables或ipvs规则，控制流量访问
1，基础模块：
    创建一个Kubernetes集群
    部署应用程序
    应用程序探索
    应用外部可见
    应用可扩展
    应用更新
2，容器时代：
    容器类似于VM，但是由于他们具有轻量级的隔离属性，可以在应用程序之间共享操作系统。因此，容器被认为是轻量级的。
    容器与VM类似，具有自己的文件系统、CPU、内存、进程空间。因此可以跨云和os分发进行移植
3，优点：
    敏捷应用程序的创建和部署：与使用VM镜像相比，提高了容器镜像创建的简便性和效率
    持续开发、集成和部署：通过简单的回滚（由于镜像不可变），提供可靠且频繁的容器镜像构建和部署
    关注开发和运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像，从而将应用程序与基础架构分离
    可观察性不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号
    跨开发、测试和生产的环境一致性：在便携式计算机上和云中相同地运行
4，主要功能：
    服务发现和负载均衡
        Kubernetes可以使用DNS名称或自己的IP地址公开容器，如果容器流量很大，Kubernetes可以负载均衡并分配网络流量，从而使部署稳定
    存储编排：
        Kubernetes允许自动挂载存储系统，例如本地存储、公共云提供商
    自动部署和回滚：
        可以使用Kubernetes描述已部署容器所需的状态，他可以以受控的速率将实际状态改为所需状态
        例如可以自动化Kubernetes来为你的容器部署创建新容器，删除所有现有容器并将他们所有资源用于新容器
    自动二进制打包：
        允许指定每个容器所需的CPU和内存。当容器指定资源请求时，Kubernetes可以做出更高的决策来管理容器资源
    自我修复：
        Kubernetes重启失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并在准备好服务之前不将其通告给客户端
    密匙与配置管理：
        Kubernetes允许存储和管理敏感信息，例如密码、Oauth令牌和ssh密匙。可以在不重建容器镜像的情况下部署和更新密匙和应用程序配置
        也无需在堆栈配置中暴露密匙
5，主要组件：
    Master组件（主节点）
        kube-apiserver:
            对外暴露k8s的api接口，是外界进行资源访问的唯一接口
        etcd：
            是兼具一致性和高可用性的键值数据库，可以作为保存k8s所有集群数据的后台数据
        kube-scheduler：
            主节点上的组件，该组件监视那些新创建的未指定运行节点的pod，并选择节点让pod在上面运行
            所有的k8s集群操作，都必须经过主节点进行调度
        kube-controller-manager
            在主节点上运行控制器的组件，从逻辑上讲，每个控制器都是一个单独的进程，但是为了降低复杂性，它们被编译到同一个可执行文件，并在一个进程中运行
            这些控制器包括：
                节点控制器：负责节点出现故障时进行通知和响应
                副本控制器：负责为系统中每个副本控制器对象维护正确数量的pod
                端点控制器：填充端点对象（即加入service与pod）
                服务账户和令牌控制器：为新的命名空间创建默认账户和API访问令牌
    Node组件
        kubelet
            一个在集群中每个节点上运行的代理。保证容器都运行在pod中
            负责维护容器的生命周期，同时负责Volume和网络管理
        kube-proxy
            负责为service提供cluster内部服务发现和负载均衡
        容器运行环境（Container Runtime）
            容器运行环境是负责运行容器的软件
            Kubernetes支持多个容器运行环境：Docker、containerd、cri-o、rktlet以及任何实现Kubernetes CRI
        fluentd：
            是一个守护进程，有助于提供集群层面日志
    插件Addons
6，主要概念
    container：容器，可以是docker启动的一个容器
    pod：
        k8s使用pod来组织一组容器，一个pod中所有的容器共享同一网络，pod是k8s中最小部署单元
        k8s管理的最小调度单元，k8s不直接来管理容器，使用一个抽象的资源对象来封装一个或者多个容器，这个抽象即为Pod。
        同一Pod中的容器共享网络名称空间和存储资源，这些容器可经由本地回环接口lo直接通信，同时对于Mount、User及PID等资源也进行了隔离；
    volume
        声明在pod容器中可访问的文件目录
        可以被挂载在pod中一个或多个容器指定路径下
        支持多种后端存储抽象（本地存储、分布式存储、云存储）
    controllers：
        Pod控制器，尽管Pod是k8s的最小调度单元，但用户通常并不会直接部署及管理Pod对象，而是要借助于另一类抽象——控制器（Controller）对其进行管理
        k8s的控制器包括ReplicationController、ReplicaSet、Deployment、StatefulSet、Job等，每种controller都有对应的功能（比如Deployment是最常见的无状态应用的控制器，它支持应用的扩缩容、滚动更新等操作，为容器化应用赋予了极具弹性的功能）；
            replicaSet：确保预期的pod副本数量
            Deployment：无状态应用部署
            StatefulSet：有状态应用部署
            DaemonSet：确保所有的node都运行一个指定的pod
            job：一次性任务
            cronjob：定时任务
    Ingress
        k8s中将Pod进行了网络隔离，如果需要开放一些Pod供外部使用，则需要一个配置一个流量进入k8s集群内的通道，除了Service外，Ingress也是实现策略之一。
    service：
        定义一组pod访问策略，pod负载均衡，提供一个或者多个pod稳定访问地址
        Service是建立在一组Pod对象之上的资源抽象，它通过标签选择器选定一组Pod对象，并为这组Pod对象定义一个统一的固定访问入口（通常是一个IP地址）
    label
        用于对象资源查询、筛选
    namespace：命名空间、逻辑隔离
        一个集群内部的逻辑隔离机制（鉴权、资源），每个资源都属于一个namespace
        同一个namespace所有资源名不能重复，不同namespace可以资源名重复
        名称是网络资源的唯一标识符，通常在一个命名空间内，名称标识是唯一的，名称空间通常用于实现租户或项目的资源隔离，从而形成逻辑分组；
7，流程描述
    1，通过k8s提交一个创建RC的请求，还请求通过APIServer被写入etcd中
    2，此时Controller Manager通过API Server监听资源变化的接口监听到此RC事件
    3，分析之后，发现当前集群中还没有它所对应的pod实例
    4，于是根据RC里的pod模版定义生成一个pod对象，通过APIServer写入etcd
    5，此事件被scheduler发现，它立即执行一个复杂的调度流程，为这个新的pod选定一个落户的node，然后通过api server将这一结果写入到etcd中
    6，目标node上运行的kubelet进程通过apiserver监听到这个新生的pod，并按照他的定义，启动该pod并任劳任怨的负责他的下半生，直到pod生命周期结束
    7，随后，我们通过kubectl提交一个新的映射到该pod的service的创建请求
    8，controllermanager通过label标签查询到相关联的pod实例，然后生成service的endpoints信息，并通过APIserver写入到etcd中
    9，接下来，所有node上运行的proxy进程通过APIserver查询并监听service对象与起对应的endpoints信息，建立一个软件方式的负载均衡器实现service访问到后端pod的流量转发功能
8，入门使用
    1，部署一个tomcat
        kubectl create deployment tomcat6 --image=tomcat.6.0.53-jre8
        kubectl get pods -o wide 可以获取到tomcat信息
    2，暴露nginx服务
        kubectl expose deployment tomcat6 --port=80 --target-port=8080 --type=NodePort
        Pod的80映射容器的8080；service会代理Pod的80
    3，动态扩容测试
        kubectl get deployment   
        应用升级：kubectl set image(--help 查看帮助)
        扩容：kubectl scale --replicas=3 deployment tomcat6
        扩容了多分，所有无论访问哪一个node的指定端口，都可以访问到tomcat6
    4，以上操作的yaml获取
    参照k8s细节
    5，删除
    kubectl get all
    kubectl delete deploy/nginx
    kubectl delete service/nginx-service
    流程：创建deployment会管理replicas，replicas控制pod数量，有pod故障会自动拉起新的pod
9，yml基本使用
10，pod、service等概念    
    1，pod和控制器
        控制器可以为您创建和管理多个pod，管理副本和上线，并在集群范围内提供自修复能力
        例如：如果一个节点失败，控制器可以在不同的节点上调度一样的替身来自动切换pod
        包含一个或多个pod的控制器一些示例包括：
            deployment
            StatefulSet
            DaemonSet
        控制器通常使用您提供的pod模版来创建它所负责的pod  
        一个节点里面有许多的pod
        
# 集群的基础形式
    1，主从式
        主从复制，同步方式（从节点复制主节点中的数据，访问落到各个节点）
        主从调度，控制方式（主节点调度所有的请求，分散到各个从节点）
    2，分片式
        数据分片存储，片区之间备份
    3，选主式
        为了容灾选主，为了调度选主
    
# 什么情况下需要用到分布式锁
1，全局ID的生成；
2，全局配置文件的修改；
3，分布式服务中的秒杀问题；
4，分布式环境下的重复提交;
    
# 雪花算法 
分布式系统中有时候需要全局唯一ID的场景，这时候可以使用uuid，但是uuid一般是无序的，有时候我们希望使用一些简单的id，并按照时间顺序有序生成
结构
    它产生的是一个64bit的id，这64bit中划分为多段：
    第一个bit位：保留位，无实际作用
    第2-42的bit位：这41位表示时间戳，精确到毫秒级别(41位的长度可以使用69年)
    第43-52的bit位：这10位表示专门负责生产ID的工作机器的id（10位的长度最多支持部署1024个节点）
    第53-64的bit位：这12位表示序列号，也就是1毫秒内可以生成2的12次方个不同的ID
优点：
    毫秒数在高位，自增序列在低位，整个ID都是趋势递增的
    作为DB主键，效率高
    不依赖第三方系统，以服务的方式部署，稳定性高，生成ID的性能也是非常高
    高性能高可用：生成时不依赖数据库，完全在内存中生成
    容量大，每秒生成数百万个自增ID
    可以根据自身业务特性分配bit位，非常灵活
缺点：
    强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务处于不可用状态
    不是严格全局递增的
时钟回拨问题：
    保存过去一段时间内每一台机器在当前这一毫秒产生的ID的最大值，比如使用Map形式，就是<machine_id,max_id>，这样如果某台机器发生了时钟回拨，直接在这台机器对应的max_id的基础上继续自增生成ID即可。
第 1 个bit：是不用的，为啥呢？
    因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
    
# eureka
整体上可以分为两个主体：Eureka Server 和 Eureka Client。 
Eureka Server：注册中心服务端
    注册中心服务端主要对外提供了三个功能：
        服务注册
            服务提供者启动时，会通过 Eureka Client 向 Eureka Server 注册信息，Eureka Server 会存储该服务的信息，Eureka Server 内部有二层缓存机制来维护整个注册表
        提供注册表
            服务消费者在调用服务时，如果 Eureka Client 没有缓存注册表的话，会从 Eureka Server 获取最新的注册表
        同步状态
            Eureka Client 通过注册、心跳机制和 Eureka Server 同步当前客户端的状态。
Eureka Client：注册中心客户端
    Eureka Client 是一个 Java 客户端，用于简化与 Eureka Server 的交互。Eureka Client 会拉取、更新和缓存 Eureka Server 中的信息。因此当所有的 Eureka Server 节点都宕掉，服务消费者依然可以使用缓存中的信息找到服务提供者，但是当服务有更改的时候会出现信息不一致。
    Register: 服务注册
        服务的提供者，将自身注册到注册中心，服务提供者也是一个 Eureka Client。当 Eureka Client 向 Eureka Server 注册时，它提供自身的元数据，比如 IP 地址、端口，运行状况指示符 URL，主页等。
    Renew: 服务续约
         Eureka Client 会每隔 30 秒发送一次心跳来续约。 通过续约来告知 Eureka Server 该 Eureka Client 运行正常，没有出现问题。 默认情况下，如果 Eureka Server 在 90 秒内没有收到 Eureka Client 的续约，Server 端会将实例从其注册表中删除，此时间可配置，一般情况不建议更改。
         服务续约的两个重要属性
             服务续约任务的调用间隔时间，默认为30秒
             eureka.instance.lease-renewal-interval-in-seconds=30
             服务失效的时间，默认为90秒。
             eureka.instance.lease-expiration-duration-in-seconds=90
    Eviction 服务剔除
        当 Eureka Client 和 Eureka Server 不再有心跳时，Eureka Server 会将该服务实例从服务注册列表中删除，即服务剔除。
    Cancel: 服务下线
        Eureka Client 在程序关闭时向 Eureka Server 发送取消请求。 发送请求后，该客户端实例信息将从 Eureka Server 的实例注册表中删除。该下线请求不会自动完成，它需要调用以下内容：
        DiscoveryManager.getInstance().shutdownComponent()；
    GetRegisty: 获取注册列表信息
        Eureka Client 从服务器获取注册表信息，并将其缓存在本地。客户端会使用该信息查找其他服务，从而进行远程调用。该注册列表信息定期（每30秒钟）更新一次。每次返回注册列表信息可能与 Eureka Client 的缓存信息不同，Eureka Client 自动处理。
        如果由于某种原因导致注册列表信息不能及时匹配，Eureka Client 则会重新获取整个注册表信息。
        Eureka Server 缓存注册列表信息，整个注册表以及每个应用程序的信息进行了压缩，压缩内容和没有压缩的内容完全相同。
        Eureka Client 和 Eureka Server 可以使用 JSON/XML 格式进行通讯。在默认情况下 Eureka Client 使用压缩 JSON 格式来获取注册列表的信息。
        获取服务是服务消费者的基础，所以必有两个重要参数需要注意：
            # 启用服务消费者从注册中心拉取服务列表的功能
            eureka.client.fetch-registry=true
            # 设置服务消费者从注册中心拉取服务列表的间隔
            eureka.client.registry-fetch-interval-seconds=30
    Remote Call: 远程调用
        当 Eureka Client 从注册中心获取到服务提供者信息后，就可以通过 Http 请求调用对应的服务；服务提供者有多个时，Eureka Client 客户端会通过 Ribbon 自动进行负载均衡。
自我保护机制
    默认情况下，如果 Eureka Server 在一定的 90s 内没有接收到某个微服务实例的心跳，会注销该实例。
    但是在微服务架构下服务之间通常都是跨进程调用，网络通信往往会面临着各种问题，比如微服务状态正常，网络分区故障，导致此实例被注销。
    固定时间内大量实例被注销，可能会严重威胁整个微服务架构的可用性。为了解决这个问题，Eureka 开发了自我保护机制，那么什么是自我保护机制呢？
        Eureka Server 在运行期间会去统计心跳失败比例在 15 分钟之内是否低于 85%，如果低于 85%，Eureka Server 即会进入自我保护机制。
        Eureka Server 进入自我保护机制，会出现以下几种情况：
            1，Eureka 不再从注册列表中移除因为长时间没收到心跳而应该过期的服务
            2，Eureka 仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上(即保证当前节点依然可用)
            3，当网络稳定时，当前实例新的注册信息会被同步到其它节点中
        Eureka 自我保护机制是为了防止误杀服务而提供的一个机制。当个别客户端出现心跳失联时，则认为是客户端的问题，剔除掉客户端；
        当 Eureka 捕获到大量的心跳失败时，则认为可能是网络问题，进入自我保护机制；当客户端心跳恢复时，Eureka 会自动退出自我保护机制。
        如果在保护期内刚好这个服务提供者非正常下线了，此时服务消费者就会拿到一个无效的服务实例，即会调用失败。对于这个问题需要服务消费者端要有一些容错机制，如重试，断路器等
        开启或者关闭保护机制：
            eureka.server.enable-self-preservation=true
集群原理
    我们假设有三台 Eureka Server 组成的集群，第一台 Eureka Server 在北京机房，另外两台 Eureka Server 在深圳和西安机房。这样三台 Eureka Server 就组建成了一个跨区域的高可用集群，只要三个地方的任意一个机房不出现问题，都不会影响整个架构的稳定性。
    Eureka Server 集群相互之间通过 Replicate 来同步数据，相互之间不区分主节点和从节点，所有的节点都是平等的。在这种架构中，节点通过彼此互相注册来提高可用性，每个节点需要添加一个或多个有效的 serviceUrl 指向其他节点。
    如果某台 Eureka Server 宕机，Eureka Client 的请求会自动切换到新的 Eureka Server 节点。当宕机的服务器重新恢复后，Eureka 会再次将其纳入到服务器集群管理之中。当节点开始接受客户端请求时，所有的操作都会进行节点间复制，将请求复制到其它 Eureka Server 当前所知的所有节点中。
    另外 Eureka Server 的同步遵循着一个非常简单的原则：
        只要有一条边将节点连接，就可以进行信息传播与同步。
        如果存在多个节点，只需要将节点之间两两连接起来形成通路，那么其它注册中心都可以共享信息
        每个 Eureka Server 同时也是 Eureka Client，多个 Eureka Server 之间通过 P2P 的方式完成服务注册表的同步。
    Eureka Server 集群之间的状态是采用异步方式同步的，所以不保证节点间的状态一定是一致的，不过基本能保证最终状态是一致的。
分区：
    Eureka 提供了 Region 和 Zone 两个概念来进行分区，这两个概念均来自于亚马逊的 AWS:
    region：
        可以理解为地理上的不同区域，比如亚洲地区，中国区或者深圳等等。没有具体大小的限制。根据项目具体的情况，可以自行合理划分 region。
    zone：
        可以简单理解为 region 内的具体机房，比如说 region 划分为深圳，然后深圳有两个机房，就可以在此 region 之下划分出 zone1、zone2 两个 zone。
    Zone 内的 Eureka Client 优先和 Zone 内的 Eureka Server 进行心跳同步，同样调用端优先在 Zone 内的 Eureka Server 获取服务列表
eureka保证AP
    Eureka Server 各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。
    而 Eureka Client 在向某个 Eureka 注册时，如果发现连接失败，则会自动切换至其它节点。
    只要有一台 Eureka Server 还在，就能保证注册服务可用(保证可用性)，只不过查到的信息可能不是最新的(不保证强一致性)。
工作流程
    1，Eureka Server 启动成功，等待服务端注册。在启动过程中如果配置了集群，集群之间定时通过 Replicate 同步注册表，每个 Eureka Server 都存在独立完整的服务注册表信息
    2，Eureka Client 启动时根据配置的 Eureka Server 地址去注册中心注册服务
    3，Eureka Client 会每 30s 向 Eureka Server 发送一次心跳请求，证明客户端服务正常
    4，当 Eureka Server 90s 内没有收到 Eureka Client 的心跳，注册中心则认为该节点失效，会注销该实例
    5，单位时间内 Eureka Server 统计到有大量的 Eureka Client 没有上送心跳，则认为可能为网络异常，进入自我保护机制，不再剔除没有上送心跳的客户端
    6，当 Eureka Client 心跳请求恢复正常之后，Eureka Server 自动退出自我保护模式
    7，Eureka Client 定时全量或者增量从注册中心获取服务注册表，并且将获取到的信息缓存到本地
    8，服务调用时，Eureka Client 会先从本地缓存找寻调取的服务。如果获取不到，先从注册中心刷新注册表，再同步到本地缓存
    9，Eureka Client 获取到目标服务器信息，发起服务调用
    10，Eureka Client 程序关闭时向 Eureka Server 发送取消请求，Eureka Server 将实例从注册表中删除
多级缓存架构
    注册中心简单来说，其实就是各个服务将自己的IP和端口号这些信息存放到注册中心里，形成一个注册表，当服务间调用的时候，调用方就能从注册中心的注册表里面获取到要调用服务的具体IP和端口号，就可以请求那个服务了
        Eureka的注册表拉取机制分为了两种
            1，第一种是第一次拉取服务注册表的时候，此时需要全量拉取注册表，将所有服务的注册表信息全部存放起来
                服务注册表的全量拉取很好理解，就是第一次的时候，从注册表全量拉取注册表到eureka client，后面的话就是增量拉取了
            2，第二种是每隔30秒，增量拉取服务注册表
                增量拉取注册表的实现借助了一个ConcurrentLinkedQueue类型的变量recentlyChangedQueue
                默认情况下recentlyChangedQueue里面存放的是180秒内修改的服务实例信息，后台会有一个定时任务来维护recentlyChangedQueue，只有最近180秒内有变更的服务实例才会在里面
                在增量拉取注册表时，会将本地的注册表和recentlyChangedQueue中的服务实例进行一个合并
                保证本地的服务注册表信息和eureka server的服务注册表一致
        在eureka client拉取注册表的时候，就会用到所谓的多级缓存机制，多级缓存机制中有两个缓存，一个叫只读缓存ReadOnlyCacheMap，一个叫读写缓存ReadWriteCacheMap
        eureka client拉取注册表的时候，会先从ReadOnlyCacheMap中去获取注册表数据，如果获取不到的话再去ReadWriteCacheMap中找，如果还是找不到的话，那就只能重新从注册表中拉取了
        ReadOnlyCacheMap就是一个普通的ConcurrentHashMap，而ReadWriteCacheMap是guava cache
        如果ReadWriteCacheMap读不到数据，就会通过ClassLoader的load方法直接从注册表获取数据再返回
        多级缓存机制有多种过期策略
            主动过期：当服务实例发生注册、下线、故障的时候，ReadWriteCacheMap中所有的缓存过期掉
            定时过期：readWriteCacheMap在构建的时候，指定了一个自动过期的时间，默认值就是180秒，所以你往readWriteCacheMap中放入一个数据，180秒过后，就将这个数据给他过期了
            被动过期：默认是每隔30秒，执行一个定时调度的线程任务，对readOnlyCacheMap和readWriteCacheMap中的数据进行一个比对，如果两块数据是不一致的，那么就将readWriteCacheMap中的数据放到readOnlyCacheMap中来
                    由于30s的间隔，readOnlyCacheMap和ReadWriteCacheMap的数据不一致
        在获取增量注册表信息的时候，同时获取了一个eureka server全量注册表的hash值，这个又是干什么用的呢？
            在eureka client增量同步注册表完成之后，也会计算一个hash值，然后将自己计算出来的这个hash值和eureka server全量注册表的hash值进行比对，如果是一致的，说明增量数据同步没问题，反之则说了增量数据同步出现了不一致，那么就会重新从eureka server全量拉取一份最新的服务注册表

# hystrix
概述
    一款针对分布式系统的延迟和容错库，目的是用来隔离分布式服务故障。它提供线程和信号量隔离，以减少不同服务之间资源竞争带来的相互影响;
    提供优雅降级机制;提供熔断机制使得服务可以快速失败，而不是一直阻塞等待服务响应，并能从中快速恢复。Hystrix通过这些机制来阻止级联失败并保证系统弹性、可用
造成雪崩原因可以归结为以下三个：
    服务提供者不可用（硬件故障，程序Bug，缓存击穿，用户大量请求）
    重试加大流量（用户重试，代码逻辑重试）
    服务调用者不可用（同步等待造成的资源耗尽）
    最终的结果就是一个服务不可用导致一系列服务的不可用，而往往这种后果往往无法预料的。
hystrix的出现即为解决雪崩效应，它通过四个方面的机制来解决这个问题
    隔离（线程池隔离和信号量隔离）：限制调用分布式服务的资源使用，某一个调用的服务出现问题不会影响其他服务调用。
    降级：超时降级、资源不足时(线程或信号量)降级，降级后可以配合降级接口返回托底数据。
    融断：当失败率达到阀值自动触发降级(如因网络故障/超时造成的失败率高)，熔断器触发的快速失败会进行快速恢复。
    缓存：提供了请求缓存、请求合并实现。
    支持实时监控、报警、控制（修改配置）
隔离
    首先，当大多数人在使用Tomcat时，多个HTTP服务会共享一个线程池，假设其中一个HTTP服务访问的数据库响应非常慢，这将造成服务响应时间延迟增加，大多数线程阻塞等待数据响应返回，导致整个Tomcat线程池都被该服务占用，甚至拖垮整个Tomcat。
    因此，如果我们能把不同HTTP服务隔离到不同的线程池，则某个HTTP服务的线程池满了也不会对其他服务造成灾难性故障。这就需要线程隔离或者信号量隔离来实现了。
    使用线程隔离或信号隔离的目的是为不同的服务分配一定的资源，当自己的资源用完，直接返回失败而不是占用别人的资源。
    1，线程池隔离模式：
        会为不同的服务设置不同的线程池，从而实现相互隔离。
        使用一个线程池来存储当前的请求，线程池对请求作处理，设置任务返回处理超时时间，堆积的请求堆积入线程池队列。这种方式需要为每个依赖的服务申请线程池，有一定的资源消耗，好处是可以应对突发流量
        （流量洪峰来临时，处理不完可将数据存储到线程池队里慢慢处理）
    2，信号量隔离模式
        使用一个原子计数器（或信号量）来记录当前有多少个线程在运行，请求来先判断计数器的数值，若超过设置的最大线程个数则丢弃改类型的新请求，若不超过则执行计数操作请求来计数器+1，请求返回计数器-1。这种方式是严格的控制线程且立即返回模式，无法应对突发流量
        （流量洪峰来临时，处理的线程超过数量，其他的请求会直接返回，不继续去请求依赖的服务）
    区别（两种隔离方式只能选其一）：
                线程池隔离	           信号量隔离
        线程	    与调用线程非相同线程	   与调用线程相同（jetty线程）
        开销	    排队、调度、上下文开销等  无线程切换，开销低
        异步	    支持	                   不支持
        并发支持	支持（最大线程池大小）	   支持（最大信号量上限）
熔断
    - 开始时断路器处于关闭状态
    - 如果调用一段时间持续出错、超式、或者失败频率超过一定限制，断路器打开进入熔断状态，后续一段时间所有请求都会被直接拒绝
    - 一段时间以后，保护器会尝试进入半熔断状态(Half-Open)，允许少量请求进来尝试；如果调用仍然失败，则回到熔断状态，如果调用成功，则回到电路闭合状态;
    主要配置参数：
        circuitBreaker.enabled：是否启用熔断器，默认是TRUE。
        circuitBreaker.forceOpen：熔断器强制打开，始终保持打开状态，不关注熔断开关的实际状态。默认值FLASE
        circuitBreaker.forceClosed：熔断器强制关闭，始终保持关闭状态，不关注熔断开关的实际状态。默认值FLASE。
        circuitBreaker.errorThresholdPercentage：错误率，默认值50%，例如一段时间（10s）内有100个请求，其中有54个超时或者异常，那么这段时间内的错误率是54%，大于了默认值50%，这种情况下会触发熔断器打开。
        circuitBreaker.requestVolumeThreshold：默认值20。含义是一段时间内至少有20个请求才进行errorThresholdPercentage计算。比如一段时间了有19个请求，且这些请求全部失败了，错误率是100%，但熔断器不会打开，总请求数不满足20。
        circuitBreaker.sleepWindowInMilliseconds：半开状态试探睡眠时间，默认值5000ms。如：当熔断器开启5000ms之后，会尝试放过去一部分流量进行试探，确定依赖服务是否恢复。
    原理：
        第一步，调用allowRequest()判断是否允许将请求提交到线程池
            1，如果熔断器强制打开，circuitBreaker.forceOpen为true，不允许放行，返回。
            2，如果熔断器强制关闭，circuitBreaker.forceClosed为true，允许放行。此外不必关注熔断器实际状态，也就是说熔断器仍然会维护统计数据和开关状态，只是不生效而已
        第二步，调用isOpen()判断熔断器开关是否打开
            1，如果熔断器开关打开，进入第三步，否则继续；
            2，如果一个周期内总的请求数小于circuitBreaker.requestVolumeThreshold的值，允许请求放行，否则继续；
            3，如果一个周期内错误率小于circuitBreaker.errorThresholdPercentage的值，允许请求放行。否则，打开熔断器开关，进入第三步。
        第三步，调用allowSingleTest()判断是否允许单个请求通行，检查依赖服务是否恢复
            1，如果熔断器打开，且距离熔断器打开的时间或上一次试探请求放行的时间超过circuitBreaker.sleepWindowInMilliseconds的值时，熔断器器进入半开状态，允许放行一个试探请求；否则，不允许放行。
降级
    服务熔断其实是一种过载保护，是指整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。
    熔断和降级二者的目标是一致的，目的都是保证上游服务的稳定性。
    但其关注的重点并不一样，融断对下层依赖的服务并不级（或者说孰轻孰重），一旦产生故障就断掉；
    而降级需要对下层依赖的业务分级，把产生故障的丢了，换一个轻量级的方案，是一种退而求其次的方法。
    降级的三种模式：
        1，快速模式（最常用的模式）
            调用服务失败了，那么立即失败并返回，通过fallback进行降级，返回静态值。
        2，故障转移（服务级联）
            如果服务调用失败了就调用备用服务，因为备用服务也可能失败，所以也有可能有再下一一级的备用服务，如此形成一个级联
            例如如果服务提供者不响应，则从缓存中取默认数据
        3，主次模式
缓存
    不建议使用，对问题排查会造成很大的困扰
运行流程
    1，两个核心代理HystrixCommand,HystrixObservableCommand，任何依赖的服务只需要继承这两个类就可以了。
     （其中HystrixObservableCommand使用观察者模式）
    2，HystrixCommand 可以采用同步调用和异步调用，异步返回Future对象（还未直接支持CompletebleFuture）
       如果开启了缓存，则会根据GroupKey,Commandkey以及cachedKey确定是否存在缓存（不建议使用）
    3，判断断路器是否开启，开启则直接调用getFallback,
    4，判断是否满足信号量隔离或线程池隔离的条件，如果隔离则抛异常
    5，执行run方法
    6，metrics包含了一个计数器，用来计算当前服务的状态，无论是成功调用，还是抛异常都会记录数据
    7，执行降级策略
HystrixCollapser(请求合并器)
    微服务架构中通常需要依赖多个远程的微服务，而远程调用中最常见的问题就是通信消耗与连接数占用。在高并发的情况之下，因通信次数的增加，总的通信时间消耗将会变得越来越长。同时，因为依赖服务的线程池资源有限，将出现排队等待与响应延迟的清况。
    为了优化这两个问题，Hystrix 提供了HystrixCollapser来实现请求的合并，以减少通信消耗和线程数的占用。
    为了优化这两个问题，Hystrix 提供了HystrixCollapser来实现请求的合并，以减少通信消耗和线程数的占用。
        HystrixCollapser实现了在 HystrixCommand之前放置一个合并处理器，将处于一个很短的时间窗(默认10毫秒)内对同一依赖服务的多个请求进行整合，
        并以批量方式发起请求的功能(前提是服务提供方提供相应的批量接口)。HystrixCollapser的封装多个请求合并发送的具体细节，开发者只需关注将业务上将单次请求合并成多次请求即可。
    1，合并请求会有开销
        用于请求合并的延迟时间窗会使得依赖服务的请求延迟增高，比如，某个请求不通过请求合并器访问的平均耗时为5ms，请求合并的延迟时间窗为lOms (默认值)， 那么当该请求设置了请求合并器之后，最坏情况下(在延迟时间 窗结束时才发起请求)该请求需要15ms才能完成。
    2，什么时候使用合并请求
        合并请求存在额外开销，所以需要根据依赖服务调用的实际情况决定是否使用此功能，主要考虑下面两个方面：
            1，请求命令本身的延迟 
                如果依赖服务的请求命令本身是一个高延迟的命令，那么就可以使用请求合并器，因为延迟时间窗的时间消耗微不足道
            2，并发量
                时间窗口内并发量大，合并请求的性能提示越明显。如果一段时间内只有少数几个请求，那么就不适合请求合并器
                相反，如果一个时间窗内有很高的并发量，那么使用请求合并器是可以的
工作流程详解
    1，创建command对象
        （1）说明
            HystrixCommand：用在依赖的服务返回单个操作结果的时候。
            HystrixObservableCommand：用在依赖的服务返回多个操作结果的时候。通过以下方式创建Command对象。
                HystrixCommand command =newHystrixCommand(arg1, arg2);
                HystrixObservableCommand command =newHystrixObservableCommand(arg1, arg2);
            如果通过注解的方式使用HystrixCommand，那么在请求被拦截时，将会在HystrixCommandAspect中创建Command对象。
        （2）代码
            HystrixCommandAspect #methodsAnnotatedWithHystrixCommand方法
                HystrixInvokable invokable = HystrixCommandFactory.getInstance().create(metaHolder);
                ExecutionType executionType = metaHolder.isCollapserAnnotationPresent() ?
                metaHolder.getCollapserExecutionType() : metaHolder.getExecutionType();
                Object result;
                try {
                    result = CommandExecutor.execute(invokable, executionType, metaHolder);
                } catch (HystrixBadRequestException e) {
                    throw e.getCause();
                }


# nacos核心功能点
服务注册
    nacos client会通过发送rest请求的方式向nacos server注册自己的服务，提供自身的元数据，比如ip地址、端口信心。
    nacos server接收到注册请求后，就会把这些元数据信息存储在一个双层的内存map中
    Nacos服务端收到请求后，做以下三件事：
        1，构建一个Service对象保存到ConcurrentHashMap集合中
        2，使用定时任务对当前服务下的所有实例建立心跳检测机制
        3，基于数据一致性协议服务数据进行同步
    源码分析
        1，在spring-cloud-alibaba-nacos-discpvery的spring.factories中发现核心注册类NacosDiscoveryAutoConfiguration
        2，NacosDiscoveryAutoConfiguration中会实例化三个bean，其中一个主要用于服务注册的是NacosAutoServiceRegistration
        3，NacosAutoServiceRegistration继承AbstractAutoServiceRegistration，AbstractAutoServiceRegistration实现了ApplicationListener<WebServerInitializedEvent>
        4，看到listener我们就应该知道，Nacos是通过Spring的事件机制继承到SpringCloud中去的。
        5，AbstractAutoServiceRegistration实现了onApplicationEvent抽象方法,并且监听WebServerInitializedEvent事件(当Webserver初始化完成之后) , 调用this.bind ( event )方法。
        6，bind就是注册开始的入口，然后里面有一个refister()方法开始注册流程
        7，真正的注册方法是NamingService.registerInstance（主要分为两部分，分别是心跳检测和服务注册）
        8，首先是beatReactor.addBeatInfo创建心跳信息实现健康检测
            这里主要是客户端通过schedule定时向服务端发送一个数据包 ,然后启动-个线程不断检测服务端的回应,
            如果在设定时间内没有收到服务端的回应,则认为服务器出现了故障。Nacos服务端会根据客户端的心跳包不断更新服务的状态。
        9，服务注册serverProxy.registerService
            这里会调用server实例注册接口：nacos/v1/ns/instance
            实现代码咋nacos-naming模块下的InstanceController类中
            这里主要做了三件事：
                1，构建一个service对象保存到ConcurrentHashMap集合中
                2，使用定时任务对当前服务下的所有实例建立心跳检测机制
                3，基于数据一致性协议服务数据进行同步
            nacos注册表的结构：
                Map<namespace, Map<group::serviceName, Service>>
                NameSpace(命名空间) -> Group(分组) -> Service(微服务) -> Cluster(集群) -> Instance(具体实例)
            具体步骤
                1，从请求参数汇总获得serviceName（服务名）和namespaceId（命名空间Id）
                2，创建一个空服务（在Nacos控制台“服务列表”中展示的服务信息），实际上是初始化一个serviceMap，它是一个ConcurrentHashMap集合
                3，根据namespaceId、serviceName从缓存中获取Service实例，如果Service实例为空，通过putService()方法将服务缓存到内存。
                4，执行service.init()：建立健康检查机制
                    它主要通过定时任务不断检测当前服务下所有实例最后发送心跳包的时间，
                    如果超时,则设置healthy为false表示服务不健康,并且发送服务变更事件。
                5，执行addInstance()(这里指的是阿里自己实现的AP模式Distro协议)：
                    DistroConsistencyServiceImpl.put(key, value)
                        1，将注册实例更新到内存注册表
                            往阻塞队列tasks中放注册实例的数据
                            循环从阻塞队列tasks中拿去到实例数据进行处理
                            将注册实例信息更新到注册表内存结构中去（里使用CopyOnWrite思想，解决冲突，提高并发）
                        2，同步实例信息到nacos server集群其他节点
                            也是把注册的实例放到一个阻塞队列里面，然后线程启动的时候就一直循环的从队列中取数据 
                            如果注册实例达到一定数量就批量同步给nacos其他节点，或者距离上次节点同步达到一定时间也开始批量同步
                            如果同步不成功就重试         
                6，consistencyService.listen实现数据一致性监听
                    Nacos服务地址动态感知原理
                        可以通过subscribe方法来实现监听，其中serviceName表示服务名、EventListener表示监听到的事件：
                            void subscribe(String serviceName, EventListener listener) throws NacosException;
                        具体调用方式
                            NamingService naming = NamingFactory.createNamingService(System.getProperty("serveAddr"));
                            naming.subscribe("example", event -> {
                                if (event instanceof NamingEvent) {
                                    System.out.println(((NamingEvent)event).getServerName();
                                    System.out.println(((NamingEvent)event).getInstances();
                                }
                            })
                        或者调用selectInstance方法，如果将subacribe属性设置为true，会自动注册监听
                            public List<Instance> selectInstances(String serviceName, List<String> clusters, boolean healthy, boolean subscribe))
                        客户端有一个hostReactor类，它的功能是实现服务的动态更新，基本原理是：
                            1，客户端发起时间订阅后，在HostReactor中有一个UpdateTask线程，每10s发送一次Pull请求，获得服务端最新的地址列表
                            2，对于服务端，它和服务提供者的实例之间维持了心跳检测，一旦服务提供者出现异常，则会发送一个Push消息给Nacos客户端，也就是服务端消费者
                            3，服务消费者收到请求之后，使用HostReactor中提供的processServiceJSON解析消息，并更新本地服务地址列表
服务心跳
    服务注册后，nacos client会维护一个定时心跳来持续通知nacos server，说明服务一直处于可用状态
服务同步
    nacos server集群之间会互相同步服务实例，保证服务信息的一致性
服务发现
    服务消费者（nacos client）在调用服务提供者的服务时，会发送一个rest请求给nacos server，获取上面注册的服务清单
    并缓存到nacos client本地，同时会在nacos client本地开启一个定时任务定时拉取服务端最新的注册表信息更新到本地缓存
服务健康检查
    nacos server会开启一个定时任务来检查注册服务实例的健康状况，对于超过15s没有收到客户端心跳的实例会将它的healthy属性设置为false
    如果某个实例超过30s没有收到心跳，直接剔除该实例（被剔除的实例如果恢复发送心跳则会重新注册）

# Feign
Feign是一种声明式、模板化的HTTP客户端(仅在Application Client中使用)。就像调用本地方法一样调用远程方法，无需感知操作远程http请求。
通过提供HTTP请求模板，让Ribbon请求的书写更加简单和便捷。另外，在Feign中整合了Ribbon，从而不需要显式的声明Ribbon的jar包。
整合了ribbon和hystrix

参数处理：
    在Feign处理远程服务调用时，传递参数是通过HTTP协议传递的，参数存在的位置是请求头或请求体中。
    请求头传递的参数必须依赖@RequestParam注解来处理请求参数，请求体传递的参数必须依赖@RequestBody注解来处理请求参数。
    1，请求头传参
        请求头传递参数时，定义的服务标准接口中，必须使用@RequestParam注解来描述方法参数，且注解属性value/name必须指定，代表从请求头中获取的请求参数命名是什么。
        在默认环境中，使用请求头传递参数时，Application Service中的控制器无法使用SpringMVC中的自动对象封装能力。只能处理简单数据类型。如：数学类型，字符串类型，数组类型等。无法处理自定义对象类型。
    2，请求体传参
        使用请求体传递参数时，定义的服务标准接口中，必须使用@RequestBody注解来描述方法参数，因为Feign技术发起的POST请求，请求参数是使用JSON字符串来传递的，且form表单类型为RAW。
        使用请求体传递参数时，Application Service中的控制器必须使用@RequestBody注解来描述方法参数，且RAW类型的form表单上传的是一个文本内容，只能转换为唯一的一个参数。
        如果使用POST方式提交请求，并传递多个普通类型的参数时，Feign不会通过请求体传递参数，是通过请求头传递的参数。也就是请求路径为 ： http://applicationserver:port/url?paramName=paramValue。
Feign通讯优化：
    1，GZIP压缩
        gzip是一种数据格式，采用deflate算法压缩数据；可以加快加载的速度
        HTTP协议中关于压缩传输的规定：
            第一：客户端向服务器请求头中带有：Accept-Encoding:gzip, deflate 字段，向服务器表示，客户端支持的压缩格式（gzip或者deflate)，如果不发送该消息头，服务器是不会压缩的。
            第二：服务端在收到请求之后，如果发现请求头中含有Accept-Encoding字段，并且支持该类型的压缩，就对响应报文压缩之后返回给客户端，并且携带Content-Encoding:gzip消息头，表示响应报文是根据该格式压缩过的。
            第三：客户端接收到响应之后，先判断是否有Content-Encoding消息头，如果有，按该格式解压报文。否则按正常报文处理。
        在Feign技术中应用GZIP压缩
            只开启Feign请求-应答过程中的GZIP，也就是浏览器-Application Client之间的请求应答不开启GZIP压缩。在全局配置文件中，使用下述配置来实现Feign请求-应答的GZIP压缩：
                # feign gzip
                # 局部配置。只配置feign技术相关的http请求-应答中的gzip压缩。
                # 配置的是application client和application service之间通讯是否使用gzip做数据压缩。
                # 和浏览器到application client之间的通讯无关。
                # 开启feign请求时的压缩， application client -> application service
                feign.compression.request.enabled=true
                # 开启feign技术响应时的压缩，  application service -> application client
                feign.compression.response.enabled=true
                # 设置可以压缩的请求/响应的类型。
                feign.compression.request.mime-types=text/xml,application/xml,application/json
                # 当请求的数据容量达到多少的时候，使用压缩。默认是2048字节。
                feign.compression.request.min-request-size=512
    2，Feign的通讯优化：HttpClient客户端替换及HTTP连接池
        两台服务器建立HTTP连接的过程是很复杂的一个过程，涉及到多个数据包的交换，并且也很耗时间。HTTP连接需要的3次握手4次挥手开销很大，这一开销对于大量的比较小的HTTP消息来说更大。
        我们可以采用HTTP连接池来提升性能，连接池可以节约大量的3次握手4次挥手的时间，这样能大大提升吞吐率。
        1，Feign技术的底层实现
            Feign的HTTP客户端支持3种框架，分别是；HttpURLConnection、HttpClient、OKHttp。Feign中默认使用HttpURLConnection。
                HttpURLConnection是JDK自带的HTTP客户端技术，并不支持连接池，如果要实现连接池的机制，还需要自己来管理连接对象。对于网络请求这种底层相对复杂的操作，如果有可用的其他方案，也没有必要自己去管理连接对象。
                Apache提供的HttpClient框架相比传统JDK自带的HttpURLConnection，它封装了访问http的请求头，参数，内容体，响应等等；它不仅使客户端发送HTTP请求变得容易，而且也方便了开发人员测试接口（基于Http协议的），即提高了开发的效率，也方便提高代码的健壮性；另外高并发大量的请求网络的时候，还是用“HTTP连接池”提升吞吐量。
        2，Feign中应用HttpClient
            资源依赖：Feign技术发起请求的位置是Application Client端，下述依赖只需要在Application Client所在工程中添加即可
                <!-- httpclient相关依赖 -->
                <dependency>
                    <groupId>org.apache.httpcomponents</groupId>
                    <artifactId>httpclient</artifactId>
                </dependency>
                <dependency>
                    <groupId>io.github.openfeign</groupId>
                    <artifactId>feign-httpclient</artifactId>
                </dependency>
            修改全局配置文件：
                # 开启feign技术对底层httpclient的依赖。 切换底层实现技术。
                feign.httpclient.enabled=true
            提供连接池配置类：
                /**
                 * 配置类型
                 * 用于提供一个HTTP连接池，并实现连接池管理。
                 * 主要目的是，提供一个合理的资源回收方式。
                 */
                @Configuration
                public class HttpClientConfiguration {
                    @Bean
                    public HttpClient httpClient(){
                        System.out.println("init feign httpclient configuration " );
                        // 生成默认请求配置
                        RequestConfig.Builder requestConfigBuilder = RequestConfig.custom();
                        // 超时时间
                        requestConfigBuilder.setSocketTimeout(5 * 1000);
                        // 连接时间
                        requestConfigBuilder.setConnectTimeout(5 * 1000);
                        RequestConfig defaultRequestConfig = requestConfigBuilder.build();
                        // 连接池配置
                        // 长连接保持30秒
                        final PoolingHttpClientConnectionManager pollingConnectionManager = new PoolingHttpClientConnectionManager(30, TimeUnit.MILLISECONDS);
                        // 总连接数
                        pollingConnectionManager.setMaxTotal(5000);
                        // 同路由的并发数
                        pollingConnectionManager.setDefaultMaxPerRoute(100);
                        // httpclient 配置
                        HttpClientBuilder httpClientBuilder = HttpClientBuilder.create();
                        // 保持长连接配置，需要在头添加Keep-Alive
                        httpClientBuilder.setKeepAliveStrategy(new DefaultConnectionKeepAliveStrategy());
                        httpClientBuilder.setConnectionManager(pollingConnectionManager);
                        httpClientBuilder.setDefaultRequestConfig(defaultRequestConfig);
                        HttpClient client = httpClientBuilder.build();
                        // 启动定时器，定时回收过期的连接， 最重要。 如果没有定义回收策略。连接池会在运行一段时间后失效。
                        Timer timer = new Timer();
                        timer.schedule(new TimerTask() {
                            @Override
                            public void run() {
                                pollingConnectionManager.closeExpiredConnections();
                                pollingConnectionManager.closeIdleConnections(5, TimeUnit.SECONDS);
                            }
                        }, 10 * 1000, 5 * 1000);
                        System.out.println("===== Apache httpclient 初始化连接池===");
                        return client;
                    }
                }
            使用HttpClient客户端替换HttpURLConnection，仅需修改Application Client，其余无需修改。当使用HttpClient技术作为Feign的底层HTTP技术应用时，使用GET请求方式请求头传递自定义类型对象是可行的，只要在服务标准对象中定义的方法参数上增加注解@RequestBody即可处理。
配置Feign中的请求超时
    在Feign声明式远程调用中，负载均衡还是使用的Ribbon技术。而Ribbon技术默认的链接超时是1秒，也就是1秒内Application Service没有处理Application Client的请求，且链接请求处理后，1秒之内没有返回响应，Application Client都会抛出超时异常。在商业项目中，部分服务是很难在1秒之内处理链接，并在处理链接后1秒之内返回响应的，所以配置超时信息就很有必要了。
    超时策略的使用优先级： 指定服务的超时策略 -> 全局配置的超时策略 -> 默认的超时策略。
    全局服务配置
         # 全局服务配置
         # 请求连接的超时时间 默认的时间为1秒
         ribbon.ConnectTimeout=1000
         # 请求处理的超时时间
         ribbon.ReadTimeout=5000
    部分服务配置
        # 部分服务配置　　服务名.ribbon.属性=属性值
        # 对所有操作请求都进行重试
        spring-cloud-feign-appservice.ribbon.OkToRetryOnAllOperations=true
        # 对当前实例的重试次数
        spring-cloud-feign-appservice.ribbon.MaxAutoRetries=2
        # 请求连接的超时时间
        spring-cloud-feign-appservice.ribbon.ConnectTimeout=3000
        # 请求处理的超时时间
        spring-cloud-feign-appservice.ribbon.ReadTimeout=3000
代码调用过程
    1，首先通过@EnableFeignCleints注解开启FeignCleint
        @EnableFeignClients注解，如果有该注解，则开启包扫描，扫描被@FeignClient注解修饰的接口。扫描出该注解后，通过beanDefinition注入到IOC容器中，方便后续被调用使用。
    2，根据Feign的规则实现接口，并加@FeignCleint注解
    3，程序启动后，会进行包扫描，扫描所有的@ FeignCleint的注解的类，并将这些信息注入到ioc容器中。
        当类有@FeignClient注解，将注解的信息取出，连同类名一起取出，赋给BeanDefinitionBuilder，然后根据BeanDefinitionBuilder得到beanDefinition，最后beanDefinition式注入到ioc容器中
    4，当接口的方法被调用，通过jdk的代理，来生成具体的RequesTemplate
        在ReflectiveFeign中：
            使用了jdk的动态代理为目标接口生成了一个动态代理类，这里会生成一个InvocationHandler(jdk动态代理原理)统一的方法拦截器，
            同时为接口的每个方法生成一个SynchronousMethodHandler拦截器，并解析方法上的元数据，生成一个http请求模板
    5，client组件
        RequestTemplate生成Request请求对象，
        Request交给Client去处理，其中Client可以是HttpUrlConnection、HttpClient也可以是Okhttp
    6，最后Client被封装到LoadBalanceClient类，这个类结合类Ribbon做到了负载均衡。（默认集成了ribbon）
        

# SpringCLoud Gateway
关于WebFlux，Gateway是基于WebFlux
    传统的Web框架，比如说：struts2，springmvc等都是基于Servlet API与Servlet容器基础之上运行的，在Servlet3.1之后才有了异步非阻塞的支持。
    WebFlux是一个典型非阻塞异步的框架，它的核心是基于Reactor的相关API实现的。相对于传统的web框架来说，它可以运行在诸如Netty，Undertow及支持Servlet3.1的容器上。
    1，非阻塞式
        其实在servlet3.1提供了非阻塞的API，WebFlux提供了一种比其更完美的解决方案。使用非阻塞的方式可以利用较小的线程或硬件资源来处理并发进而提高其可伸缩性
    2，函数式编程端点
        老生常谈的编程方式了，Spring5必须让你使用java8，那么函数式编程就是java8重要的特点之一，而WebFlux支持函数式编程来定义路由端点处理请求。
基础功能
    网关可以理解为网络关卡，是整个微服务的统一入口（门卫）。
    可以和服务注册中心完美的整合，如：Eureka、Consol、Nacos
    1，基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0
    2，动态路由
    3，Predicates 和 Filters 作用于特定路由
    4，集成 Hystrix 断路器
    5，集成 Spring Cloud DiscoveryClient
    6，易于编写的 Predicates 和 Filters
    7，限流
    8，路径重写
工作原理
    客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。
    Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。
    过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。
    Filter在“pre”类型的过滤器可以做参数校验、权限校验、流量监控、日志输出、协议转换等
    在“post”类型的过滤器中可以做响应内容、响应头的修改，日志的输出，流量监控等有着非常重要的作用。
    核心逻辑就是路由转发，执行过滤器链。
谓词工厂/断言
    After	- After=2017-01-20T17:42:47.789-07:00[America/Denver]	在该日期时间之后发生的请求都将被匹配。
    Before	- Before=2017-01-20T17:42:47.789-07:00[America/Denver]	在该日期时间之前发生的请求都将被匹配。
    Between	- Between=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver]	在两个日期时间之间发生的请求都将被匹配。
    Cookie	- Cookie=chocolate, ch.p	请求包含次cookie名称且正则表达式为真的将会被匹配。
    Header	- Header=X-Request-Id, \d+	请求包含次header名称且正则表达式为真的将会被匹配。
    Host	- Host=**.somehost.org,**.anotherhost.org	使用Ant路径匹配规则，.作为分隔符
    Method	- Method=GET	所有GET请求都将被路由
    Path	- Path=/foo/{segment},/bar/{segment}	路径/foo/开头或/bar/开头的请求都将被匹配
    Query	- Query=baz，    包含了请求参数 baz的都将被匹配
            - Query=foo, ba.  请求参数里包含foo参数，并且值匹配为ba.  
    RemoteAddr	- RemoteAddr=192.168.1.1/24	请求的remote address 为 192.168.1.10则将被路由
    Weight	    routes:
    　             - id: weight_high
    　　             uri: https://weighthigh.org  将大约80％的流量转发到weighthigh.org
    　　             predicates:
    　　　　            - Weight=group1, 8
    　             - id: weight_low
    　　              uri: https://weightlow.org  将大约20％的流量转发到weightlow.org
    　　              predicates:
    　　　　             - Weight=group1, 2
过滤器工厂
    全局过滤器与其他2类过滤器相比，永远是最后执行的；它的优先级只对其他全局过滤器起作用
    当默认过滤器与自定义过滤器的优先级一样时，优先出发默认过滤器，然后才是自定义过滤器；同类型的过滤器，出发顺序与他们在配置文件中声明的顺序一致
    默认过滤器与自定义过滤器使用同样的order顺序空间，即他们会按照各自的顺序来进行排序 
    AddRequestHeader    filters:                                    向下游请求的header头中添加 x-request-foo:bar
                        　　- AddRequestHeader=X-Request-Foo, Bar
    AddRequestParameter	 - AddRequestParameter=foo, bar	 向下游请求添加foo=bar请求参数
    AddResponseHeader	 - AddResponseHeader=X-Response-Foo, Bar	 向下游响应的header头添加x-response-foo:bar
    CircuitBreaker       - Hystrix=myCommandName    断路器过滤器；发生断路时将请求转发或者调用fallback处理
                         或者
                         filters:
                         　　- name: CircuitBreaker
                         　　　args:
                         　　　　name: myCircuitBreaker                         还可以将请求重新路由到外部应用程序中的控制器或处理程序
                         　　　　fallbackUri: forward:/inCaseOfFailureUseThis
                         　　- RewritePath=/consumingServiceEndpoint, /backingServiceEndpoint 
    PrefixPath	 - PrefixPath=/mypath	 所有匹配请求的路径加前缀/mypath。因此，向/hello发送的请求将发送到/mypath/hello
    RequestRateLimiter	    filters:                                        
                            　　- name: RequestRateLimiter
                            　　args:
                            　　　　redis-rate-limiter.replenishRate: 10    每个用户10的请求速率限制。
                            　　　　redis-rate-limiter.burstCapacity: 20    允许20个突发，但是在下一秒中，只有10个请求可用
                            　　　　redis-rate-limiter.requestedTokens: 1
    RedirectTo	 - RedirectTo=302, http://acme.org	 发送一个302状态码和一个Location:http://acme.org header来执行重定向
    RemoveRequestHeader	 - RemoveRequestHeader=X-Request-Foo	 向下游请求的header头中删除X-Request-Foo
    RemoveResponseHeader	 - RemoveResponseHeader=X-Request-Foo	 向下游响应的header头中删除X-Request-Foo
    RewritePath	 - RewritePath=/foo/(?<segment>.*), /$\{segment}	 使用Java正则表达式重写请求路径
    RewriteResponseHeader	 - RewriteResponseHeader=X-Response-Foo, , password=[^&]+, password=***	 使用Java正则表达式重写响应头的值
    SetPath	    predicates:                 对于一个 /foo/bar请求，在做下游请求前，路径将被设置为/bar
                　　- Path=/foo/{segment}
                filters:
                　　- SetPath=/{segment}
    StripPrefix	    predicates:         当通过网关发出/name/bar/foo请求时，向nameservice发出的请求将是http://nameservice/bar/foo
                    　　- Path=/name/**   
                    filters:
                    　　- StripPrefix=1
    Retry	filters:            retry filter 不支持body请求的重试，如通过body的POST 或 PUT请求
            　　- name: Retry
            args:                   
            　　retries: 3
            　　statuses: BAD_GATEWAY
    RequestSize     filters:                请求大小大于限制	 
                    　　- name: RequestSize
                    args:
                    　　maxSize: 5000000
负载均衡
    spring:
      cloud:
        gateway:
          discovery:
            locator:
              enabled: true # 启用自动根据服务ID生成路由
              lower-case-service-id: true # 设置路由的路径为小写的服务ID
          routes:
            - id: sso-service # 路由ID（一个路由配置一个ID）
              uri: lb://sso # 通过注册中心来查找服务（lb代表从注册中心获取服务，并且自动开启负载均衡）
              predicates:
                - Path=/auth/** # 匹配到的以/product开头的路径都转发到product的服务，相当于访问 lb://PRODUCT-SERVICE/**
              filters:
                - StripPrefix=1 # 去掉匹配到的路径的第一段
    LoadBalancerClientFilter ：实现负载均衡的全局过滤器，内部实现是ribbon
权重负载
    routes:
        - id: spring-cloud-client-demo
          uri: lb://spring-cloud-client-demo
          predicates:
            - Path=/client/**
            - Weight=group1, 2
          filters:
            - StripPrefix=1
        - id: spring-cloud-client-demo1
          uri: lb://spring-cloud-client-demo
          predicates:
            - Path=/client/**
            - Weight=group1, 8
          filters:
            - StripPrefix=1
限流
    默认：RequestRateLimiterGatewayFilterFactory限流过滤器和限流的实现类RedisRateLimiter使用令牌桶限流；
    常用的限流算法有几种：计数器算法、漏桶算法和令牌桶算法
        计数算法适合流量突发情况（瞬间突发）
        令牌桶适合均速，无法获取令牌的请求直接拒绝
        漏桶算法适合均速并且可以让请求进行等待，不需要直接拒绝请求
    计数器算法：
        维护一个单位时间内的计数器（例如：设置1s内允许请求次数10次)，表示为时间单位1秒内允许计数次数最高为10，每次请求计数器加1，
        当单位时间内计数器累加到大于设定的阈值(10)，则之后的请求都被拒绝，直到单位时间(1s)已经过去，再将计数器重置为零，
        缺点：
            如果在单位时间1s内允许100个请求，在10ms已经通过了100个请求，那后面的990ms所接收到的请求都会被拒绝，我们把这种现象称为“突刺现象”。
    漏桶算法：
        水（请求）先进入到漏桶里，漏桶以一定的速度出水（接口响应速率），当水流入速度过大会直接溢出（访问频率超过接口响应速率），
        然后就拒绝请求，可以看出漏桶算法能强行限制数据的传输速率。
    令牌桶算法：
        随着时间流逝，系统会按恒定 1/QPS 时间间隔（如果 QPS=100，则间隔是 10ms）往桶里加入 Token（想象和漏洞漏水相反，有个水龙头在不断的加水）
        如果桶已经满了就不再加了。新请求来临时，会各自拿走一个 Token，如果没有 Token 可拿了就阻塞或者拒绝服务。
    配置：
        spring:
          cloud:
            gateway:
              routes:
              - id: test-service
                uri: lb://test
                predicates:
                - Path=/test/**
                filters:
                - StripPrefix= 1
                - name: RequestRateLimiter #请求数限流 名字不能随便写 
                  args:
                    key-resolver: "#{@hostAddrKeyResolver}" #使用SpEL按名称引用bean
                    redis-rate-limiter.replenishRate: 1 #令牌桶每秒填充平均速率
                    redis-rate-limiter.burstCapacity: 1 #令牌桶的容量，允许在一秒钟内完成的最大请求数
降级：
    spring:
      cloud:
        gateway:
          routes:
          - id: test-service
            uri: lb://test
            predicates:
            - Path=/test/**
            filters:
            - StripPrefix= 1
            - name: Hystrix
              args:
                name: fallback # Hystrix的bean名称
                fallbackUri: 'forward:/fallback' # Hystrix超时降级后调用uri地址
    @RestController
    @Slf4j
    public class FallbackController {
        @RequestMapping(value = "/fallback")
        @ResponseStatus
        public Mono<Map<String, Object>> fallback(ServerWebExchange exchange) {
            Map<String, Object> result = new HashMap<>(3);
            result.put("code", 7002);
            result.put("data", null);
            Exception exception = exchange.getAttribute(ServerWebExchangeUtils.HYSTRIX_EXECUTION_EXCEPTION_ATTR);
            ServerWebExchange delegate = ((ServerWebExchangeDecorator) exchange).getDelegate();
            log.error("接口调用失败，URL={}", delegate.getRequest().getURI(), exception);
            if (exception instanceof HystrixTimeoutException) {
                result.put("msg", "接口调用超时");
            } else if (exception != null && exception.getMessage() != null) {
                result.put("msg", "接口调用失败: " + exception.getMessage());
            } else {
                result.put("msg", "接口调用失败");
            }
            return Mono.just(result);
        }
    }
重试
    spring:
      cloud:
        gateway:
          routes:
          - id: test-service
            uri: lb://test
            predicates:
            - Path=/test/**
            filters:
            - StripPrefix= 1
            - name: Retry #重试
              args:
                retries: 1 #重试次数
                series: #不指定错误码系列
                statuses: BAD_GATEWAY,INTERNAL_SERVER_ERROR,SERVICE_UNAVAILABLE #500，502状态重试
                methods: GET,POST # 只有get和post接口重试
# Ribbon
自动化配置累中，主要做了下面三件事：
    创建了一个LoadBalancerInterceptor的Bean，用于实现对客户端发起请求时进行拦截，以实现客户端负载均衡。
    创建了一个RestTemplateCustomizer的Bean，用于给RestTemplate增加LoadBalancerInterceptor拦截器。
    维护了一个被@LoadBalanced注解修饰的RestTemplate对象列表，并在这里进行初始化，通过调用RestTemplateCustomizer的实例来给需要客户端负载均衡的RestTemplate增加LoadBalancerInterceptor拦截器。
LoadBalancerInterceptor拦截器是如何将一个普通的RestTemplate变成客户端负载均衡的：
    在拦截器中注入了LoadBalancerClient的实现。
    当一个被@LoadBalanced注解修饰的RestTemplate对象向外发起HTTP请求时，会被LoadBalancerInterceptor类的intercept函数所拦截。
    由于我们在使用RestTemplate时候采用了服务名作为host，所以直接从HttpRequest的URI对象中通过getHost()就可以拿到服务名，然后调用execute函数去根据服务名来选择实例并发起实际的请求。
加了ribbon发起一个请求的具体流程：
    1，RestTemplate：发起请求
    2，LoadBanlanceInterceptor：负载均衡拦截器拦截
    3，LoadBanlanceClient：获取该服务的ILoadBalance
    4，ILoadBalance：获取服务列表 -> 服务路由 -> 根据负载均衡算法选择一个server -> 发起请求 -> 记录调用数据（耗时、成功、失败等信息）
PingTask执行流程：
    1，PingTask：周期性执行
    2，Pinger：获取服务实例列表 -> 更新upServerList
    3，PingStrategy：串行/并行发起请求
    4，IPing：检测服务可用性
获取服务实例列表
    Ribbon使用ServerList接口抽象服务实例列表，Ribbon获取服务实例有如下两种方法：
        1，配置文件：com.netflix.loadbalancer.ConfigurationBasedServerList
            在没有使用注册中心的情况下，Ribbon可以通过配置文件手动列举服务实例的地址，它的命令规范是{{服务名}}.ribbon.listOfServers，Ribbon通过ConfigurationBasedServerList类实现配置服务列表,多个服务实例用逗号隔开
                spring.application.name=shop-order
                shop-product.ribbon.listOfServers=http://localhost:8001,http://localhost:8002
            使用配置文件是不是意味着服务实例列表就不会不变了呢？不是的，其实还会定时更新
        2，利用注册中心获取
            利用配置文件获取服务实例列表扩展性很差，因为在服务实例上线或者下线的情况下，需要手动修改配置文件，扩展性很低，一个健壮的微服务系统会采用注册中心的方式维护服务的上下线。Ribbon可以使用DiscoveryEnabledNIWSServerList维护和Eureka之间的服务上下线
动态更新服务实例列表
    服务实例上下线在微服务系统中是一个非常常见的场景，Ribbon也实现了该功能。Ribbon定时更新的接口抽象为ServerListUpdater。当Ribbon从注册中心获取了服务实例列表之后，Ribbon需要动态更新服务实例列表，抽象接口为ServerListUpdater
    更新的方式有两种：
        1,定时任务定时拉取服务实例列表
            参数设置：
                com.netflix.loadbalancer.PollingServerListUpdater:定时拉取
            Ribbon会使用一个定时任务线程池定时拉取更新数据。
            Ribbon也提供了一些参数，用于控制拉取的实现细节:
                {service-name}.ribbon.ServerListRefreshInterval:更新频率
                DynamicServerListLoadBalancer.ThreadPoolSize:定时更新的线程数目
            PollingServerListUpdater只是控制了线程池的动作，但是具体的业务逻辑则是封装在UpdateAction。
        2,事件通知
            参数设置：
                com.netflix.niws.loadbalancer.EurekaNotificationServerListUpdater:事件通知
            和PollingServerListUpdater不同的是，如果注册中心是Eureka，可以采用事件通知的方式，即当Eureka注册中心发生注册信息变更的时候，那么就将消息发送到事件监听者，
            Ribbon使用EurekaNotificationServerListUpdater实现类进行更新，首先会创建一个Eureka监听器，当接口接受到通知事件之后，会将更新逻辑提交到线程池中执行，更详细的代码如下
                public synchronized void start(final UpdateAction updateAction) {
                    if (isActive.compareAndSet(false, true)) {
                        this.updateListener = new EurekaEventListener() {
                            @Override
                            public void onEvent(EurekaEvent event) {
                                if (event instanceof CacheRefreshedEvent) {
                                    if (!updateQueued.compareAndSet(false, true)) {  // if an update is already queued
                                        logger.info("an update action is already queued, returning as no-op");
                                        return;
                                    }
                                    try {
                                        refreshExecutor.submit(new Runnable() {
                                            @Override
                                            public void run() {
                                                  updateAction.doUpdate();
                                            }
                                        }); 
                                    } catch (Exception e) {
                                        updateQueued.set(false);  // if submit fails, need to reset updateQueued to false
                                    }
                                }
                            }
                        };
                        //注册事件监听器，省略不重要的代码
                    } else {
                        logger.info("Update listener already registered, no-op");
                    }
                }
对服务进行心跳检测
    服务列表中的服务实例未必一直都处于可用的状态，Ribbon会对服务实例进行检测，PingerStrategy接口抽象检测的策略，Ribbon默认采用了串行的方式进行检测，
    如果有必要，我们可以通过该接口实现并行的检测方式。Pinger会定时通过PingerStrategy获取更新的服务实例，并调用监听者。
        // 避免在检测过程中服务实例列表发生变更，预先进行复制，代码省略
        //在线服务实例列表
        final List<Server> newUpList = new ArrayList<Server>();
        //发生状态变更的服务实例列表
        final List<Server> changedServers = new ArrayList<Server>();
        for (int i = 0; i < numCandidates; i++) {
            boolean isAlive = results[i];
            Server svr = allServers[i];
            boolean oldIsAlive = svr.isAlive();
            svr.setAlive(isAlive);
            if (oldIsAlive != isAlive) {
                changedServers.add(svr);
                logger.debug("LoadBalancer [{}]:  Server [{}] status changed to {}", 
                    name, svr.getId(), (isAlive ? "ALIVE" : "DEAD"));
            }
            if (isAlive) {
                newUpList.add(svr);
            }
        }
    除此之外，还有一个IPing接口，它的目的是检测单个服务的可用性，对于Eureka来说使用的是NIWSDiscoveryPing策略
服务路由
    ServerListFilter接口的作用就是从一批接口中选择一些符合条件的接口并返回。
    如果希望得到某个版本的微服务实例，那么这个接口就能派上用场了，但是Ribbon没有这样的实现，如果需要解决该需求就要自己开发接口了。
    在默认情况下，Ribbon采取了区域优先的过滤策略(ZoneAffinityServerListFilter)，也就是说，优先使用和当前调用者一样的区域微服务实例。
负载均衡调度器
    从ServerListFilter获取到一个微服务实例集合后，ILoadBalancer需要使用某个策略从集合中选择一个服务实例， 而策略的抽象接口为IRule，如下所示
        public interface IRule{
            //省略一些不重要的方法
            public Server choose(Object key);
        }
    选择服务实例之后，ILoadBalancer在调用过程中，会记录请求的执行结果，比如请求的失败成功情况，调用耗时等，IRule接口也可以根据这些信息决定是否使用某个Server。
    Ribbon提供了七种负载均衡策略，默认的负载均衡策略是轮训策略。
        RoundRobinRule	轮训策略
        RandomRule	随机策略
        BestAvailableRule	过滤出故障服务器后，选择一个并发量最小的
        WeightedResponseTimeRule	针对响应时间加权轮询
        AvailabilityFilteringRule	可用过滤策略，先过滤出故障的或并发请求大于阈值的一部分服务实例，然后再以线性轮询的方式从过滤后的实例清单中选出一个;
        ZoneAvoidanceRule	从最佳区域实例集合中选择一个最优性能的服务实例
        RetryRule	选择一个Server，如果失败，重新选择一个Server重试

1，Sentinal
定义资源：
    资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，RPC接口方法，甚至可以是一段代码。
    只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。
    把需要控制流量的代码用 Sentinel的关键代码 SphU.entry("资源名") 和 entry.exit() 包围起来即可。
        Entry entry = null;
            try {
                // 定义一个sentinel保护的资源，名称为test-sentinel-api
                entry = SphU.entry(resourceName);
                // 模拟执行被保护的业务逻辑耗时
                Thread.sleep(100);
                return a;
            } catch (BlockException e) {
                // 如果被保护的资源被限流或者降级了，就会抛出BlockException
                log.warn("资源被限流或降级了", e);
                return "资源被限流或降级了";
            } catch (InterruptedException e) {
                return "发生InterruptedException";
            } finally {
                if (entry != null) {
                    entry.exit();
                }
                ContextUtil.exit();
            }
        }
    在下面的例子中， 用 try-with-resources 来定义资源。参考代码如下:
        public static void main(String[] args) {
            // 配置规则.
            initFlowRules();
            while (true) {
                // 1.5.0 版本开始可以直接利用 try-with-resources 特性
                try (Entry entry = SphU.entry("HelloWorld")) {
                    // 被保护的逻辑
                    System.out.println("hello world");
        	} catch (BlockException ex) {
                    // 处理被流控的逻辑
        	    System.out.println("blocked!");
        	}
            }
        }
    资源注解@SentinelResource
        @SentinelResource("HelloWorld")
        public void helloWorld() {
            // 资源中的逻辑
            System.out.println("hello world");
        }
        @SentinelResource 用于定义资源，并提供可选的异常处理和 fallback 配置项。 @SentinelResource 注解包含以下属性：
            value：资源名称，必需项（不能为空）
            entryType：entry 类型，可选项（默认为 EntryType.OUT）
            blockHandler / blockHandlerClass:
                blockHandler 对应处理 BlockException的函数名称，可选项。blockHandler 函数访问范围需要是 public，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 BlockException。
                blockHandler 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 blockHandlerClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。
            fallback /fallbackClass
                fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了exceptionsToIgnore里面排除掉的异常类型）进行处理。
                函数签名和位置要求：
                    返回值类型必须与原函数返回值类型一致；
                    方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。
                    fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。
            defaultFallback：
                since 1.6.0）：默认的 fallback 函数名称，可选项，通常用于通用的 fallback 逻辑（即可以用于很多服务或方法）。默认 fallback 函数可以针对所有类型的异常（除了exceptionsToIgnore里面排除掉的异常类型）进行处理。若同时配置了 fallback 和 defaultFallback，则只有 fallback 会生效。
                函数签名和位置要求：
                    返回值类型必须与原函数返回值类型一致；
                    方法参数列表需要为空，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。
                    defaultFallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必需为 static 函数，否则无法解析。
                    exceptionsToIgnore（since 1.6.0）：用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 fallback 逻辑中，而是会原样抛出。
定义规则
    规则主要有流控规则、 熔断降级规则、系统规则、权限规则、热点参数规则等：
    一段硬编码的方式定义流量控制规则如下：
        private void initSystemRule() {
            List<SystemRule> rules = new ArrayList<>();
            SystemRule rule = new SystemRule();
            rule.setHighestSystemLoad(10);
            rules.add(rule);
            SystemRuleManager.loadRules(rules);
        }
    加载规则：
        FlowRuleManager.loadRules(List<FlowRule> rules); // 修改流控规则
        DegradeRuleManager.loadRules(List<DegradeRule> rules); // 修改降级规则
        SystemRuleManager.loadRules(List<SystemRule> rules); // 修改系统规则
        AuthorityRuleManager.loadRules(List<AuthorityRule> rules); // 修改授权规则
sentinel 熔断降级
    熔断降级规则包含下面几个重要的属性：
        resource	资源名，即规则的作用对象	
        grade	熔断策略，支持慢调用比例/异常比例/异常数策略	慢调用比例
        count	慢调用比例模式下为慢调用临界 RT（超出该值计为慢调用）；异常比例/异常数模式下为对应的阈值	
        timeWindow	熔断时长，单位为 s	
        minRequestAmount	熔断触发的最小请求数，请求数小于该值时即使异常比率超出阈值也不会熔断（1.7.0 引入）	5
        statIntervalMs	统计时长（单位为 ms），如 60*1000 代表分钟级（1.8.0 引入）	1000 ms
        slowRatioThreshold	慢调用比例阈值，仅慢调用比例模式有效（1.8.0 引入）
    几种降级策略：
        我们通常用以下几种降级策略：
            平均响应时间 (DEGRADE_GRADE_RT)：
                当资源的平均响应时间超过阈值（DegradeRule 中的 count，以 ms 为单位）之后，资源进入准降级状态。如果接下来 1s 内持续进入 5 个请求（即 QPS >= 5），它们的 RT 都持续超过这个阈值，那么在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地熔断（抛出 DegradeException）。
                注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。
            异常比例 (DEGRADE_GRADE_EXCEPTION_RATIO)：
                当资源的每秒异常总数占通过量的比值超过阈值（DegradeRule 中的 count）之后，资源进入降级状态，即在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法的调用都会自动地返回。
                异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。
            异常数 (DEGRADE_GRADE_EXCEPTION_COUNT)：
                当资源近 1 分钟的异常数目超过阈值之后会进行熔断。
                注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60s，则结束熔断状态后仍可能再进入熔断状态。
    熔断降级代码实现
        可以通过调用 DegradeRuleManager.loadRules() 方法来用硬编码的方式定义流量控制规则。
            @PostConstruct
                public void initSentinelRule()
                {
                    //熔断规则： 5s内调用接口出现异常次数超过5的时候, 进行熔断
                    List<DegradeRule> degradeRules = new ArrayList<>();
                    DegradeRule rule = new DegradeRule();
                    rule.setResource("queryGoodsInfo");
                    rule.setCount(5);
                    rule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT);//熔断规则
                    rule.setTimeWindow(5);
                    degradeRules.add(rule);
                    DegradeRuleManager.loadRules(degradeRules);
                }
    控制台降级规则
        不演示
    与Hystrix的熔断对比：
        Hystrix常用的线程池隔离会造成线程上下切换的overhead比较大；
        Hystrix使用的信号量隔离对某个资源调用的并发数进行控制，效果不错，但是无法对慢调用进行自动降级；
        Sentinel通过并发线程数的流量控制提供信号量隔离的功能；
        此外，Sentinel支持的熔断降级维度更多，可对多种指标进行流控、熔断，且提供了实时监控和控制面板，功能更为强大。
Sentinel 流控（限流）
    流量控制(Flow Control)，原理是监控应用流量的QPS或并发线程数等指标，当达到指定阈值时对流量进行控制，避免系统被瞬时的流量高峰冲垮，保障应用高可用性。
    通过流控规则来指定允许该资源通过的请求次数，例如下面的代码定义了资源 HelloWorld 每秒最多只能通过 20 个请求。 参考的规则定义如下：
        private static void initFlowRules(){
            List<FlowRule> rules = new ArrayList<>();
            FlowRule rule = new FlowRule();
            rule.setResource("HelloWorld");
            rule.setGrade(RuleConstant.FLOW_GRADE_QPS);
            // Set limit QPS to 20.
            rule.setCount(20);
            rules.add(rule);
            FlowRuleManager.loadRules(rules);
        }
    一条限流规则主要由下面几个因素组成，我们可以组合这些元素来实现不同的限流效果：
        resource：资源名，即限流规则的作用对象
            唯一名称，默认请求路径
        count: 限流阈值
            1.QPS：每秒请求数，当前调用该api的QPS到达阈值的时候进行限流
            2.线程数：当调用该api的线程数到达阈值的时候，进行限流
        grade: 限流阈值类型（QPS 或并发线程数）
        limitApp: 流控针对的调用来源，若为 default 则不区分调用来源
            Sentinel可以针对调用者进行限流，填写微服务名，默认为default(不区分来源)
        strategy: 调用关系限流策略
            1.直接：当api大达到限流条件时，直接限流
            2.关联：当关联的资源到达阈值，就限流自己
            3.链路：只记录指定路上的流量，指定资源从入口资源进来的流量，如果达到阈值，就进行限流，api级别的限流
        controlBehavior: 流量控制效果（直接拒绝、Warm Up、匀速排队）
    直接失败模式：
        使用API进行资源定义
            /**
             * 限流实现方式一: 抛出异常的方式定义资源
             *
             * @param orderId
             * @return
             */
            @ApiOperation(value = "纯代码限流")
            @GetMapping("/getOrder")
            @ResponseBody
            public String getOrder(@RequestParam(value = "orderId", required = false)String orderId)
            {
                Entry entry = null;
                // 资源名
                String resourceName = "getOrder";
                try
                {
                    // entry可以理解成入口登记
                    entry = SphU.entry(resourceName);
                    // 被保护的逻辑, 这里为订单查询接口
                    return "正常的业务逻辑 OrderInfo :" + orderId;
                } catch (BlockException blockException)
                {
                    // 接口被限流的时候, 会进入到这里
                    log.warn("---getOrder1接口被限流了---, exception: ", blockException);
                    return "接口限流, 返回空";
                } finally
                {
                    // SphU.entry(xxx) 需要与 entry.exit() 成对出现,否则会导致调用链记录异常
                    if (entry != null)
                    {
                        entry.exit();
                    }
                }
            }
        代码限流规则：
            /限流规则 QPS mode,
            List<FlowRule> rules = new ArrayList<FlowRule>();
            FlowRule rule1 = new FlowRule();
            rule1.setResource("getOrder");
            // QPS控制在2以内
            rule1.setCount(2);
            // QPS限流
            rule1.setGrade(RuleConstant.FLOW_GRADE_QPS);
            rule1.setLimitApp("default");
            rules.add(rule1);
            FlowRuleManager.loadRules(rules);
    关联模式
        调用关系包括调用方、被调用方；一个方法又可能会调用其它方法，形成一个调用链路的层次关系。
        Sentinel 通过 NodeSelectorSlot 建立不同资源间的调用的关系，并且通过 ClusterBuilderSlot 记录每个资源的实时统计信息。、
        当两个资源之间具有资源争抢或者依赖关系的时候，这两个资源便具有了关联。
        比如对数据库同一个字段的读操作和写操作存在争抢，读的速度过高会影响写得速度，写的速度过高会影响读的速度。
        如果放任读写操作争抢资源，则争抢本身带来的开销会降低整体的吞吐量。可使用关联限流来避免具有关联关系的资源之间过度的争抢.
        eg1:
            read_db 和 write_db 这两个资源分别代表数据库读写，我们可以给 read_db 设置限流规则来达到写优先的目的。具体的方法：
                设置 `strategy` 为 `RuleConstant.STRATEGY_RELATE` 
                设置 `refResource` 为 `write_db`。
                这样当写库操作过于频繁时，读数据的请求会被限流。
        eg2:
            电商的 下订单 和 支付两个操作，需要优先保障 支付， 可以根据 支付接口的 流量阈值，来对订单接口进行限制，从而保护支付的目的。
        使用注解进行资源定义:
            @SentinelResource(value = "test1", blockHandler = "exceptionHandler")
            @GetMapping("/test1")
            public String test1()
            {
                log.info(Thread.currentThread().getName() + "\t" + "...test1");
                return "-------hello baby，i am test1";
            }
            // Block 异常处理函数，参数最后多一个 BlockException，其余与原函数一致.
            public String exceptionHandler(BlockException ex)
            {
                // Do some log here.
                ex.printStackTrace();
                log.info(Thread.currentThread().getName() + "\t" + "...exceptionHandler");
                return String.format("error: test1  is not OK");
            }
            @SentinelResource(value = "test1_ref")
            @GetMapping("/test1_ref")
            public String test1_ref()
            {
                log.info(Thread.currentThread().getName() + "\t" + "...test1_related");
                return "-------hello baby，i am test1_ref";
            }
        代码配置关联限流规则：
            // 关联模式流控  QPS控制在1以内
            String refResource = "test1_ref";
            FlowRule rRule = new FlowRule("test1")
                    .setCount(1)  // QPS控制在1以内
                    .setStrategy(RuleConstant.STRATEGY_RELATE)
                    .setRefResource(refResource);
            rules.add(rRule);
            FlowRuleManager.loadRules(rules);
    Warm up（预热）模式
        当流量突然增大的时候，我们常常会希望系统从空闲状态到繁忙状态的切换的时间长一些。
        即如果系统在此之前长期处于空闲的状态，我们希望处理请求的数量是缓步的增多，经过预期的时间以后，到达系统处理请求个数的最大值。
        Warm Up（冷启动，预热）模式就是为了实现这个目的的。默认 coldFactor 为 3，即请求 QPS 从 threshold / 3 开始，经预热时长逐渐升至设定的 QPS 阈值。
        使用注解定义资源：
            @SentinelResource(value = "testWarmUP", blockHandler = "exceptionHandlerOfWarmUp")
            @GetMapping("/testWarmUP")
            public String testWarmUP()
            {
                log.info(Thread.currentThread().getName() + "\t" + "...test1");
                return "-------hello baby，i am testWarmUP";
            }
        代码限流规则
            FlowRule warmUPRule = new FlowRule();
            warmUPRule.setResource("testWarmUP");
            warmUPRule.setCount(20);
            warmUPRule.setGrade(RuleConstant.FLOW_GRADE_QPS);
            warmUPRule.setLimitApp("default");
            warmUPRule.setControlBehavior(RuleConstant.CONTROL_BEHAVIOR_WARM_UP);
            warmUPRule.setWarmUpPeriodSec(10);
    排队等待模式：
        匀速排队（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法。阈值必须设置为QPS。
        这种方式主要用于处理间隔性突发的流量，例如消息队列。想象一下这样的场景，在某一秒有大量的请求到来，而接下来的几秒则处于空闲状态，我们希望系统能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒直接拒绝多余的请求。
        某瞬时来了大流量的请求, 而如果此时要处理所有请求，很可能会导致系统负载过高，影响稳定性。但其实可能后面几秒之内都没有消息投递，若直接把多余的消息丢掉则没有充分利用系统处理消息的能力。Sentinel的Rate Limiter模式能在某一段时间间隔内以匀速方式处理这样的请求, 充分利用系统的处理能力, 也就是削峰填谷, 保证资源的稳定性.
        Sentinel会以固定的间隔时间让请求通过, 访问资源。当请求到来的时候，如果当前请求距离上个通过的请求通过的时间间隔不小于预设值，则让当前请求通过；
        否则，计算当前请求的预期通过时间，如果该请求的预期通过时间小于规则预设的 timeout 时间，则该请求会等待直到预设时间到来通过；反之，则马上抛出阻塞异常。
        使用Sentinel的这种策略, 简单点说, 就是使用一个时间段(比如20s的时间)处理某一瞬时产生的大量请求, 起到一个削峰填谷的作用, 从而充分利用系统的处理能力, 下图能很形象的展示这种场景: X轴代表时间, Y轴代表系统处理的请求.
        eg:
            模拟2个用户同时并发的访问资源，发出100个请求,
            如果设置QPS阈值为1, 拒绝策略修改为Rate Limiter匀速RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER方式,
            还需要设置setMaxQueueingTimeMs(20 * 1000)表示每一请求最长等待时间, 这里等待时间大一点, 以保证让所有请求都能正常通过;
            假设这里设置的排队等待时间过小的话, 导致排队等待的请求超时而抛出异常BlockException, 最终结果可能是这100个并发请求中只有一个请求或几个才能正常通过, 所以使用这种模式得根据访问资源的耗时时间决定排队等待时间. 按照目前这种设置, QPS阈值为10的话, 每一个请求相当于是以匀速100ms左右通过.
            使用注解定义资源
                @SentinelResource(value = "testLineUp", blockHandler = "exceptionHandlerOftestLineUp")
                @GetMapping("/testLineUp")
                public String testLineUp() {
                    log.info(Thread.currentThread().getName() + "\t" + "...test1");
                    return "-------hello baby，i am testLineUp";
                }
            代码限流规则
                FlowRule lineUpRule = new FlowRule();
                lineUpRule.setResource("testLineUp");
                lineUpRule.setCount(10);
                lineUpRule.setGrade(RuleConstant.FLOW_GRADE_QPS);
                lineUpRule.setLimitApp("default");
                lineUpRule.setMaxQueueingTimeMs(20 * 1000);
                // CONTROL_BEHAVIOR_DEFAULT means requests more than threshold will be rejected immediately.
                // CONTROL_BEHAVIOR_DEFAULT将超过阈值的流量立即拒绝掉.
                lineUpRule.setControlBehavior(RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER);
                rules.add(lineUpRule);
    热点规则(ParamFlowRule)：
        何为热点？热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的 Top K 数据，并对其访问进行限制。比如：
            商品 ID 为参数，统计一段时间内最常购买的商品 ID 并进行限制
            用户 ID 为参数，针对一段时间内频繁访问的用户 ID 进行限制 热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅对包含热点参数的资源调用生效。 使用该规则需要引入依赖：
        热点参数规则（ParamFlowRule）类似于流量控制规则（FlowRule）：
            resource	资源名，必填	
            count	限流阈值，必填	
            grade	限流模式	QPS 模式
            durationInSec	统计窗口时间长度（单位为秒），1.6.0 版本开始支持	1s
            controlBehavior	流控效果（支持快速失败和匀速排队模式），1.6.0 版本开始支持	快速失败
            maxQueueingTimeMs	最大排队等待时长（仅在匀速排队模式生效），1.6.0 版本开始支持	0ms
            paramIdx	热点参数的索引，必填，对应 SphU.entry(xxx, args) 中的参数索引位置	
            paramFlowItemList	参数例外项，可以针对指定的参数值单独设置限流阈值，不受前面 count 阈值的限制。仅支持基本类型和字符串类型	
            clusterMode	是否是集群参数流控规则	false
            clusterConfig	集群流控相关配置
        自定义资源
            @GetMapping("/byHotKey")
                @SentinelResource(value = "byHotKey", blockHandler = "userAccessError")
                public String test4(@RequestParam(value = "userId", required = false) String userId,
                                    @RequestParam(value = "goodId", required = false) int goodId)
                {
                    log.info(Thread.currentThread().getName() + "\t" + "...byHotKey");
                    return "-----------by HotKey： UserId";
                }
        限流规则代码：
            可以通过 ParamFlowRuleManager 的 loadRules 方法更新热点参数规则，下面是官方实例：
                ParamFlowRule rule = new ParamFlowRule(resourceName)
                    .setParamIdx(0)
                    .setCount(5);
                // 针对 int 类型的参数 PARAM_B，单独设置限流 QPS 阈值为 10，而不是全局的阈值 5.
                ParamFlowItem item = new ParamFlowItem().setObject(String.valueOf(PARAM_B))
                    .setClassType(int.class.getName())
                    .setCount(10);
                rule.setParamFlowItemList(Collections.singletonList(item));
                ParamFlowRuleManager.loadRules(Collections.singletonList(rule));
                具体的限流代码如下：
                    ParamFlowRule pRule = new ParamFlowRule("byHotKey")
                                    .setParamIdx(1)
                                    .setCount(1);
                    // 针对 参数值1000，单独设置限流 QPS 阈值为 5，而不是全局的阈值 1.
                    ParamFlowItem item = new ParamFlowItem().setObject(String.valueOf(1000))
                            .setClassType(int.class.getName())
                            .setCount(5);
                    pRule.setParamFlowItemList(Collections.singletonList(item));
                    ParamFlowRuleManager.loadRules(Collections.singletonList(pRule));
原理：
    ProcessorSlotChain：
        Sentinel的核心架构，将不同的slot按照顺序串在一起（责任链模式），从而将不同的功能（限流、降级、系统保护）组合在一起
        系统会为每个资源创建一套SlotChain
        slot chain其实可以分为两部分：统计数据构建部分（statistic）和判断部分（rule checking）
    SPI机制
        Sentinel槽链中各slot的执行顺序是固定好的。但是并不是绝对不能改变的。sentinel将ProcessorSolt作为SPI接口进行扩展
        使得SlotChain具备了扩展能力。用户可以自定义slot并编排slot间的顺序
        StatisticSlot监控统计 -> SystemSlot系统保护 -> FlowSlot流量控制 -> DegradeSlot熔断降级
            这每一步中奖都可以加入MyCustomSlot自定义实现
    常用slot简介：
        NodeSelectorSlot
            负责收集资源的路径，并将这些资源的调用路径以树状结构存储起来，用于根据调用路径来限流降级
        ClusterbuilderSlot
            用于存储资源统计信息以及调用者信息，例如该资源的RT、QPS、thread count等等，这些信息将用作多维度限流、降级的依据。简单来说就是用于构建ClusterNode
        StatisticSlot
            用于记录、统计不同维度的runtime指标监控信息
        ParamFlowSlot
            对应热点流控
        FlowSlot
            用于根据预设限流规则以及前面slot统计的状态，来进行流量控制。对应'流控规则'
        AuthoritySlot
            根据配置的黑白名单和调用信息来源，做黑白名单规则。对应授权规则
        DeagadeSlot
            降级规则
        SystemSlot
            通过系统状态，例如load1等，来控制入口流量。对应系统规则
    context简介
        context是对资源操作的上下文，每个资源操作必须属于一个context。如果代码中没有指定context，
        则会创建一个name为sentinel_default_context的默认context
        一个context生命周期中可以包含多个资源操作。context生命周期最后一个资源在exit()时会清理该context，这也就意味着这个context生命周期结束了
    Node的关系
        Node：用于完成数据统计
        StatisticNode：统计节点，是Node接口的实现类，用于完成数据统计
        EntranceNode：入口节点，一个Context会有一个入口节点，用于统计当前Context的总体流量数据
        DefaultNode：默认节点，用于统计一个资源在当前Context中的流量数据
        ClisterNode：集群节点，用于统计一个资源在所有Context中的总体流量数据
    滑动时间窗算法：
        时间窗算法
            系统会自动选定一个时间窗口的起始零点，然后按照固定长度将时间轴划分为若干定长的时间窗口。所以该算法也成为"固定时间窗口算法"。
            当请求到达时，系统会查看该请求到达的时间点所在的时间窗口当前统计的数据是否超过了预先设定好的阈值。未超出，则请求通过，否则被限流
            存在的问题：
                如果用户在上一个窗口的最后一刻和下一个窗口的最前一刻发起冲击服务，那么时间窗限制的流量就不起作用
        滑动时间窗算法初级：
            时间窗口随着时间的流失而移动，最开始的窗口将会失效，但是也会生成新的窗口。来新的请求的时候就看这个时间窗口内的请求是否超过阈值
            存在的问题：
                随着生成新的时间窗口，重复统计了时间窗口内的一部分请求，资源浪费
        滑动时间窗算法高级：
            将时间轴划分为一个个样本窗口，比如每个样本窗口长度为250ms，然后滑动时间窗长度为1s，那么一个滑动时间窗就有4个样本窗口
            那么在时间窗滑动时，是随着样本窗口的大小来滑动，这样就可以避免重复统计一部分数据。
            假设我们将1s划分为四个窗口，则每个窗口对应250ms。假设恶意用户还是在上一秒最后一刻和下一秒第一刻冲击服务，按照滑动窗口原理
            此时统计上一秒最后750ms和下一秒250ms，这种方式能够判断出用户的访问依旧超过了1s的访问数量，此时依然会阻拦用户访问
        源码分析：
            public abstract class LeapArray<T> {
                //样本窗口长度
                protected int windowLengthInMs;
                //一个时间窗中的样本窗口数量
                protected int sampleCount;
                //时间窗长度
                protected int intervalInMs;
                //这是一个数组，元素为WindowWrap样本窗口
                protected final AtomicReferenceArray<WindowWrap<T>> array;
                //核心代码获取当前样本窗口
                public WindowWrap<T> currentWindow(long timeMillis) {
                    if (timeMillis < 0) {
                        return null;
                    }
                    //计算当前时间所在的样本窗口id，即在计算数组LeapArray中的索引
                    //样本窗口是一个闭路循环，这里取余重新开始写下一轮时间窗口值
                    int idx = calculateTimeIdx(timeMillis);
                    //计算当前样本窗口的时间点
                    long windowStart = calculateWindowStart(timeMillis);
                    while (true) {
                        //获取当前时间所在的样本窗口
                        WindowWrap<T> old = array.get(idx);
                        if (old == null) {
                            //若当前所在样本窗口为null，则新建一个样本窗口
                            WindowWrap<T> window = new WindowWrap<T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));
                            //通过CAS方式将新建窗口放入到array
                            if (array.compareAndSet(idx, null, window)) {
                                return window;
                            } else {
                                Thread.yield();
                            }
                        } else if (windowStart == old.windowStart()) {
                            //若当前样本窗口的起始时间与计算出的样本窗口时间相同，则是同一个样本窗口，直接返回
                            return old;
                        } else if (windowStart > old.windowStart()) {
                            //若当前样本窗口起始时间大于计算出的样本窗口起始时间，说明计算出的样本窗口已经过时，需要将原来的样本窗口替换
                            if (updateLock.tryLock()) {
                                try {
                                    // Successfully get the update lock, now we reset the bucket.
                                    return resetWindowTo(old, windowStart);
                                } finally {
                                    updateLock.unlock();
                                }
                            } else {
                                // Contention failed, the thread will yield its time slice to wait for bucket available.
                                Thread.yield();
                            }
                        } else if (windowStart < old.windowStart()) {
                            //若当前样本窗口起始时间小于计算出的样本窗口起始时间，这一般不会出现，除非时间倒流
                            return new WindowWrap<T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis));
                        }
                    }
                }
            }
            //样本窗口实例，泛型T实际为Metricbucket类型
            public class WindowWrap<T> {
                //样本窗口长度
                private final long windowLengthInMs;
                //样本窗口起始时间戳
                private long windowStart;
                //样本窗口中的统计数据，类型为Metricbucket
                private T value;
            }

            
   
            
        
    源码分析
        入口源码（CtSph.entryWithPriority）
            1，从ThreadLocal中获取Context。
                //一个请求会占用一个线程，一个线程会绑定一个Context
                Context context = ContextUtil。getContext();
            2，如果context是NullContext，则表示当前系统中的Context数量超出阈值，即访问请求数量超出了阈值，此时直接返回一个无需做规则校验的资源操作对象
                if (context instanceof NullContext) {
                    return new CtEntry(resourceWrapper, null, context);
                }
            3，如果线程中没有绑定context，则创建一个context将其放入ThreadLocal
                if (context == null) {
                    context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME);
                }
            4，如果全局开关关闭，则直接返回一个无需规则检测的资源操作对象
                if (!Constants.ON) {
                    return new CtEntry(reourceWrapper, null, context);
                }
            5，查找SlotChain
                ProcessSlot<Object> chain = lookProcessChain(reourceWrapper);
                if (chain == null) {
                    //如果没有找到chain，则意味着chain数量超出阈值
                }
            6，创建一个资源操作对象
                Entry e = new CtEntry(resourceWrapper, chain, context);
            7，对资源进行操作
                chain.entry(context, resourceWrapper, null, count, prioritized, args);
        上述第三步：获取context（InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME)）
            //尝试从ThreadLocal中获取Context
            Context context = contextHolder.get();
            //如果ThreadLocal中没有context，则尝试从缓存map中获取
            if (context == null) {
                //缓存map的key为context名称，value为EntranceNode
                Map<String, DefaultNode> localCacheNameMap = contextNameNodeMap;
                //获取EntranceNode---双重检测锁DCL（为了防止并发创建）
                DefaultNode node = localCacheNameMap.get(name);
                if (node == null) {
                    //若缓存map的size大于context数量的最大阈值，则直接返回NULL_CONTEXT
                    if (localCacheNameMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) {
                        setNullContext();
                        return NULL_CONTEXT;
                    } else {
                        try {
                            LOCK.lock();
                            node = contextNameNodeMap.get(name);
                            if (node == null) {
                                if (contextNameNodeMap.size() > Constants.MAX_CONTEXT_NAME_SIZE) {
                                    setNullContext();
                                    return NULL_CONTEXT;
                                } else {
                                    //创建一个EntranceNode
                                    node = new EntranceNode(new StringResourceWrapper(name, EntryType.IN), null);
                                    //将新创建node添加到root
                                    Constants.ROOT.addChild(node);
                                    //将新建node写入到map
                                    //为了防止迭代稳定性，copyOnWrite，对于共享集合的写操作
                                    Map<String, DefaultNode> newMap = new HashMap<>(contextNameNodeMap.size() + 1);
                                    newMap.putAll(contextNameNodeMap);
                                    newMap.put(name, node);
                                    contextNameNodeMap = newMap;
                                }
                            }
                        } finally {
                            LOCK.unlock();
                        }
                    }
                }
                //将context的name与entranceNode封装为context
                context = new Context(node, name);
                //初始化context来源
                context.setOrigin(origin);
                //将context写入到ThreadLocal
                contextHolder.set(context);
            }
            return context;
        上述第五步：查找slotChain（lookProcessChain(reourceWrapper);）
            //从缓存map中获取SlotChain
            //缓存map的key为资源，value为其相关的SlotChain
            ProcessorSlotChain chain = chainMap.get(resourceWrapper);
            //DCL
            //若缓存中没有相关的SlotChain，则创建一个并放入到缓存
            if(chain == null){
                synchronized (LOCK){
                    chain = chainMap.get(resourceWrapper);
                    if(chain == null){
                        //缓存mao的size >= chain数量最大值，则返回null，不再创建新的chian
                        if (chainMap.size() >= Constants.MAX_SLOT_CHAIN_SIZE) {
                            return null;
                        }
                        //创建新的chain
                        chain = SlotChainProvider.newSlotChain();
                        //防止迭代稳定性
                        Map<ResourceWrapper,ProcessorSlotChain> newMap = new HashMap<>(chainMap.size() + 1);
                        newMap.putAll(chainMap);
                        newMap.put(resourceWrapper, chain);
                        chainMap = newMap;
                    }
                }
            }
            return chain;
            上述步骤中的：创建SlotChain（SlotChainProvider.newSlotChain();）
                ProcessorSlotChain chain = new DefaultProcessorSlotChain();
                //通过SPI方式构建Slot
                //这里会获取所有的slot插槽（NodeSelectorSlot、ClusterbuilderSlot、StatisticSlot、FlowSlot、AuthoritySlot、DeagadeSlot、SystemSlot......）
                List<ProcessorSlot> sprtedSlotList = SpiLoader.of(ProcessorSlot.class).loadInstanceListSorted();
                for (ProcessorSlot slot : sprtedSlotList) {
                    if (!(slot instanceof AbstractLinkedProcessorSlot)) {
                        //记录信息
                        RecordLog.warn("The ProcessorSlot is not an instance of");
                        continue;
                    }
                    //ProcessorSlotChain中的slot是一个单项链表，有first和end指针分别指向slot节点
                    chain.addLast((AbstractLinkedProcessorSlot<?>)slot);
                }
        上述第七步：对资源进行操作（chain.entry(context, resourceWrapper, null, count, prioritized, args);）
            这里就是链式循环运行SlotChain中各个slot，这里我们分析几个关键的slot
                1，NodeSelectorSlot
                    //从缓存中获取DefaultNode
                    DefaultNode node = map.get(context.getName());
                    //DCL---双重检测锁
                    if (node == null) {
                        synchronized (this) {
                            node = map.get(context.getName());
                            if (node == null) {
                                //创建DefaultNode
                                node = new DefaultNode(resourceWrapper, null);
                                HashMap<String, DefaultNode> cacheMap = new HashMap<String, DefaultNode>(map.size());
                                cacheMap.putAll(map);
                                cacheMap.put(context.getName(), node);
                                map = cacheMap;
                                // Build invocation tree
                                //将新建的node添加到调用树中
                                ((DefaultNode) context.getLastNode()).addChild(node);
                            }
                        }
                    }
                    context.setCurNode(node);
                    //触发下一个节点
                    fireEntry(context, resourceWrapper, node, count, prioritized, args);
                2，StatisticSlot
                    try {
                        //调用SlotChain中后续的所有Slot，完成所有规则检测
                        //其在执行过程中可能会抛出异常，例如规则检测未通过，跑出BlockException
                        fireEntry(context, resourceWrapper, node, count, prioritized, args);
                        //代码能走到这里，说明钱前面所有检测通过，此时可以将该请求统计到相应的数据中了
                        //增加线程数
                        node.increaseThreadNum();
                        //增加通过的请求数量
                        node.addPassRequest(count);
                        if (context.getCurEntry().getOriginNode() != null) {
                            // Add count for origin node.
                            context.getCurEntry().getOriginNode().increaseThreadNum();
                            context.getCurEntry().getOriginNode().addPassRequest(count);
                        }
                        if (resourceWrapper.getEntryType() == EntryType.IN) {
                            // Add count for global inbound entry node for global statistics.
                            Constants.ENTRY_NODE.increaseThreadNum();
                            Constants.ENTRY_NODE.addPassRequest(count);
                        }
                        // Handle pass event with registered entry callback handlers.
                        for (ProcessorSlotEntryCallback<DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) {
                            handler.onPass(context, resourceWrapper, node, count, args);
                        }
                    } catch (PriorityWaitException ex) {
                        node.increaseThreadNum();
                        if (context.getCurEntry().getOriginNode() != null) {
                            // Add count for origin node.
                            context.getCurEntry().getOriginNode().increaseThreadNum();
                        }
                        if (resourceWrapper.getEntryType() == EntryType.IN) {
                            // Add count for global inbound entry node for global statistics.
                            Constants.ENTRY_NODE.increaseThreadNum();
                        }
                        // Handle pass event with registered entry callback handlers.
                        for (ProcessorSlotEntryCallback<DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) {
                            handler.onPass(context, resourceWrapper, node, count, args);
                        }
                    } catch (BlockException e) {
                        // Blocked, set block exception to current entry.
                        context.getCurEntry().setBlockError(e);
                        // Add block count.
                        node.increaseBlockQps(count);
                        if (context.getCurEntry().getOriginNode() != null) {
                            context.getCurEntry().getOriginNode().increaseBlockQps(count);
                        }
                        if (resourceWrapper.getEntryType() == EntryType.IN) {
                            // Add count for global inbound entry node for global statistics.
                            Constants.ENTRY_NODE.increaseBlockQps(count);
                        }
                        // Handle block event with registered entry callback handlers.
                        for (ProcessorSlotEntryCallback<DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) {
                            handler.onBlocked(e, context, resourceWrapper, node, count, args);
                        }
                        throw e;
                    } catch (Throwable e) {
                        // Unexpected internal error, set error to current entry.
                        context.getCurEntry().setError(e);
                        throw e;
                    }
                3，FlowSlot
                    if (ruleProvider == null || resource == null) {
                        return;
                    }
                    //获取指定资源的所有流控规则
                    Collection<FlowRule> rules = ruleProvider.apply(resource.getName());
                    if (rules != null) {
                        //逐个应用流控规则。若无法通过抛出异常
                        for (FlowRule rule : rules) {
                            if (!canPassCheck(rule, context, node, count, prioritized)) {
                                throw new FlowException(rule.getLimitApp(), rule);
                            }
                        }
                    }
                    私有方法canPassCheck：
                        public boolean canPassCheck(/*@NonNull*/ FlowRule rule, Context context, DefaultNode node, int acquireCount,
                            //从规则中获取限定的来源
                            String limitApp = rule.getLimitApp();
                            //如果限流来源为null，则请求直接通过
                            if (limitApp == null) {
                                return true;
                            }
                            //使用规则处理集群流控
                            if (rule.isClusterMode()) {
                                return passClusterCheck(rule, context, node, acquireCount, prioritized);
                            }
                            //使用规则处理单机流控
                            return passLocalCheck(rule, context, node, acquireCount, prioritized);
                        }
                        private static boolean passLocalCheck(FlowRule rule, Context context, DefaultNode node, int acquireCount, boolean prioritized) {
                            //通过规则形成选择出的规则node
                            Node selectedNode = selectNodeByRequesterAndStrategy(rule, context, node);
                            //若没有node，说明没有规则，表示通过检测
                            if (selectedNode == null) {
                                return true;
                            }
                            //使用规则进行逐项检测，分别对应的是快速失败、漏斗算法、令牌算法
                            return rule.getRater().canPass(selectedNode, acquireCount, prioritized);
                        }
                        1，快速失败
                        @Override
                        public boolean canPass(Node node, int acquireCount, boolean prioritized) {
                            //获取当前时间窗中已经统计好的数据
                            int curCount = avgUsedTokens(node);
                            //若已经统计的数据与本次请求的数量和大于设置的阈值，则返回false
                            //若小于等于阈值，返回true，表示通过检测
                            if (curCount + acquireCount > count) {
                                if (prioritized && grade == RuleConstant.FLOW_GRADE_QPS) {
                                    long currentTime;
                                    long waitInMs;
                                    currentTime = TimeUtil.currentTimeMillis();
                                    waitInMs = node.tryOccupyNext(currentTime, acquireCount, count);
                                    if (waitInMs < OccupyTimeoutProperty.getOccupyTimeout()) {
                                        node.addWaitingRequest(currentTime + waitInMs, acquireCount);
                                        node.addOccupiedPass(acquireCount);
                                        sleep(waitInMs);
                                        // PriorityWaitException indicates that the request will pass after waiting for {@link @waitInMs}.
                                        throw new PriorityWaitException(waitInMs);
                                    }
                                }
                                return false;
                            }
                            return true;
                        }
                4，DeagadeSlot（降级）   
                    void performChecking(COntext context, ResourceWrapper r) throws BlockException {
                        //获取当前资源的所有熔断器
                        List<CircuitBreaker> circuitBreakers = DegradeRuleManager.getCircuitBreakers(r.getName());
                        若熔断器为空，则直接结束
                        if (circuitBreakers == null || circuitBreakers.isEmpty()) {
                            return;
                        }
                        逐个尝试熔断器
                        for (CircuitBreaker cb : circuitBreakers) {
                            if (!cb.tryPass(context)) {
                                抛出异常
                            }
                        }
                    }
                    public boolean tryPass(Context context) {
                        熔断状态为关闭状态，则请求可以通过
                        if (currentState.get() == State.CLOSED) {
                            return true;
                        }
                        熔断状态为打开状态，此时再查看
                        若下次时间窗时间点已到达，且熔断器成功由Open变为Half-Open，则请求通过
                        if (currentState.get() == State.OPEN) {
                            return retryTimeoutArrived() && fromOpenToHalfOpen(context);
                        }
                        return false;
                    }
            
            
    
    
# 微服务注册中心的注册表如何更好的防止读写并发冲突
    使用读写锁

1，微服务注册中心的注册表如何更好的防止读写并发冲突？
2、Nacos如何支撑阿里巴巴内部上百万服务实例的访问？
3、Nacos高并发异步注册架构知道如何设计的吗？
10、Nacos集群CP架构底层类Raft协议怎么实现的？
11、Nacos&Eureka&Zookeeper集群架构都有脑裂问题吗？

5、Sentinel底层滑动时间窗限流算法怎么实现的？
6、Sentinel底层是如何计算线上系统实时QPS的？

7、Seata分布式事务协调管理器是如何实现的？
8、Seata分布式事务一致性锁机制如何设计的？
9、Seata分布式事务回滚机制如何实现的？

12、如何设计能支撑全世界公司使用的微服务云架构？
13、RocketMQ架构如何设计能支撑每天万亿级消息处理？
14、RocketMQ在交易支付场景如何做到消息零丢失？

https://www.cnblogs.com/javaguide/p/14202860.html

                   
    