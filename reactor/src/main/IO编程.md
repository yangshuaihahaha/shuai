# IO读写原理
基础知识：
    1，read系统的调用，并不是把数据直接从物理设备读数据到内存；write系统的调用也不是直接把数据写入到屋里设备
    2，read系统调用，是把数据从内核缓冲区复制到进程缓冲区；而write系统调用，是把数据从进程缓冲区复制到内核缓冲区
    3，等待缓冲区达到一定数量的时候，再进行IO的调用，提升性能。至于什么时候读取和存储则由内核来决定，用户程序不需要关心。
    4，用户程序的IO读写程序，大多数情况下，并没有进行实际的IO操作，而是在读写自己的进程缓冲区。
java IO读写的底层流程
     用户程序进行IO的读写，基本上会用到系统调用read&write，read把数据从内核缓冲区复制到进程缓冲区
     write把数据从进程缓冲区复制到内核缓冲区，它们不等价于数据在内核缓冲区和磁盘之间的交换。
     典型Java 服务端处理网络请求的典型过程：
        （1）客户端请求
            Linux通过网卡，读取客户断的请求数据，将数据读取到内核缓冲区。
        （2）获取请求数据
            服务器从内核缓冲区读取数据到Java进程缓冲区。
        （3）服务器端业务处理
            Java服务端在自己的用户空间中，处理客户端的请求。
        （4）服务器端返回数据
            Java服务端已构建好的响应，从用户缓冲区写入系统缓冲区。
        （5）发送给客户端
            Linux内核通过网络 I/O ，将内核缓冲区中的数据，写入网卡，网卡通过底层的通讯协议，会将数据发送给目标客户端。
四种主要的IO模型
    （1）同步阻塞IO（Blocking IO）
        首先，解释一下这里的阻塞与非阻塞：
            阻塞IO，指的是需要内核IO操作彻底完成后，才返回到用户空间，执行用户的操作。阻塞指的是用户空间程序的执行状态，用户空间程序需等到IO操作彻底完成。
            传统的IO模型都是同步阻塞IO。在java中，默认创建的socket都是阻塞的。
        其次，解释一下同步与异步：
            同步IO，是一种用户空间与内核空间的调用发起方式。同步IO是指用户空间线程是主动发起IO请求的一方，内核空间是被动接受方。异步IO则反过来，是指内核kernel是主动发起IO请求的一方，用户线程是被动接受方。
    （2）同步非阻塞IO（Non-blocking IO）
        非阻塞IO，指的是用户程序不需要等待内核IO操作完成后，内核立即返回给用户一个状态值，用户空间无需等到内核的IO操作彻底完成，可以立即返回用户空间，执行用户的操作，处于非阻塞的状态。
        简单的说：阻塞是指用户空间（调用线程）一直在等待，而且别的事情什么都不做；非阻塞是指用户空间（调用线程）拿到状态就返回，IO操作可以干就干，不可以干，就去干的事情。
        非阻塞IO要求socket被设置为NONBLOCK。
        强调一下，这里所说的NIO（同步非阻塞IO）模型，并非Java的NIO（New IO）库。
    （3）IO多路复用（IO Multiplexing）
        即经典的Reactor设计模式，有时也称为异步阻塞IO，Java中的Selector和Linux中的epoll都是这种模型。
    （4）异步IO（Asynchronous IO）
        异步IO，指的是用户空间与内核空间的调用方式反过来。用户空间线程是变成被动接受的，内核空间是主动调用者。
        这一点，有点类似于Java中比较典型的模式是回调模式，用户空间线程向内核空间注册各种IO事件的回调函数，由内核去主动调用。
同步阻塞IO（Blocking IO）
    在linux中的Java进程中，默认情况下所有的socket都是blocking IO。在阻塞式 I/O 模型中，应用程序在从IO系统调用开始，一直到到系统调用返回，这段时间是阻塞的。返回成功后，应用进程开始处理用户空间的缓存数据。
    举个栗子，发起一个blocking socket的read读操作系统调用，流程大概是这样：
        （1）当用户线程调用了read系统调用，内核（kernel）就开始了IO的第一个阶段：准备数据。很多时候，数据在一开始还没有到达（比如，还没有收到一个完整的Socket数据包），这个时候kernel就要等待足够的数据到来。
        （2）当kernel一直等到数据准备好了，它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。
        （3）从开始IO读的read系统调用开始，用户线程就进入阻塞状态。一直到kernel返回结果后，用户线程才解除block的状态，重新运行起来。
        所以，blocking IO的特点就是在内核进行IO执行的两个阶段，用户线程都被block了。
        BIO的优点：
           程序简单，在阻塞等待数据期间，用户线程挂起。用户线程基本不会占用 CPU 资源。
        BIO的缺点：
           一般情况下，会为每个连接配套一条独立的线程，或者说一条线程维护一个连接成功的IO流的读写。在并发量小的情况下，这个没有什么问题。
           但是，当在高并发的场景下，需要大量的线程来维护大量的网络连接，内存、线程切换开销会非常巨大。因此，基本上，BIO模型在高并发场景下是不可用的。
同步非阻塞NIO（None Blocking IO）
    在linux系统下，可以通过设置socket使其变为non-blocking。NIO 模型中应用程序在一旦开始IO系统调用，会出现以下两种情况：
        （1）在内核缓冲区没有数据的情况下，系统调用会立即返回，返回一个调用失败的信息。
        （2）在内核缓冲区有数据的情况下，是阻塞的，直到数据从内核缓冲复制到用户进程缓冲。复制完成后，系统调用返回成功，应用进程开始处理用户空间的缓存数据。
    举个栗子。发起一个non-blocking socket的read读操作系统调用，流程是这个样子：
        （1）在内核数据没有准备好的阶段，用户线程发起IO请求时，立即返回。用户线程需要不断地发起IO系统调用。
        （2）内核数据到达后，用户线程发起系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。
        （3）用户线程才解除block的状态，重新运行起来。经过多次的尝试，用户线程终于真正读取到数据，继续执行。
    NIO的特点：
        应用程序的线程需要不断的进行 I/O 系统调用，轮询数据是否已经准备好，如果没有准备好，继续轮询，直到完成系统调用为止。
    NIO的优点：
        每次发起的 IO 系统调用，在内核的等待数据过程中可以立即返回。用户线程不会阻塞，实时性较好。
    NIO的缺点：
        需要不断的重复发起IO系统调用，这种不断的轮询，将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低。
    总之，NIO模型在高并发场景下，也是不可用的。一般 Web 服务器不使用这种 IO 模型。一般很少直接使用这种模型，而是在其他IO模型中使用非阻塞IO这一特性。java的实际开发中，也不会涉及这种IO模型。
    再次说明，Java NIO（New IO） 不是IO模型中的NIO模型，而是另外的一种模型，叫做IO多路复用模型（ IO multiplexing ）。    
IO多路复用模型(I/O multiplexing）
    如何避免同步非阻塞NIO模型中轮询等待的问题呢？这就是IO多路复用模型。
    IO多路复用模型，就是通过一种新的系统调用，一个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是内核缓冲区可读/可写），内核kernel能够通知程序进行相应的IO系统调用。
    目前支持IO多路复用的系统调用，有 select，epoll等等。select系统调用，是目前几乎在所有的操作系统上都有支持，具有良好跨平台特性。epoll是在linux 2.6内核中提出的，是select系统调用的linux增强版本。
    IO多路复用模型的基本原理就是select/epoll系统调用，单个线程不断的轮询select/epoll系统调用所负责的成百上千的socket连接，当某个或者某些socket网络连接有数据到达了，就返回这些可以读写的连接。
    因此，好处也就显而易见了——通过一次select/epoll系统调用，就查询到到可以读写的一个甚至是成百上千的网络连接。
    举个栗子。发起一个多路复用IO的的read读操作系统调用，流程是这个样子：
        在这种模式中，首先不是进行read系统调动，而是进行select/epoll系统调用。当然，这里有一个前提，需要将目标网络连接，提前注册到select/epoll的可查询socket列表中。然后，才可以开启整个的IO多路复用模型的读流程。
            （1）进行select/epoll系统调用，查询可以读的连接。kernel会查询所有select的可查询socket列表，当任何一个socket中的数据准备好了，select就会返回。  
                当用户进程调用了select，那么整个线程会被block（阻塞掉）。
            （2）用户线程获得了目标连接后，发起read系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。
            （3）用户线程才解除block的状态，用户线程终于真正读取到数据，继续执行。
    多路复用IO的特点：
        IO多路复用模型，建立在操作系统kernel内核能够提供的多路分离系统调用select/epoll基础之上的。多路复用IO需要用到两个系统调用（system call）， 一个select/epoll查询调用，一个是IO的读取调用。
        和NIO模型相似，多路复用IO需要轮询。负责select/epoll查询调用的线程，需要不断的进行select/epoll轮询，查找出可以进行IO操作的连接。
        另外，多路复用IO模型与前面的NIO模型，是有关系的。对于每一个可以查询的socket，一般都设置成为non-blocking模型。只是这一点，对于用户程序是透明的（不感知）。
    多路复用IO的优点：
        用select/epoll的优势在于，它可以同时处理成千上万个连接（connection）。与一条线程维护一个连接相比，I/O多路复用技术的最大优势是：系统不必创建线程，也不必维护这些线程，从而大大减小了系统的开销。
        Java的NIO（new IO）技术，使用的就是IO多路复用模型。在linux系统上，使用的是epoll系统调用。
    多路复用IO的缺点：
        本质上，select/epoll系统调用，属于同步IO，也是阻塞IO。都需要在读写事件就绪后，自己负责进行读写，也就是说这个读写过程是阻塞的。
异步IO模型（asynchronous IO）
    如何进一步提升效率，解除最后一点阻塞呢？这就是异步IO模型，全称asynchronous I/O，简称为AIO。
    AIO的基本流程是：
        用户线程通过系统调用，告知kernel内核启动某个IO操作，用户线程返回。kernel内核在整个IO操作（包括数据准备、数据复制）完成后，通知用户程序，用户执行后续的业务操作。
    kernel的数据准备是将数据从网络物理设备（网卡）读取到内核缓冲区；kernel的数据复制是将数据从内核缓冲区拷贝到用户程序空间的缓冲区。
    （1）当用户线程调用了read系统调用，立刻就可以开始去做其它的事，用户线程不阻塞。
    （2）内核（kernel）就开始了IO的第一个阶段：准备数据。当kernel一直等到数据准备好了，它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存）。
    （3）kernel会给用户线程发送一个信号（signal），或者回调用户线程注册的回调接口，告诉用户线程read操作完成了。
    （4）用户线程读取用户缓冲区的数据，完成后续的业务操作。
    异步IO模型的特点：
        在内核kernel的等待数据和复制数据的两个阶段，用户线程都不是block(阻塞)的。用户线程需要接受kernel的IO操作完成的事件，或者说注册IO操作完成的回调函数，到操作系统的内核。所以说，异步IO有的时候，也叫做信号驱动 IO 。
    异步IO模型缺点：
        需要完成事件的注册与传递，这里边需要底层操作系统提供大量的支持，去做大量的工作。
        目前来说， Windows 系统下通过 IOCP 实现了真正的异步 I/O。但是，就目前的业界形式来说，Windows 系统，很少作为百万级以上或者说高并发应用的服务器操作系统来使用。
        而在 Linux 系统下，异步IO模型在2.6版本才引入，目前并不完善。所以，这也是在 Linux 下，实现高并发网络编程时都是以 IO 复用模型模式为主。
小结一下：
    四种IO模型，理论上越往后，阻塞越少，效率也是最优。在这四种 I/O 模型中，前三种属于同步 I/O，因为其中真正的 I/O 操作将阻塞线程。只有最后一种，才是真正的异步 I/O 模型，可惜目前Linux 操作系统尚欠完善。
# 零拷贝
指计算机操作的过程中，cpu不需要为数据在内存之间的拷贝消耗资源。
而它通常是指计算机在网络上发送文件时，不需要将文件内容拷贝到用户空间，而直接在内核空间中传输到网络的方式。
好处
    减少设置完全避免不必要的cpu拷贝，让cpu解脱出来去执行其他的任务
    减少内存带宽的占用
    通常零拷贝技术还能够减少用户空间和操作系统内核空间之间的上下文切换
实现
    零拷贝实际的实现并没有真正的标准，取决于操作系统如何实现这一点。零拷贝完全依赖于操作系统。操作系统支持，就有；不支持，就没有。不依赖Java本身
传统I/O
    在Java中，我们可以通过InputStream从源数据中读取数据流到一个缓冲区里，然后再将它们输入到OutputStream里。
    我们知道，这种IO方式传输效率是比较低的。那么，当使用上面的代码时操作系统会发生什么情况：
        1，程序使用read()系统调用。
            系统由用户态转换为内核态(第一次上线文切换)，磁盘中的数据有DMA（Direct Memory Access)的方式读取到内核缓冲区(kernel buffer)。
            DMA过程中CPU不需要参与数据的读写，而是DMA处理器直接将硬盘数据通过总线传输到内存中
        2，系统由内核态转换为用户态（第二次上下文切换）
            当程序要读取的数据已经完成写入内核缓冲区以后，程序会将数据由内核缓存区，写入用户缓存区），这个过程需要CPU参与数据的读写。
        3，程序使用write()系统调用。
            系统由用户态切换到内核态(第三次上下文切换)，数据从用户态缓冲区写入到网络缓冲区(Socket Buffer)，这个过程需要CPU参与数据的读写。
        4，系统由内核态切换到用户态（第四次上下文切换）
            网络缓冲区的数据通过DMA的方式传输到网卡的驱动(存储缓冲区)中(protocol engine)
    可以看到，传统的I/O方式会经过4次用户态和内核态的切换(上下文切换)，两次CPU中内存中进行数据读写的过程。这种拷贝过程相对来说比较消耗资源。
mmap内存映射方式I/O
    mmap通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户空间的拷贝次数
        write(socket, tmp_buf, len);
        tmp_buf = mmap(file, len);
    这是使用的系统调用方法，这种方式的I/O原理就是将用户缓冲区（user buffer）的内存地址和内核缓冲区（kernel buffer）的内存地址做一个映射，也就是说系统在用户态可以直接读取并操作内核空间的数据。
        1，mmap()系统调用首先会使用DMA的方式将磁盘数据读取到内核缓冲区，然后通过内存映射方式，使用户缓冲区和内核缓冲区的地址为同一地址，也就是说不需要cpu再将数据从内核缓冲区复制到用户缓冲区
        2，当使用write()系统调用的时候，cpu将内核缓冲区（等同于用户缓冲区）的数据直接写入到网络发送缓冲区（socket buffer），然后通过DMA的方式将数据传入到网卡驱动程序中准备发送
    可以看到这种方式减少了CPU的读写次数，但是用户态到内核态的切换（上下文切换）依旧有四次，
    同时需要注意的是在进行内存映射的时候，有可能会出现并发线程操作同一块内存区域而导致严重数据不一致的问题，所以需要进行合理的并发编程来解决这些问题
    java代码实现
        public static void mappedFile(Path filename) {
            try (FileChannel fileChannel = FileChannel.open(filename)) {
                long size = fileChannel.size();
                MappedByteBuffer mappedByteBuffer = fileChannel.map(MapMode.READ_ONLY, 0, size);
                for (int i = 0; i < size; i++) {
                    mappedByteBuffer.get(i);
                }
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
通过sendfile实现的零拷贝I/O
    Linux 2.1 版本 提供了 sendFile 函数，其基本原理如下：
        数据根本不经过用户态，直接从内核缓冲区进入到Socket Buffer，同时，由于和用户态完全无关，减少了一次上下文切换
        sendFile(socket, file, len);
    通过sendfile()系统调用，可以做到内核空间内部直接进行I/O传输。
        1，senfile()系统调用也会 引起用户态到内核态的切换，与 内存映射方式不同的是，用户空间此时无法看到或者修改数据内容，也就是说这是一次完全意义上的数据传输过程
        2，从磁盘读取到内存的方式是DMA的方式，从内核缓冲区读取到网络发送区，依旧需要CPU参与拷贝，而从网络发送缓冲区到网卡中的缓冲区依旧是DMA方式
    sendfile()系统调用，依旧有一次CPU进行数据拷贝，两次用户态和内核态的切换，相比较于内存映射的方式有了很大的进步，但是问题是程序不能对数据进行修改，而只是单纯进行了一次数据传输过程
理想状态下的零拷贝I/O
    Linux 在 2.4 版本中，做了一些修改，避免了从内核缓冲区拷贝到 Socket buffer 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝。
    依旧是系统调用sendfile()
    可以看到，这是真正意义上的零拷贝，因为其间CPU已经不参与数据的拷贝过程，也就是说完全通过其他硬件和中断的方式来实现数据的读写过程吗，但是这样的过程需要硬件的支持才能实现。
        借助于硬件上的帮助，我们是可以办到的。之前我们是把页缓存的数据拷贝到socket缓存中，实际上，我们仅仅需要把缓冲区描述符传到socket缓冲区，再把数据长度传过去，这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了。
    1， 系统调用sendfile()发起后，磁盘数据通过DMA方式读取到内核缓冲区，内核缓冲区中的数据通过DMA聚合网络缓冲区，然后一齐发送到网卡中。
    可以看到在这种模式下，是没有一次CPU进行数据拷贝的，所以就做到了真正意义上的零拷贝，虽然和前一种是同一个系统调用，但是这种模式实现起来需要硬件的支持，但对于基于操作系统的用户来讲，操作系统已经屏蔽了这种差异，它会根据不同的硬件平台来实现这个系统调用。
零拷贝的再次理解
    1，我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据）。
    2，零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。
mmap 和 sendFile 的区别
    1，mmap 适合小数据量读写，sendFile 适合大文件传输。
    2，mmap 需要 4 次上下文切换，3 次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。
    3，sendFile 可以利用 DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。
Java NIO的零拷贝
    代码实现：
        SocketChannel socketChannel = SocketChannel.open();
        socketChannel.connect(new InetSocketAddress("localhost",7001));
        String filename = "text.zip";
        //得到一个文件channel
        FileChannel fileChannel = new FileInputStream(filename).getChannel();
        //在linux下一个transferTo 方法就可以完成传输
        //在windows下 一次调用 transferTo 只能发送8M, 大文件就需要分段传输文件
        //transferTo 底层使用到零拷贝
        long transferCount = fileChannel.transferTo(0, fileChannel.size(), socketChannel);
        //关闭
        fileChannel.close();
    NIO的零拷贝由transferTo()方法实现。transferTo()方法将数据从FileChannel对象传送到可写的字节通道（如Socket Channel等）。在内部实现中，由native方法transferTo0()来实现，它依赖底层操作系统的支持。在UNIX和Linux系统中，调用这个方法将会引起sendfile()系统调用。
使用场景一般是：
    1，较大，读写较慢，追求速度。
    2，M内存不足，不能加载太大数据。
    3，带宽不够，即存在其他程序或线程存在大量的IO操作，导致带宽本来就小。
    以上都建立在不需要进行数据文件操作的情况下，如果既需要这样的速度，也需要进行数据操作怎么办？
    那么使用NIO的直接内存！
NIO的直接内存
    代码实现：
        File file = new File("test.zip");
        RandomAccessFile randomAccessFile = new RandomAccessFile(file, "rw");
        //获取对应的通道
        FileChannel fileChannel = randomAccessFile.getChannel();
        /**
         * 参数1：FileChannel.MapMode.READ_WRITE 使用的读写模式
         * 参数2：可以直接修改的起始位置
         * 参数3: 是映射到内存的大小(不是索引位置) ,即将 test.zip 的多少个字节映射到内存
         * 实际类型 DirectByteBuffer
         */
        MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, fileChannel.size);
    首先，它的作用位置处于传统IO（BIO）与零拷贝之间，为何这么说？
        1，IO，可以把磁盘的文件经过内核空间，读到JVM空间，然后进行各种操作，最后再写到磁盘或是发送到网络，效率较慢但支持数据文件操作。
        2，零拷贝则是直接在内核空间完成文件读取并转到磁盘（或发送到网络）。由于它没有读取文件数据到JVM这一环，因此程序无法操作该文件数据，尽管效率很高！
    而直接内存则介于两者之间，效率一般且可操作文件数据。直接内存（mmap技术）将文件直接映射到内核空间的内存，返回一个操作地址（address），它解决了文件数据需要拷贝到JVM才能进行操作的窘境。而是直接在内核空间直接进行操作，省去了内核空间拷贝到用户空间这一步操作。
    NIO的直接内存是由MappedByteBuffer实现的。核心即是map()方法，该方法把文件映射到内存中，获得内存地址addr，然后通过这个addr构造MappedByteBuffer类，以暴露各种文件操作API。
    由于MappedByteBuffer申请的是堆外内存，因此不受Minor GC控制，只能在发生Full GC时才能被回收。而DirectByteBuffer改善了这一情况，它是MappedByteBuffer类的子类，同时它实现了DirectBuffer接口，维护一个Cleaner对象来完成内存回收。因此它既可以通过Full GC来回收内存，也可以调用clean()方法来进行回收。
    另外，直接内存的大小可通过jvm参数来设置：-XX:MaxDirectMemorySize。
    NIO的MappedByteBuffer还有一个兄弟叫做HeapByteBuffer。顾名思义，它用来在堆中申请内存，本质是一个数组。由于它位于堆中，因此可受GC管控，易于回收。


    


     
      




        

    



    
